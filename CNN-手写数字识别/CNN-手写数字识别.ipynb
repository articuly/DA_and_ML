{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据加载器基类，派生出图片加载器和标签加载器\n",
    "class Loader:\n",
    "    # 初始化加载器，path为数据文件路经，count为文件中的样本个数\n",
    "    def __init__(self, path, count):\n",
    "        self.path = path\n",
    "        self.count = count\n",
    "\n",
    "    # 读取文件内容\n",
    "    def get_file_content(self):\n",
    "        print(self.path)\n",
    "        f = open(self.path, 'rb')\n",
    "        content = f.read()\n",
    "        f.close()\n",
    "        return content  # 返回字节数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像数据加载器\n",
    "class ImageLoader(Loader):\n",
    "    # 内部函数，从文件字节数组中获取第index个图像数据，文件中包含所有样本图片数据\n",
    "    def get_picture(self, content, index):\n",
    "        start = index * 28 * 28 + 16  # 文件头16个字节，后面每28*28个字节为一个图片数据\n",
    "        picture = []\n",
    "        for i in range(28):\n",
    "            picture.append([])\n",
    "            for j in range(28):\n",
    "                byte1 = content[start + i * 28 + j]\n",
    "                picture[i].append(byte1)  # 在Python3中本来就是int\n",
    "                # picture[i].append(self.to_int(btye1))\n",
    "        # print(picture)\n",
    "        return picture\n",
    "\n",
    "    # 将图像数据转化成长度为784的行向量形式\n",
    "    def get_one_sample(self, picture):\n",
    "        sample = []\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                sample.append(picture[i][j])\n",
    "        # print(sample)\n",
    "        return sample\n",
    "\n",
    "    # 加载数据文件，获得全部样本的输入向量，onerow表示是否将每张图片转化为行向量\n",
    "    # to2表示是否转化为0，1矩阵\n",
    "    def load(self, onerow=False):\n",
    "        content = self.get_file_content()  #  获取文件字节数组\n",
    "        data_set = []\n",
    "        for index in range(self.count):  # 遍历每个样本\n",
    "            onepic = self.get_picture(content, index)  # 从样本得到图片数据，返回二维数组\n",
    "            if onerow:\n",
    "                onepic = sefl.get_one_sample(onepic)  # 转为一维向量形式\n",
    "            data_set.append(onepic)\n",
    "        # print(data_set)\n",
    "        return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标签数据加载器\n",
    "class LabelLoader(Loader):\n",
    "    # 加载数据文件，获得全部样本的标签向量\n",
    "    def load(self):\n",
    "        content = self.get_file_content()  # 获取文件字节数据\n",
    "        labels = []\n",
    "        for index in range(self.count):\n",
    "            onelabel = content[index + 8]  # 文件头有8个字节\n",
    "            onelabelvec = self.norm(onelabel)  # one-hot编码\n",
    "            labels.append(onelabelvec)\n",
    "        # print(labels)\n",
    "        return labels\n",
    "\n",
    "    # one-hot编码，用于将一个值转换为10维标签向量\n",
    "    def norm(self, label):\n",
    "        label_vec = []\n",
    "        # label_value=self.to_int(label)\n",
    "        label_value = label  # 在Python3中就是int\n",
    "        for i in range(10):\n",
    "            if i == label_value:\n",
    "                label_vec.append(1)\n",
    "            else:\n",
    "                label_vec.append(0)\n",
    "        return label_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得训练数据集\n",
    "def get_training_data_set(num, onerow=False):\n",
    "    image_loader = ImageLoader('train-images.idx3-ubyte', num)\n",
    "    label_loader = LabelLoader('train-labels.idx1-ubyte', num)\n",
    "    return image_loader.load(onerow), label_loader.load()\n",
    "\n",
    "\n",
    "# 获得测试数据集\n",
    "def get_test_data_set(num, onerow=False):\n",
    "    image_loader = ImageLoader('t10k-images.idx3-ubyte', num)\n",
    "    label_loader = LabelLoader('t10k-labels.idx1-ubyte', num)\n",
    "    return image_loader.load(onerow), label_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个长度为784的行向量打印成图形的样式\n",
    "def printimg(onepic):\n",
    "    onepic = onepic.reshape(28, 28)\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            if onepic[i, j] == 0:\n",
    "                print('  ', end='')\n",
    "            else:\n",
    "                print('* ', end='')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images.idx3-ubyte\n",
      "train-labels.idx1-ubyte\n",
      "t10k-images.idx3-ubyte\n",
      "t10k-labels.idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "# 加载训练集，最大样本量为60000\n",
    "X_train, Y_train = get_training_data_set(60000, False)\n",
    "# 加载测试集，最大样本量为10000\n",
    "X_test, Y_test = get_test_data_set(10000, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片数据归一化\n",
    "X_train = np.array(X_train).astype(bool).astype(float) / 255\n",
    "X_test = np.array(X_test).astype(bool).astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.         0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00392157 0.00392157\n",
      "  0.00392157 0.00392157 0.00392157 0.00392157 0.00392157 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换成np数组\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                                                        \n",
      "                  * * * * * * *                         \n",
      "                * * * * * * * * *                       \n",
      "                * * * *     * * * *                     \n",
      "              * * * *         * * * *                   \n",
      "              * * *             * * *                   \n",
      "              * * *             * * *                   \n",
      "              * *               * * *                   \n",
      "              * * *             * * *                   \n",
      "              * * * *           * * * * *               \n",
      "                * * * *         * * * * *               \n",
      "                  * * * * * * * * * * * *               \n",
      "                    * * * * * * * * * *                 \n",
      "                        * * * * * * *                   \n",
      "                                * * *                   \n",
      "                                * *                     \n",
      "                              * * *                     \n",
      "                              * * *                     \n",
      "                            * * * *                     \n",
      "                            * * *                       \n",
      "                            * * *                       \n",
      "                                                        \n",
      "                                                        \n"
     ]
    }
   ],
   "source": [
    "printimg(X_test[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加一个维度，代表图片通道，分别为样本个数，宽度，高度，通道数\n",
    "# X_train=X_train[:, :, :, np.newaxis]\n",
    "# X_test=X_test[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的维度： (60000, 28, 28, 1) (60000, 10)\n",
      "测试集的维度： (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('训练集的维度：', X_train.shape, Y_train.shape)\n",
    "print('测试集的维度：', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局变量\n",
    "batch_size = 512  # 批处理样本数量\n",
    "nb_classes = 10  # 分类数目\n",
    "epochs = 100  # 迭代轮数\n",
    "img_rows, img_cols = 28, 28  # 图片样本宽高\n",
    "nb_filters = 32  # 卷积核的个数\n",
    "pool_size = (2, 2)  # 池化层的大小\n",
    "kernel_size = (5, 5)  # 卷积核的大小\n",
    "input_shape = (img_rows, img_cols, 1)  # 输入图片的维度，灰度图片为1个通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "model = Sequential()\n",
    "# 卷积层一，深度6，核大小5*5，输入维度28*28，步长为1\n",
    "model.add(Conv2D(6, kernel_size, input_shape=input_shape, strides=1))\n",
    "# 池化层一，池大小5*5，步长为2\n",
    "model.add(AveragePooling2D(pool_size=pool_size, strides=2))\n",
    "# 卷积层二，深度2，核大小5*5，步长为1\n",
    "model.add(Conv2D(12, kernel_size=kernel_size, strides=1))\n",
    "# 池化层二\n",
    "model.add(AveragePooling2D(pool_size=pool_size, strides=2))\n",
    "# 拉成一维数据\n",
    "model.add(Flatten())\n",
    "# 全链接层，10分类\n",
    "model.add(Dense(nb_classes))\n",
    "# 激活函数\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 2.3016 - acc: 0.1116 - val_loss: 2.3009 - val_acc: 0.1135\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 2.3007 - acc: 0.1124 - val_loss: 2.3001 - val_acc: 0.1135\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.2996 - acc: 0.1124 - val_loss: 2.2980 - val_acc: 0.1135\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.2943 - acc: 0.1129 - val_loss: 2.2853 - val_acc: 0.1135\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 2.2350 - acc: 0.1995 - val_loss: 2.0660 - val_acc: 0.2847\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 1.2705 - acc: 0.6268 - val_loss: 0.8277 - val_acc: 0.7197\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.6700 - acc: 0.7938 - val_loss: 0.5545 - val_acc: 0.8339\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.5433 - acc: 0.8370 - val_loss: 0.4875 - val_acc: 0.8559\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4978 - acc: 0.8498 - val_loss: 0.4716 - val_acc: 0.8602\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4646 - acc: 0.8591 - val_loss: 0.4550 - val_acc: 0.8622\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4469 - acc: 0.8640 - val_loss: 0.4302 - val_acc: 0.8696\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4338 - acc: 0.8695 - val_loss: 0.4295 - val_acc: 0.8695\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.4218 - acc: 0.8724 - val_loss: 0.4261 - val_acc: 0.8670\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4140 - acc: 0.8741 - val_loss: 0.4033 - val_acc: 0.8783\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4068 - acc: 0.8771 - val_loss: 0.3995 - val_acc: 0.8773\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.4013 - acc: 0.8787 - val_loss: 0.3888 - val_acc: 0.8821\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3947 - acc: 0.8808 - val_loss: 0.3838 - val_acc: 0.8826\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3912 - acc: 0.8817 - val_loss: 0.3729 - val_acc: 0.8898\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3876 - acc: 0.8826 - val_loss: 0.3760 - val_acc: 0.8885\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3830 - acc: 0.8843 - val_loss: 0.3745 - val_acc: 0.8862\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3806 - acc: 0.8854 - val_loss: 0.3708 - val_acc: 0.8893\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3769 - acc: 0.8866 - val_loss: 0.3693 - val_acc: 0.8860\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3752 - acc: 0.8869 - val_loss: 0.3751 - val_acc: 0.8870\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3726 - acc: 0.8880 - val_loss: 0.3685 - val_acc: 0.8934\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3714 - acc: 0.8890 - val_loss: 0.3831 - val_acc: 0.8820\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3687 - acc: 0.8900 - val_loss: 0.3755 - val_acc: 0.8882\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3665 - acc: 0.8909 - val_loss: 0.3570 - val_acc: 0.8946\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3662 - acc: 0.8905 - val_loss: 0.3558 - val_acc: 0.8967\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3646 - acc: 0.8910 - val_loss: 0.3642 - val_acc: 0.8940\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3633 - acc: 0.8915 - val_loss: 0.3818 - val_acc: 0.8901\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3616 - acc: 0.8914 - val_loss: 0.3674 - val_acc: 0.8931\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3616 - acc: 0.8926 - val_loss: 0.3635 - val_acc: 0.8888\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3595 - acc: 0.8933 - val_loss: 0.3488 - val_acc: 0.8988\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3585 - acc: 0.8932 - val_loss: 0.3610 - val_acc: 0.8967\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3577 - acc: 0.8935 - val_loss: 0.3428 - val_acc: 0.9014\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3573 - acc: 0.8935 - val_loss: 0.3486 - val_acc: 0.8992\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3560 - acc: 0.8940 - val_loss: 0.3682 - val_acc: 0.8950\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3560 - acc: 0.8943 - val_loss: 0.3440 - val_acc: 0.9011\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3540 - acc: 0.8951 - val_loss: 0.3569 - val_acc: 0.8963\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3538 - acc: 0.8951 - val_loss: 0.3468 - val_acc: 0.9015\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3536 - acc: 0.8955 - val_loss: 0.3458 - val_acc: 0.9006\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3518 - acc: 0.8957 - val_loss: 0.3455 - val_acc: 0.9003\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3528 - acc: 0.8950 - val_loss: 0.3492 - val_acc: 0.8971\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3511 - acc: 0.8952 - val_loss: 0.3456 - val_acc: 0.8996\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3501 - acc: 0.8964 - val_loss: 0.3433 - val_acc: 0.9026\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3504 - acc: 0.8959 - val_loss: 0.3435 - val_acc: 0.8993\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3494 - acc: 0.8963 - val_loss: 0.3443 - val_acc: 0.8994\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3486 - acc: 0.8968 - val_loss: 0.3616 - val_acc: 0.8982\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3483 - acc: 0.8970 - val_loss: 0.3412 - val_acc: 0.9010\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3472 - acc: 0.8975 - val_loss: 0.3359 - val_acc: 0.9035\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3475 - acc: 0.8973 - val_loss: 0.3375 - val_acc: 0.9022\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3463 - acc: 0.8975 - val_loss: 0.3472 - val_acc: 0.9001\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3474 - acc: 0.8975 - val_loss: 0.3386 - val_acc: 0.9014\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3454 - acc: 0.8982 - val_loss: 0.3402 - val_acc: 0.9009\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3446 - acc: 0.8987 - val_loss: 0.3464 - val_acc: 0.9007\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3439 - acc: 0.8983 - val_loss: 0.3442 - val_acc: 0.9012\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3435 - acc: 0.8985 - val_loss: 0.3447 - val_acc: 0.9023\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3437 - acc: 0.8989 - val_loss: 0.3489 - val_acc: 0.8983\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3441 - acc: 0.8988 - val_loss: 0.3462 - val_acc: 0.8988\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3433 - acc: 0.8987 - val_loss: 0.3365 - val_acc: 0.9027\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.3428 - acc: 0.8989 - val_loss: 0.3436 - val_acc: 0.9016\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3417 - acc: 0.8996 - val_loss: 0.3407 - val_acc: 0.9006\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3415 - acc: 0.8998 - val_loss: 0.3338 - val_acc: 0.9044\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3410 - acc: 0.8990 - val_loss: 0.3400 - val_acc: 0.8992\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3398 - acc: 0.9001 - val_loss: 0.3427 - val_acc: 0.9015\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3395 - acc: 0.9000 - val_loss: 0.3278 - val_acc: 0.9058\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3396 - acc: 0.8996 - val_loss: 0.3362 - val_acc: 0.9037\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3399 - acc: 0.9003 - val_loss: 0.3297 - val_acc: 0.9049\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3386 - acc: 0.9007 - val_loss: 0.3306 - val_acc: 0.9031\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3391 - acc: 0.9011 - val_loss: 0.3381 - val_acc: 0.9031\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3385 - acc: 0.9011 - val_loss: 0.3372 - val_acc: 0.9046\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3379 - acc: 0.9009 - val_loss: 0.3345 - val_acc: 0.9038\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3378 - acc: 0.9010 - val_loss: 0.3268 - val_acc: 0.9064\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3369 - acc: 0.9013 - val_loss: 0.3349 - val_acc: 0.9039\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3359 - acc: 0.9014 - val_loss: 0.3367 - val_acc: 0.9011\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3370 - acc: 0.9009 - val_loss: 0.3324 - val_acc: 0.9040\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3361 - acc: 0.9021 - val_loss: 0.3387 - val_acc: 0.9038\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3357 - acc: 0.9017 - val_loss: 0.3349 - val_acc: 0.9023\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3349 - acc: 0.9023 - val_loss: 0.3267 - val_acc: 0.9059\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3345 - acc: 0.9027 - val_loss: 0.3297 - val_acc: 0.9069\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3345 - acc: 0.9022 - val_loss: 0.3338 - val_acc: 0.9035\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3347 - acc: 0.9021 - val_loss: 0.3309 - val_acc: 0.9035\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3337 - acc: 0.9028 - val_loss: 0.3245 - val_acc: 0.9092\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3333 - acc: 0.9024 - val_loss: 0.3293 - val_acc: 0.9057\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3336 - acc: 0.9025 - val_loss: 0.3287 - val_acc: 0.9047\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3325 - acc: 0.9030 - val_loss: 0.3281 - val_acc: 0.9079\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3338 - acc: 0.9034 - val_loss: 0.3271 - val_acc: 0.9079\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3328 - acc: 0.9039 - val_loss: 0.3343 - val_acc: 0.9034\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3321 - acc: 0.9035 - val_loss: 0.3230 - val_acc: 0.9062\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3309 - acc: 0.9035 - val_loss: 0.3324 - val_acc: 0.9062\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3308 - acc: 0.9035 - val_loss: 0.3209 - val_acc: 0.9099\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3298 - acc: 0.9035 - val_loss: 0.3274 - val_acc: 0.9058\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.3303 - acc: 0.9033 - val_loss: 0.3320 - val_acc: 0.9042\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.3292 - acc: 0.9036 - val_loss: 0.3374 - val_acc: 0.9038\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3294 - acc: 0.9045 - val_loss: 0.3442 - val_acc: 0.8999\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3288 - acc: 0.9042 - val_loss: 0.3283 - val_acc: 0.9066\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3288 - acc: 0.9042 - val_loss: 0.3318 - val_acc: 0.9080\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3289 - acc: 0.9046 - val_loss: 0.3219 - val_acc: 0.9079\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.3273 - acc: 0.9048 - val_loss: 0.3346 - val_acc: 0.9060\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 2s 27us/step - loss: 0.3281 - acc: 0.9051 - val_loss: 0.3253 - val_acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec0baa0ba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.3252777906358242\n",
      "Test accuary: 0.9062\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuary:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23b2e77e278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i4 = cv2.imread('4.png', 0)\n",
    "plt.imshow(i4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23b2e7e2198>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i5 = cv2.imread('5.png', 0)\n",
    "plt.imshow(i5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23b2e839c50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i6 = cv2.imread('6.png', 0)\n",
    "plt.imshow(i6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23b2e89a668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i7 = cv2.imread('7.png', 0)\n",
    "plt.imshow(i7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('cnn_model.h5')\n",
    "img_list = [i7, i6, i5, i4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "识别为：\n",
      "[[1.5467405e-05 0.0000000e+00 1.0728836e-05 1.9453168e-03 2.9802322e-07\n",
      "  1.9460917e-05 0.0000000e+00 1.3823211e-03 9.4805800e-06 6.1301151e-05]]\n",
      "[3]\n",
      "识别为：\n",
      "[[1.6748905e-05 0.0000000e+00 2.5033951e-06 1.0848045e-05 3.8743019e-07\n",
      "  1.0955334e-03 0.0000000e+00 0.0000000e+00 4.4854663e-05 2.6899434e-05]]\n",
      "[5]\n",
      "识别为：\n",
      "[[3.8743019e-07 0.0000000e+00 1.9142032e-04 5.0887465e-04 3.7234724e-03\n",
      "  3.0279160e-05 3.9637089e-06 0.0000000e+00 7.2856370e-04 8.2767582e-07]]\n",
      "[4]\n",
      "识别为：\n",
      "[[0.0000000e+00 0.0000000e+00 1.1920929e-07 1.4901161e-07 3.9708614e-04\n",
      "  8.9406967e-08 1.1622906e-06 4.7266483e-05 7.2480708e-07 3.7196351e-04]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "for img in img_list:\n",
    "    img = np.reshape(img, (1, 28, 28, 1)).astype(bool).astype('float32') / 255\n",
    "    my_proba = model.predict_proba(img)\n",
    "    my_predict = model.predict_classes(img)\n",
    "    print('识别为：')\n",
    "    print(my_proba)\n",
    "    print(my_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1_env]",
   "language": "python",
   "name": "conda-env-tf1_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
