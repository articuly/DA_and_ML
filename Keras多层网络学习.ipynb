{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离数据集\n",
    "(x_train, y_train), (x_test, y_test)=mnist.load_data()\n",
    "x_val=x_train[50000:]\n",
    "y_val=y_train[50000:]\n",
    "x_train=x_train[:50000]\n",
    "y_train=y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 值归一\n",
    "x_train=x_train.reshape(50000, 784).astype('float32')/255\n",
    "x_val=x_val.reshape(10000,784).astype('float32')/255\n",
    "x_test=x_test.reshape(10000, 784).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多值变哑变量矩阵\n",
    "y_train=np_utils.to_categorical(y_train)\n",
    "y_val=np_utils.to_categorical(y_val)\n",
    "y_test=np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽选部分数据\n",
    "train_rand_idxs=np.random.choice(50000, 700)\n",
    "val_rand_idxs=np.random.choice(10000, 300)\n",
    "x_train=x_train[train_rand_idxs]\n",
    "y_train=y_train[train_rand_idxs]\n",
    "x_val=x_val[val_rand_idxs]\n",
    "y_val=y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 2s 3ms/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 569us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 558us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 453us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 570us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 575us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 595us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 450us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 572us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 618us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 576us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 551us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 465us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 423us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 610us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 436us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 468us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 608us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 630us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 430us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 566us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 591us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.6785 - acc: 0.314 - 0s 491us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 607us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 485us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 475us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.6493 - acc: 0.3186 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.6483 - acc: 0.3214 - val_loss: 1.8191 - val_acc: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.6488 - acc: 0.3257 - val_loss: 1.8199 - val_acc: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.6466 - acc: 0.3257 - val_loss: 1.8512 - val_acc: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.6465 - acc: 0.3214 - val_loss: 1.8168 - val_acc: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 437us/step - loss: 1.6446 - acc: 0.3229 - val_loss: 1.8284 - val_acc: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.6437 - acc: 0.3243 - val_loss: 1.8154 - val_acc: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.6437 - acc: 0.3329 - val_loss: 1.8292 - val_acc: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6431 - acc: 0.3329 - val_loss: 1.8273 - val_acc: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.6419 - acc: 0.3271 - val_loss: 1.8197 - val_acc: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.6392 - acc: 0.3343 - val_loss: 1.8324 - val_acc: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 475us/step - loss: 1.6412 - acc: 0.3100 - val_loss: 1.8328 - val_acc: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.6390 - acc: 0.3243 - val_loss: 1.8306 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.6375 - acc: 0.3271 - val_loss: 1.8189 - val_acc: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6367 - acc: 0.3229 - val_loss: 1.8276 - val_acc: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.6364 - acc: 0.3257 - val_loss: 1.8245 - val_acc: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.6350 - acc: 0.3214 - val_loss: 1.8290 - val_acc: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.6340 - acc: 0.3400 - val_loss: 1.8270 - val_acc: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 491us/step - loss: 1.6319 - acc: 0.3457 - val_loss: 1.8343 - val_acc: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.6316 - acc: 0.3243 - val_loss: 1.8183 - val_acc: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 1.6326 - acc: 0.3329 - val_loss: 1.8309 - val_acc: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.6308 - acc: 0.3300 - val_loss: 1.8241 - val_acc: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.6308 - acc: 0.3343 - val_loss: 1.8329 - val_acc: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.6285 - acc: 0.3257 - val_loss: 1.8336 - val_acc: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.6278 - acc: 0.3300 - val_loss: 1.8304 - val_acc: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.6271 - acc: 0.3257 - val_loss: 1.8406 - val_acc: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.6265 - acc: 0.3271 - val_loss: 1.8350 - val_acc: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.6254 - acc: 0.3371 - val_loss: 1.8365 - val_acc: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.6239 - acc: 0.3314 - val_loss: 1.8264 - val_acc: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.6236 - acc: 0.3200 - val_loss: 1.8396 - val_acc: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 558us/step - loss: 1.6230 - acc: 0.3286 - val_loss: 1.8344 - val_acc: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.6221 - acc: 0.3314 - val_loss: 1.8389 - val_acc: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.6208 - acc: 0.3386 - val_loss: 1.8444 - val_acc: 0.2200\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.6198 - acc: 0.3386 - val_loss: 1.8525 - val_acc: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.6191 - acc: 0.3371 - val_loss: 1.8369 - val_acc: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.6170 - acc: 0.3271 - val_loss: 1.8517 - val_acc: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.6164 - acc: 0.3386 - val_loss: 1.8397 - val_acc: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6182 - acc: 0.3386 - val_loss: 1.8392 - val_acc: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 435us/step - loss: 1.6167 - acc: 0.3300 - val_loss: 1.8420 - val_acc: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.6166 - acc: 0.3357 - val_loss: 1.8406 - val_acc: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.6143 - acc: 0.3229 - val_loss: 1.8437 - val_acc: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.6134 - acc: 0.3371 - val_loss: 1.8384 - val_acc: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.6139 - acc: 0.3371 - val_loss: 1.8446 - val_acc: 0.2267\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.6134 - acc: 0.3400 - val_loss: 1.8376 - val_acc: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.6110 - acc: 0.3371 - val_loss: 1.8415 - val_acc: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.6115 - acc: 0.3457 - val_loss: 1.8339 - val_acc: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.6106 - acc: 0.3471 - val_loss: 1.8365 - val_acc: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.6115 - acc: 0.3300 - val_loss: 1.8411 - val_acc: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.6093 - acc: 0.3443 - val_loss: 1.8453 - val_acc: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.6076 - acc: 0.3386 - val_loss: 1.8641 - val_acc: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.6086 - acc: 0.3443 - val_loss: 1.8449 - val_acc: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.6065 - acc: 0.3543 - val_loss: 1.8442 - val_acc: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.6075 - acc: 0.3386 - val_loss: 1.8412 - val_acc: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.6045 - acc: 0.3529 - val_loss: 1.8517 - val_acc: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.6065 - acc: 0.3314 - val_loss: 1.8401 - val_acc: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.6042 - acc: 0.3529 - val_loss: 1.8564 - val_acc: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.6044 - acc: 0.3500 - val_loss: 1.8503 - val_acc: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.6029 - acc: 0.3357 - val_loss: 1.8539 - val_acc: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.6025 - acc: 0.3414 - val_loss: 1.8470 - val_acc: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.6019 - acc: 0.3457 - val_loss: 1.8453 - val_acc: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.6016 - acc: 0.3514 - val_loss: 1.8472 - val_acc: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.6002 - acc: 0.3443 - val_loss: 1.8488 - val_acc: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.6005 - acc: 0.3386 - val_loss: 1.8591 - val_acc: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.6003 - acc: 0.3429 - val_loss: 1.8558 - val_acc: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5975 - acc: 0.3457 - val_loss: 1.8604 - val_acc: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.5986 - acc: 0.3457 - val_loss: 1.8469 - val_acc: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5979 - acc: 0.3414 - val_loss: 1.8478 - val_acc: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.5965 - acc: 0.3343 - val_loss: 1.8562 - val_acc: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.5953 - acc: 0.3557 - val_loss: 1.8461 - val_acc: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 435us/step - loss: 1.5953 - acc: 0.3429 - val_loss: 1.8508 - val_acc: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.5946 - acc: 0.3500 - val_loss: 1.8463 - val_acc: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5947 - acc: 0.3543 - val_loss: 1.8537 - val_acc: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 440us/step - loss: 1.5920 - acc: 0.3414 - val_loss: 1.8557 - val_acc: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.5919 - acc: 0.3514 - val_loss: 1.8521 - val_acc: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.5915 - acc: 0.3443 - val_loss: 1.8523 - val_acc: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.5903 - acc: 0.3371 - val_loss: 1.8456 - val_acc: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.5913 - acc: 0.3471 - val_loss: 1.8593 - val_acc: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.5894 - acc: 0.3500 - val_loss: 1.8519 - val_acc: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.5905 - acc: 0.3457 - val_loss: 1.8541 - val_acc: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.5886 - acc: 0.3514 - val_loss: 1.8602 - val_acc: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5895 - acc: 0.3486 - val_loss: 1.8624 - val_acc: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.5881 - acc: 0.3471 - val_loss: 1.8638 - val_acc: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.5876 - acc: 0.3486 - val_loss: 1.8600 - val_acc: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5865 - acc: 0.3500 - val_loss: 1.8659 - val_acc: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.5855 - acc: 0.3514 - val_loss: 1.8581 - val_acc: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5855 - acc: 0.3471 - val_loss: 1.8621 - val_acc: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5845 - acc: 0.3514 - val_loss: 1.8751 - val_acc: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5844 - acc: 0.3443 - val_loss: 1.8615 - val_acc: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.5845 - acc: 0.3529 - val_loss: 1.8766 - val_acc: 0.2467\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.5833 - acc: 0.3457 - val_loss: 1.8572 - val_acc: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.5835 - acc: 0.3486 - val_loss: 1.8686 - val_acc: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.5825 - acc: 0.3486 - val_loss: 1.8611 - val_acc: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.5825 - acc: 0.3443 - val_loss: 1.8693 - val_acc: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 1.5801 - acc: 0.3471 - val_loss: 1.8688 - val_acc: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5818 - acc: 0.3471 - val_loss: 1.8635 - val_acc: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.5797 - acc: 0.3529 - val_loss: 1.8605 - val_acc: 0.2200\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 1.5809 - acc: 0.3514 - val_loss: 1.8730 - val_acc: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5796 - acc: 0.3486 - val_loss: 1.8781 - val_acc: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.5791 - acc: 0.3457 - val_loss: 1.8666 - val_acc: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.5777 - acc: 0.3571 - val_loss: 1.8693 - val_acc: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.5778 - acc: 0.3443 - val_loss: 1.8664 - val_acc: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.5770 - acc: 0.3429 - val_loss: 1.8718 - val_acc: 0.2300\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.5774 - acc: 0.3471 - val_loss: 1.8613 - val_acc: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.5770 - acc: 0.3571 - val_loss: 1.8682 - val_acc: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8719 - val_acc: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.5749 - acc: 0.3571 - val_loss: 1.8738 - val_acc: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.5743 - acc: 0.3514 - val_loss: 1.8733 - val_acc: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5743 - acc: 0.3629 - val_loss: 1.8806 - val_acc: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.5713 - acc: 0.3557 - val_loss: 1.8724 - val_acc: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5715 - acc: 0.3586 - val_loss: 1.8838 - val_acc: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5712 - acc: 0.3543 - val_loss: 1.8710 - val_acc: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.5722 - acc: 0.3557 - val_loss: 1.8631 - val_acc: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.5716 - acc: 0.3557 - val_loss: 1.8700 - val_acc: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.5712 - acc: 0.3471 - val_loss: 1.8840 - val_acc: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.5680 - acc: 0.3657 - val_loss: 1.8981 - val_acc: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.5704 - acc: 0.3486 - val_loss: 1.8793 - val_acc: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.5682 - acc: 0.3643 - val_loss: 1.8744 - val_acc: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.5689 - acc: 0.3586 - val_loss: 1.8820 - val_acc: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.5677 - acc: 0.3571 - val_loss: 1.8835 - val_acc: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5681 - acc: 0.3457 - val_loss: 1.8713 - val_acc: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.5657 - acc: 0.3571 - val_loss: 1.8761 - val_acc: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.5667 - acc: 0.3514 - val_loss: 1.8912 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 442us/step - loss: 1.5649 - acc: 0.3614 - val_loss: 1.8946 - val_acc: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 580us/step - loss: 1.5648 - acc: 0.3643 - val_loss: 1.8911 - val_acc: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.5657 - acc: 0.3600 - val_loss: 1.8989 - val_acc: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.5637 - acc: 0.3571 - val_loss: 1.8751 - val_acc: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 566us/step - loss: 1.5638 - acc: 0.3614 - val_loss: 1.8836 - val_acc: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.5631 - acc: 0.3629 - val_loss: 1.8858 - val_acc: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.5640 - acc: 0.3571 - val_loss: 1.8812 - val_acc: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5638 - acc: 0.3686 - val_loss: 1.8902 - val_acc: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.5614 - acc: 0.3614 - val_loss: 1.8968 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.5612 - acc: 0.3629 - val_loss: 1.8918 - val_acc: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.5613 - acc: 0.3614 - val_loss: 1.8757 - val_acc: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.5601 - acc: 0.3643 - val_loss: 1.8854 - val_acc: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.5594 - acc: 0.3671 - val_loss: 1.8674 - val_acc: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 583us/step - loss: 1.5610 - acc: 0.3657 - val_loss: 1.8914 - val_acc: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.5595 - acc: 0.3600 - val_loss: 1.9030 - val_acc: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.5591 - acc: 0.3571 - val_loss: 1.8964 - val_acc: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 577us/step - loss: 1.5589 - acc: 0.3457 - val_loss: 1.8841 - val_acc: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 465us/step - loss: 1.5589 - acc: 0.3629 - val_loss: 1.8914 - val_acc: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.5579 - acc: 0.3529 - val_loss: 1.8967 - val_acc: 0.2533\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.5581 - acc: 0.3714 - val_loss: 1.8909 - val_acc: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5578 - acc: 0.3600 - val_loss: 1.9032 - val_acc: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.5559 - acc: 0.3571 - val_loss: 1.8859 - val_acc: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.5559 - acc: 0.3700 - val_loss: 1.8876 - val_acc: 0.2167\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.5541 - acc: 0.3586 - val_loss: 1.8906 - val_acc: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.5553 - acc: 0.3671 - val_loss: 1.8840 - val_acc: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.5543 - acc: 0.3557 - val_loss: 1.8927 - val_acc: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.5542 - acc: 0.3614 - val_loss: 1.8936 - val_acc: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5535 - acc: 0.3557 - val_loss: 1.8887 - val_acc: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.5536 - acc: 0.3586 - val_loss: 1.8989 - val_acc: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.5527 - acc: 0.3686 - val_loss: 1.9019 - val_acc: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5525 - acc: 0.3600 - val_loss: 1.8930 - val_acc: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5519 - acc: 0.3600 - val_loss: 1.9014 - val_acc: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.5514 - acc: 0.3657 - val_loss: 1.9032 - val_acc: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.5513 - acc: 0.3586 - val_loss: 1.9037 - val_acc: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.5509 - acc: 0.3543 - val_loss: 1.8995 - val_acc: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5507 - acc: 0.3543 - val_loss: 1.9011 - val_acc: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.5497 - acc: 0.3543 - val_loss: 1.9002 - val_acc: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.5499 - acc: 0.3657 - val_loss: 1.9120 - val_acc: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.5495 - acc: 0.3571 - val_loss: 1.9104 - val_acc: 0.2133\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.5479 - acc: 0.3571 - val_loss: 1.9128 - val_acc: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 453us/step - loss: 1.5477 - acc: 0.3486 - val_loss: 1.8958 - val_acc: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.5485 - acc: 0.3686 - val_loss: 1.9145 - val_acc: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.5472 - acc: 0.3629 - val_loss: 1.9031 - val_acc: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.5469 - acc: 0.3629 - val_loss: 1.8934 - val_acc: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.5479 - acc: 0.3657 - val_loss: 1.9081 - val_acc: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5464 - acc: 0.3529 - val_loss: 1.9016 - val_acc: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.5452 - acc: 0.3671 - val_loss: 1.9066 - val_acc: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.5432 - acc: 0.3643 - val_loss: 1.9140 - val_acc: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.5458 - acc: 0.3600 - val_loss: 1.9100 - val_acc: 0.2233\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 437us/step - loss: 1.5436 - acc: 0.3671 - val_loss: 1.9064 - val_acc: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.5453 - acc: 0.3600 - val_loss: 1.9129 - val_acc: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5435 - acc: 0.3643 - val_loss: 1.9120 - val_acc: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.5448 - acc: 0.3671 - val_loss: 1.9110 - val_acc: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.5426 - acc: 0.3586 - val_loss: 1.9058 - val_acc: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 611us/step - loss: 1.5423 - acc: 0.3729 - val_loss: 1.9273 - val_acc: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.5387 - acc: 0.3657 - val_loss: 1.9056 - val_acc: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.5433 - acc: 0.3686 - val_loss: 1.9131 - val_acc: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 570us/step - loss: 1.5406 - acc: 0.3657 - val_loss: 1.9118 - val_acc: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.5404 - acc: 0.3614 - val_loss: 1.9141 - val_acc: 0.2233\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 617us/step - loss: 1.5412 - acc: 0.3614 - val_loss: 1.9213 - val_acc: 0.2333\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.5461 - acc: 0.364 - 0s 495us/step - loss: 1.5408 - acc: 0.3614 - val_loss: 1.9096 - val_acc: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 600us/step - loss: 1.5390 - acc: 0.3614 - val_loss: 1.9092 - val_acc: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.5392 - acc: 0.3629 - val_loss: 1.9278 - val_acc: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 640us/step - loss: 1.5392 - acc: 0.3686 - val_loss: 1.9258 - val_acc: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.5375 - acc: 0.3671 - val_loss: 1.9181 - val_acc: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5383 - acc: 0.3714 - val_loss: 1.9197 - val_acc: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5373 - acc: 0.3657 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.5387 - acc: 0.3600 - val_loss: 1.9178 - val_acc: 0.2133\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.5365 - acc: 0.3614 - val_loss: 1.9227 - val_acc: 0.2200\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 518us/step - loss: 1.5359 - acc: 0.3743 - val_loss: 1.9378 - val_acc: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5366 - acc: 0.3657 - val_loss: 1.9307 - val_acc: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.5354 - acc: 0.3714 - val_loss: 1.9147 - val_acc: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.5351 - acc: 0.3600 - val_loss: 1.9222 - val_acc: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.5338 - acc: 0.3714 - val_loss: 1.9155 - val_acc: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 592us/step - loss: 1.5346 - acc: 0.3571 - val_loss: 1.9340 - val_acc: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 587us/step - loss: 1.5358 - acc: 0.3671 - val_loss: 1.9234 - val_acc: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.5349 - acc: 0.3629 - val_loss: 1.9289 - val_acc: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.5327 - acc: 0.3757 - val_loss: 1.9246 - val_acc: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.5335 - acc: 0.3786 - val_loss: 1.9184 - val_acc: 0.2300\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 437us/step - loss: 1.5330 - acc: 0.3757 - val_loss: 1.9324 - val_acc: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.5320 - acc: 0.3743 - val_loss: 1.9238 - val_acc: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.5314 - acc: 0.3700 - val_loss: 1.9157 - val_acc: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5328 - acc: 0.3729 - val_loss: 1.9403 - val_acc: 0.2267\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 628us/step - loss: 1.5317 - acc: 0.3757 - val_loss: 1.9258 - val_acc: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.5313 - acc: 0.3600 - val_loss: 1.9441 - val_acc: 0.2167\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.5310 - acc: 0.3686 - val_loss: 1.9333 - val_acc: 0.2267\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.5308 - acc: 0.3671 - val_loss: 1.9431 - val_acc: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.5291 - acc: 0.3686 - val_loss: 1.9443 - val_acc: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.5301 - acc: 0.3700 - val_loss: 1.9314 - val_acc: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.5277 - acc: 0.3800 - val_loss: 1.9199 - val_acc: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.5284 - acc: 0.3643 - val_loss: 1.9294 - val_acc: 0.2167\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.5281 - acc: 0.3700 - val_loss: 1.9273 - val_acc: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.5282 - acc: 0.3657 - val_loss: 1.9311 - val_acc: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.5264 - acc: 0.3757 - val_loss: 1.9309 - val_acc: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.5283 - acc: 0.3729 - val_loss: 1.9282 - val_acc: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 596us/step - loss: 1.5256 - acc: 0.3657 - val_loss: 1.9422 - val_acc: 0.2300\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 596us/step - loss: 1.5279 - acc: 0.3700 - val_loss: 1.9350 - val_acc: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.5261 - acc: 0.3600 - val_loss: 1.9553 - val_acc: 0.2267\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 565us/step - loss: 1.5260 - acc: 0.3700 - val_loss: 1.9442 - val_acc: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.5259 - acc: 0.3743 - val_loss: 1.9355 - val_acc: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9494 - val_acc: 0.2233\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.5251 - acc: 0.3729 - val_loss: 1.9450 - val_acc: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.5232 - acc: 0.3743 - val_loss: 1.9454 - val_acc: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5232 - acc: 0.3686 - val_loss: 1.9485 - val_acc: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.5240 - acc: 0.3643 - val_loss: 1.9508 - val_acc: 0.2267\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.5215 - acc: 0.3757 - val_loss: 1.9527 - val_acc: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.5230 - acc: 0.3643 - val_loss: 1.9381 - val_acc: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 1.5224 - acc: 0.3771 - val_loss: 1.9524 - val_acc: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.5222 - acc: 0.3686 - val_loss: 1.9406 - val_acc: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.5221 - acc: 0.3757 - val_loss: 1.9567 - val_acc: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 1s 854us/step - loss: 1.5206 - acc: 0.3786 - val_loss: 1.9551 - val_acc: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.5207 - acc: 0.3629 - val_loss: 1.9321 - val_acc: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 1s 896us/step - loss: 1.5200 - acc: 0.3757 - val_loss: 1.9534 - val_acc: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 1s 745us/step - loss: 1.5209 - acc: 0.3671 - val_loss: 1.9508 - val_acc: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 495us/step - loss: 1.5195 - acc: 0.3729 - val_loss: 1.9590 - val_acc: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.5205 - acc: 0.3757 - val_loss: 1.9453 - val_acc: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.5197 - acc: 0.3686 - val_loss: 1.9514 - val_acc: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.5181 - acc: 0.3843 - val_loss: 1.9386 - val_acc: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 577us/step - loss: 1.5182 - acc: 0.3800 - val_loss: 1.9487 - val_acc: 0.2167\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.5170 - acc: 0.3743 - val_loss: 1.9760 - val_acc: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.5182 - acc: 0.3743 - val_loss: 1.9761 - val_acc: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5188 - acc: 0.3700 - val_loss: 1.9516 - val_acc: 0.2367\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.5166 - acc: 0.3671 - val_loss: 1.9602 - val_acc: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5180 - acc: 0.3786 - val_loss: 1.9711 - val_acc: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.5161 - acc: 0.3743 - val_loss: 1.9585 - val_acc: 0.2267\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.5155 - acc: 0.3700 - val_loss: 1.9714 - val_acc: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.5164 - acc: 0.3771 - val_loss: 1.9509 - val_acc: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 580us/step - loss: 1.5163 - acc: 0.3743 - val_loss: 1.9579 - val_acc: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 566us/step - loss: 1.5156 - acc: 0.3714 - val_loss: 1.9502 - val_acc: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.5153 - acc: 0.3743 - val_loss: 1.9578 - val_acc: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.5143 - acc: 0.3714 - val_loss: 1.9668 - val_acc: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.5158 - acc: 0.3800 - val_loss: 1.9490 - val_acc: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.5125 - acc: 0.3671 - val_loss: 1.9572 - val_acc: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.5132 - acc: 0.3757 - val_loss: 1.9539 - val_acc: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.5137 - acc: 0.3714 - val_loss: 1.9599 - val_acc: 0.2233\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.5137 - acc: 0.3757 - val_loss: 1.9730 - val_acc: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5136 - acc: 0.3757 - val_loss: 1.9565 - val_acc: 0.2267\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.5132 - acc: 0.3771 - val_loss: 1.9565 - val_acc: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.5124 - acc: 0.3771 - val_loss: 1.9619 - val_acc: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.5111 - acc: 0.3857 - val_loss: 1.9755 - val_acc: 0.2367\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.5124 - acc: 0.3643 - val_loss: 1.9588 - val_acc: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.5107 - acc: 0.3743 - val_loss: 1.9872 - val_acc: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.5113 - acc: 0.3643 - val_loss: 1.9599 - val_acc: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.5109 - acc: 0.3657 - val_loss: 1.9595 - val_acc: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.5086 - acc: 0.3771 - val_loss: 1.9650 - val_acc: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 450us/step - loss: 1.5068 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.5085 - acc: 0.3743 - val_loss: 1.9678 - val_acc: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5074 - acc: 0.3800 - val_loss: 1.9811 - val_acc: 0.2300\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.5085 - acc: 0.3771 - val_loss: 1.9745 - val_acc: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.5080 - acc: 0.3714 - val_loss: 1.9792 - val_acc: 0.2267\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.5077 - acc: 0.3757 - val_loss: 1.9706 - val_acc: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.5040 - acc: 0.3700 - val_loss: 1.9783 - val_acc: 0.2367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.5058 - acc: 0.3771 - val_loss: 1.9611 - val_acc: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.5056 - acc: 0.3714 - val_loss: 1.9817 - val_acc: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.5048 - acc: 0.3843 - val_loss: 1.9719 - val_acc: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.5033 - acc: 0.3771 - val_loss: 1.9760 - val_acc: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.5043 - acc: 0.3786 - val_loss: 1.9842 - val_acc: 0.2333\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.5015 - acc: 0.3786 - val_loss: 1.9778 - val_acc: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.5031 - acc: 0.3843 - val_loss: 1.9889 - val_acc: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.5032 - acc: 0.3786 - val_loss: 1.9804 - val_acc: 0.2200\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.5016 - acc: 0.3871 - val_loss: 1.9744 - val_acc: 0.2333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.5019 - acc: 0.3786 - val_loss: 1.9663 - val_acc: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.5015 - acc: 0.3800 - val_loss: 1.9877 - val_acc: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.5011 - acc: 0.3829 - val_loss: 1.9692 - val_acc: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.5004 - acc: 0.3743 - val_loss: 1.9747 - val_acc: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.5003 - acc: 0.3814 - val_loss: 1.9792 - val_acc: 0.2333\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.5001 - acc: 0.3757 - val_loss: 1.9678 - val_acc: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4991 - acc: 0.3886 - val_loss: 1.9619 - val_acc: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4984 - acc: 0.3914 - val_loss: 1.9792 - val_acc: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.4983 - acc: 0.3814 - val_loss: 1.9833 - val_acc: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4984 - acc: 0.3843 - val_loss: 2.0046 - val_acc: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4982 - acc: 0.3771 - val_loss: 1.9696 - val_acc: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.4977 - acc: 0.3814 - val_loss: 1.9811 - val_acc: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.4990 - acc: 0.3786 - val_loss: 1.9880 - val_acc: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 541us/step - loss: 1.4974 - acc: 0.3843 - val_loss: 1.9760 - val_acc: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4967 - acc: 0.3814 - val_loss: 1.9850 - val_acc: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4976 - acc: 0.3743 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4957 - acc: 0.3900 - val_loss: 1.9819 - val_acc: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4975 - acc: 0.3843 - val_loss: 1.9691 - val_acc: 0.2233\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4957 - acc: 0.3943 - val_loss: 1.9951 - val_acc: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4948 - acc: 0.3857 - val_loss: 1.9635 - val_acc: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4946 - acc: 0.3771 - val_loss: 1.9781 - val_acc: 0.2233\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4960 - acc: 0.3800 - val_loss: 1.9796 - val_acc: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.4951 - acc: 0.3886 - val_loss: 1.9825 - val_acc: 0.2300\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 495us/step - loss: 1.4944 - acc: 0.3829 - val_loss: 1.9939 - val_acc: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4937 - acc: 0.3857 - val_loss: 1.9899 - val_acc: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4946 - acc: 0.3829 - val_loss: 1.9926 - val_acc: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 541us/step - loss: 1.4942 - acc: 0.3829 - val_loss: 1.9955 - val_acc: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4931 - acc: 0.3886 - val_loss: 2.0029 - val_acc: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4926 - acc: 0.3800 - val_loss: 2.0142 - val_acc: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.4927 - acc: 0.3843 - val_loss: 1.9924 - val_acc: 0.2267\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4918 - acc: 0.3886 - val_loss: 2.0006 - val_acc: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.4929 - acc: 0.3843 - val_loss: 1.9930 - val_acc: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.4919 - acc: 0.3843 - val_loss: 1.9986 - val_acc: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 581us/step - loss: 1.4908 - acc: 0.3857 - val_loss: 1.9947 - val_acc: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 574us/step - loss: 1.4910 - acc: 0.3871 - val_loss: 1.9899 - val_acc: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.4908 - acc: 0.3871 - val_loss: 1.9967 - val_acc: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4907 - acc: 0.3843 - val_loss: 1.9881 - val_acc: 0.2233\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.4898 - acc: 0.3786 - val_loss: 1.9915 - val_acc: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.4899 - acc: 0.3871 - val_loss: 1.9972 - val_acc: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.4902 - acc: 0.3857 - val_loss: 1.9926 - val_acc: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 580us/step - loss: 1.4881 - acc: 0.3943 - val_loss: 1.9909 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 598us/step - loss: 1.4900 - acc: 0.3886 - val_loss: 2.0007 - val_acc: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 613us/step - loss: 1.4883 - acc: 0.3957 - val_loss: 2.0033 - val_acc: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 581us/step - loss: 1.4883 - acc: 0.3900 - val_loss: 1.9937 - val_acc: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4872 - acc: 0.3857 - val_loss: 2.0002 - val_acc: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 1.9888 - val_acc: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4877 - acc: 0.3900 - val_loss: 1.9972 - val_acc: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4871 - acc: 0.3757 - val_loss: 2.0004 - val_acc: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.4873 - acc: 0.3871 - val_loss: 2.0061 - val_acc: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4865 - acc: 0.3829 - val_loss: 1.9905 - val_acc: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 491us/step - loss: 1.4859 - acc: 0.3871 - val_loss: 2.0313 - val_acc: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4871 - acc: 0.3871 - val_loss: 2.0096 - val_acc: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.4859 - acc: 0.3957 - val_loss: 2.0055 - val_acc: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4845 - acc: 0.3971 - val_loss: 2.0080 - val_acc: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.4850 - acc: 0.3914 - val_loss: 2.0121 - val_acc: 0.2367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4838 - acc: 0.3900 - val_loss: 1.9976 - val_acc: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.4842 - acc: 0.3900 - val_loss: 2.0047 - val_acc: 0.2233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.4835 - acc: 0.3900 - val_loss: 2.0056 - val_acc: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4839 - acc: 0.3900 - val_loss: 2.0095 - val_acc: 0.2267\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4838 - acc: 0.3929 - val_loss: 2.0056 - val_acc: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 577us/step - loss: 1.4833 - acc: 0.3900 - val_loss: 2.0015 - val_acc: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 541us/step - loss: 1.4824 - acc: 0.3957 - val_loss: 2.0102 - val_acc: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4821 - acc: 0.3871 - val_loss: 2.0187 - val_acc: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4810 - acc: 0.3986 - val_loss: 2.0164 - val_acc: 0.2300\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4821 - acc: 0.4000 - val_loss: 2.0144 - val_acc: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4815 - acc: 0.3986 - val_loss: 2.0162 - val_acc: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.4811 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.4808 - acc: 0.3857 - val_loss: 2.0074 - val_acc: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.4811 - acc: 0.3957 - val_loss: 2.0075 - val_acc: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4808 - acc: 0.3914 - val_loss: 2.0157 - val_acc: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4804 - acc: 0.3886 - val_loss: 2.0031 - val_acc: 0.2267\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 603us/step - loss: 1.4809 - acc: 0.3900 - val_loss: 2.0000 - val_acc: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4808 - acc: 0.3871 - val_loss: 2.0215 - val_acc: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4800 - acc: 0.3914 - val_loss: 2.0007 - val_acc: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 1.4799 - acc: 0.4014 - val_loss: 2.0076 - val_acc: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4802 - acc: 0.3900 - val_loss: 2.0072 - val_acc: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.4792 - acc: 0.4029 - val_loss: 2.0260 - val_acc: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.4786 - acc: 0.3857 - val_loss: 2.0112 - val_acc: 0.2433\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.4773 - acc: 0.3929 - val_loss: 2.0122 - val_acc: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.4763 - acc: 0.3886 - val_loss: 2.0468 - val_acc: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4775 - acc: 0.4014 - val_loss: 2.0281 - val_acc: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4780 - acc: 0.3929 - val_loss: 2.0262 - val_acc: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4782 - acc: 0.4000 - val_loss: 2.0258 - val_acc: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4760 - acc: 0.3943 - val_loss: 2.0261 - val_acc: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4766 - acc: 0.3957 - val_loss: 2.0202 - val_acc: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4757 - acc: 0.3971 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.4754 - acc: 0.3957 - val_loss: 2.0196 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4754 - acc: 0.3986 - val_loss: 2.0154 - val_acc: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4769 - acc: 0.3986 - val_loss: 2.0225 - val_acc: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4750 - acc: 0.3900 - val_loss: 2.0240 - val_acc: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4744 - acc: 0.3943 - val_loss: 2.0373 - val_acc: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4745 - acc: 0.3914 - val_loss: 2.0230 - val_acc: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4737 - acc: 0.4029 - val_loss: 2.0154 - val_acc: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4739 - acc: 0.3971 - val_loss: 2.0106 - val_acc: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4732 - acc: 0.3986 - val_loss: 2.0137 - val_acc: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4727 - acc: 0.4000 - val_loss: 2.0268 - val_acc: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4734 - acc: 0.4014 - val_loss: 2.0250 - val_acc: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4741 - acc: 0.3957 - val_loss: 2.0273 - val_acc: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4706 - acc: 0.3929 - val_loss: 2.0338 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4740 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.4727 - acc: 0.4043 - val_loss: 2.0238 - val_acc: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4718 - acc: 0.3957 - val_loss: 2.0307 - val_acc: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4713 - acc: 0.4129 - val_loss: 2.0126 - val_acc: 0.2333\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.4725 - acc: 0.3986 - val_loss: 2.0341 - val_acc: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 1s 826us/step - loss: 1.4721 - acc: 0.3929 - val_loss: 2.0293 - val_acc: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.4711 - acc: 0.3986 - val_loss: 2.0230 - val_acc: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 597us/step - loss: 1.4696 - acc: 0.4000 - val_loss: 2.0285 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4711 - acc: 0.4029 - val_loss: 2.0247 - val_acc: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4702 - acc: 0.3929 - val_loss: 2.0259 - val_acc: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4694 - acc: 0.4029 - val_loss: 2.0291 - val_acc: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4681 - acc: 0.3943 - val_loss: 2.0337 - val_acc: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4686 - acc: 0.4000 - val_loss: 2.0412 - val_acc: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4689 - acc: 0.3957 - val_loss: 2.0247 - val_acc: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.4690 - acc: 0.4014 - val_loss: 2.0352 - val_acc: 0.2433\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.4685 - acc: 0.4000 - val_loss: 2.0311 - val_acc: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.4688 - acc: 0.3971 - val_loss: 2.0267 - val_acc: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.4673 - acc: 0.4043 - val_loss: 2.0499 - val_acc: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4671 - acc: 0.4043 - val_loss: 2.0468 - val_acc: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4676 - acc: 0.4029 - val_loss: 2.0293 - val_acc: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4672 - acc: 0.3957 - val_loss: 2.0361 - val_acc: 0.2367\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4691 - acc: 0.3943 - val_loss: 2.0313 - val_acc: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4678 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.4667 - acc: 0.4014 - val_loss: 2.0371 - val_acc: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4665 - acc: 0.4057 - val_loss: 2.0430 - val_acc: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4670 - acc: 0.4000 - val_loss: 2.0292 - val_acc: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4657 - acc: 0.3943 - val_loss: 2.0243 - val_acc: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4665 - acc: 0.4014 - val_loss: 2.0327 - val_acc: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.4635 - acc: 0.4000 - val_loss: 2.0464 - val_acc: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.4657 - acc: 0.4000 - val_loss: 2.0517 - val_acc: 0.2400\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4643 - acc: 0.3971 - val_loss: 2.0295 - val_acc: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4647 - acc: 0.4043 - val_loss: 2.0262 - val_acc: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4638 - acc: 0.4000 - val_loss: 2.0388 - val_acc: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4647 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2300\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.4632 - acc: 0.4086 - val_loss: 2.0365 - val_acc: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4654 - acc: 0.4000 - val_loss: 2.0342 - val_acc: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4630 - acc: 0.3986 - val_loss: 2.0435 - val_acc: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4637 - acc: 0.4057 - val_loss: 2.0446 - val_acc: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4621 - acc: 0.4000 - val_loss: 2.0385 - val_acc: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4614 - acc: 0.4114 - val_loss: 2.0554 - val_acc: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4631 - acc: 0.4029 - val_loss: 2.0380 - val_acc: 0.2333\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4614 - acc: 0.4029 - val_loss: 2.0413 - val_acc: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4612 - acc: 0.4014 - val_loss: 2.0446 - val_acc: 0.2567\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4623 - acc: 0.4100 - val_loss: 2.0394 - val_acc: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4619 - acc: 0.4029 - val_loss: 2.0325 - val_acc: 0.2300\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4613 - acc: 0.4000 - val_loss: 2.0365 - val_acc: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 508us/step - loss: 1.4611 - acc: 0.4071 - val_loss: 2.0515 - val_acc: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4603 - acc: 0.4043 - val_loss: 2.0375 - val_acc: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4620 - acc: 0.4100 - val_loss: 2.0473 - val_acc: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.4599 - acc: 0.4171 - val_loss: 2.0504 - val_acc: 0.2300\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4598 - acc: 0.4057 - val_loss: 2.0486 - val_acc: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4594 - acc: 0.4057 - val_loss: 2.0432 - val_acc: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4586 - acc: 0.4114 - val_loss: 2.0507 - val_acc: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4588 - acc: 0.4043 - val_loss: 2.0480 - val_acc: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.4580 - acc: 0.4014 - val_loss: 2.0397 - val_acc: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0551 - val_acc: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4597 - acc: 0.4043 - val_loss: 2.0408 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4597 - acc: 0.4114 - val_loss: 2.0449 - val_acc: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4586 - acc: 0.3957 - val_loss: 2.0468 - val_acc: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4583 - acc: 0.4014 - val_loss: 2.0449 - val_acc: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.4577 - acc: 0.4071 - val_loss: 2.0453 - val_acc: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4584 - acc: 0.4057 - val_loss: 2.0428 - val_acc: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4574 - acc: 0.4086 - val_loss: 2.0531 - val_acc: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4570 - acc: 0.4071 - val_loss: 2.0488 - val_acc: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4569 - acc: 0.4071 - val_loss: 2.0513 - val_acc: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4563 - acc: 0.4014 - val_loss: 2.0529 - val_acc: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4571 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4558 - acc: 0.4100 - val_loss: 2.0556 - val_acc: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4549 - acc: 0.4043 - val_loss: 2.0555 - val_acc: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4573 - acc: 0.4114 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4560 - acc: 0.4043 - val_loss: 2.0581 - val_acc: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4553 - acc: 0.4057 - val_loss: 2.0576 - val_acc: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4553 - acc: 0.4014 - val_loss: 2.0520 - val_acc: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4554 - acc: 0.4086 - val_loss: 2.0605 - val_acc: 0.2267\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4544 - acc: 0.4086 - val_loss: 2.0557 - val_acc: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4546 - acc: 0.4057 - val_loss: 2.0498 - val_acc: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4540 - acc: 0.4129 - val_loss: 2.0513 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.4543 - acc: 0.4057 - val_loss: 2.0569 - val_acc: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.4537 - acc: 0.4129 - val_loss: 2.0472 - val_acc: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0491 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4537 - acc: 0.3986 - val_loss: 2.0563 - val_acc: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4541 - acc: 0.4043 - val_loss: 2.0478 - val_acc: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4525 - acc: 0.4143 - val_loss: 2.0625 - val_acc: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.4523 - acc: 0.4129 - val_loss: 2.0623 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4424 - acc: 0.404 - 0s 477us/step - loss: 1.4526 - acc: 0.4029 - val_loss: 2.0585 - val_acc: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.4527 - acc: 0.4114 - val_loss: 2.0504 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4525 - acc: 0.4029 - val_loss: 2.0489 - val_acc: 0.2433\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4516 - acc: 0.4057 - val_loss: 2.0553 - val_acc: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4517 - acc: 0.4100 - val_loss: 2.0474 - val_acc: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4518 - acc: 0.4100 - val_loss: 2.0580 - val_acc: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.4515 - acc: 0.4071 - val_loss: 2.0504 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4500 - acc: 0.4157 - val_loss: 2.0635 - val_acc: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4507 - acc: 0.4129 - val_loss: 2.0636 - val_acc: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4508 - acc: 0.4129 - val_loss: 2.0608 - val_acc: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4506 - acc: 0.4086 - val_loss: 2.0591 - val_acc: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4505 - acc: 0.4086 - val_loss: 2.0601 - val_acc: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.4496 - acc: 0.4129 - val_loss: 2.0686 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4502 - acc: 0.4129 - val_loss: 2.0535 - val_acc: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4495 - acc: 0.4129 - val_loss: 2.0732 - val_acc: 0.2333\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4480 - acc: 0.4157 - val_loss: 2.0653 - val_acc: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4491 - acc: 0.4014 - val_loss: 2.0597 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4479 - acc: 0.4114 - val_loss: 2.0671 - val_acc: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4488 - acc: 0.4171 - val_loss: 2.0564 - val_acc: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4487 - acc: 0.4129 - val_loss: 2.0741 - val_acc: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4476 - acc: 0.4114 - val_loss: 2.0741 - val_acc: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4471 - acc: 0.4186 - val_loss: 2.0690 - val_acc: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4455 - acc: 0.419 - 0s 496us/step - loss: 1.4480 - acc: 0.4171 - val_loss: 2.0689 - val_acc: 0.2367\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.4479 - acc: 0.4029 - val_loss: 2.0724 - val_acc: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4471 - acc: 0.4086 - val_loss: 2.0535 - val_acc: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4478 - acc: 0.4257 - val_loss: 2.0632 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4459 - acc: 0.4157 - val_loss: 2.0503 - val_acc: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4475 - acc: 0.4100 - val_loss: 2.0615 - val_acc: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4460 - acc: 0.4114 - val_loss: 2.0542 - val_acc: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4468 - acc: 0.4114 - val_loss: 2.0818 - val_acc: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4467 - acc: 0.4086 - val_loss: 2.0750 - val_acc: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.4455 - acc: 0.4143 - val_loss: 2.0829 - val_acc: 0.2367\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4457 - acc: 0.4129 - val_loss: 2.0715 - val_acc: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4444 - acc: 0.4071 - val_loss: 2.0653 - val_acc: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4463 - acc: 0.4129 - val_loss: 2.0669 - val_acc: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4451 - acc: 0.4114 - val_loss: 2.0764 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4452 - acc: 0.4114 - val_loss: 2.0816 - val_acc: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.4449 - acc: 0.4086 - val_loss: 2.0820 - val_acc: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4441 - acc: 0.4157 - val_loss: 2.0581 - val_acc: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4437 - acc: 0.4143 - val_loss: 2.0742 - val_acc: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4448 - acc: 0.4100 - val_loss: 2.0819 - val_acc: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4439 - acc: 0.4129 - val_loss: 2.0856 - val_acc: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4440 - acc: 0.4129 - val_loss: 2.0722 - val_acc: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4432 - acc: 0.4186 - val_loss: 2.0797 - val_acc: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4414 - acc: 0.4114 - val_loss: 2.0734 - val_acc: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4423 - acc: 0.4114 - val_loss: 2.0704 - val_acc: 0.2367\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4431 - acc: 0.4100 - val_loss: 2.0860 - val_acc: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4415 - acc: 0.4057 - val_loss: 2.0823 - val_acc: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4432 - acc: 0.4143 - val_loss: 2.0725 - val_acc: 0.2333\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.4418 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4430 - acc: 0.4114 - val_loss: 2.0737 - val_acc: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4415 - acc: 0.4171 - val_loss: 2.0781 - val_acc: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.4414 - acc: 0.4143 - val_loss: 2.0641 - val_acc: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4406 - acc: 0.4100 - val_loss: 2.0746 - val_acc: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4426 - acc: 0.4086 - val_loss: 2.0850 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4409 - acc: 0.4186 - val_loss: 2.0809 - val_acc: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4409 - acc: 0.4143 - val_loss: 2.0781 - val_acc: 0.2367\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4404 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4409 - acc: 0.4100 - val_loss: 2.0796 - val_acc: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.4418 - acc: 0.4086 - val_loss: 2.0753 - val_acc: 0.2367\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4410 - acc: 0.4000 - val_loss: 2.0794 - val_acc: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4402 - acc: 0.4157 - val_loss: 2.0953 - val_acc: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4394 - acc: 0.4186 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4396 - acc: 0.4114 - val_loss: 2.0887 - val_acc: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4390 - acc: 0.4200 - val_loss: 2.0808 - val_acc: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4406 - acc: 0.4114 - val_loss: 2.0751 - val_acc: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4375 - acc: 0.4157 - val_loss: 2.0902 - val_acc: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.4382 - acc: 0.4157 - val_loss: 2.0931 - val_acc: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4393 - acc: 0.4171 - val_loss: 2.0815 - val_acc: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0801 - val_acc: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4382 - acc: 0.4100 - val_loss: 2.0893 - val_acc: 0.2367\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4384 - acc: 0.4186 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4374 - acc: 0.4086 - val_loss: 2.1027 - val_acc: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4366 - acc: 0.4214 - val_loss: 2.1019 - val_acc: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0800 - val_acc: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4360 - acc: 0.4143 - val_loss: 2.0972 - val_acc: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4355 - acc: 0.4200 - val_loss: 2.0724 - val_acc: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4369 - acc: 0.4257 - val_loss: 2.0890 - val_acc: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4377 - acc: 0.4157 - val_loss: 2.0891 - val_acc: 0.2400\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4370 - acc: 0.4186 - val_loss: 2.0805 - val_acc: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.4360 - acc: 0.4214 - val_loss: 2.0854 - val_acc: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.4356 - acc: 0.4129 - val_loss: 2.0779 - val_acc: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4330 - acc: 0.4143 - val_loss: 2.0887 - val_acc: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.4356 - acc: 0.4143 - val_loss: 2.0846 - val_acc: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4352 - acc: 0.4200 - val_loss: 2.1067 - val_acc: 0.2533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4354 - acc: 0.4143 - val_loss: 2.0772 - val_acc: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4355 - acc: 0.4157 - val_loss: 2.0829 - val_acc: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4348 - acc: 0.4200 - val_loss: 2.0925 - val_acc: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4345 - acc: 0.4143 - val_loss: 2.0995 - val_acc: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4337 - acc: 0.4229 - val_loss: 2.0944 - val_acc: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4339 - acc: 0.4186 - val_loss: 2.0823 - val_acc: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4345 - acc: 0.4171 - val_loss: 2.0821 - val_acc: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4335 - acc: 0.4186 - val_loss: 2.1067 - val_acc: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4348 - acc: 0.4171 - val_loss: 2.0871 - val_acc: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.4376 - acc: 0.433 - 0s 487us/step - loss: 1.4324 - acc: 0.4214 - val_loss: 2.0991 - val_acc: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4337 - acc: 0.4186 - val_loss: 2.1061 - val_acc: 0.2467\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.4333 - acc: 0.4257 - val_loss: 2.0948 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4328 - acc: 0.4214 - val_loss: 2.0957 - val_acc: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4329 - acc: 0.4200 - val_loss: 2.0952 - val_acc: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4316 - acc: 0.4171 - val_loss: 2.0921 - val_acc: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4327 - acc: 0.4129 - val_loss: 2.0981 - val_acc: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4316 - acc: 0.4229 - val_loss: 2.1061 - val_acc: 0.2333\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4325 - acc: 0.4214 - val_loss: 2.0935 - val_acc: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4320 - acc: 0.4157 - val_loss: 2.0879 - val_acc: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4321 - acc: 0.4214 - val_loss: 2.0806 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4315 - acc: 0.4243 - val_loss: 2.0931 - val_acc: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4316 - acc: 0.4214 - val_loss: 2.0923 - val_acc: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 1.4296 - acc: 0.4186 - val_loss: 2.1160 - val_acc: 0.2533\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.4314 - acc: 0.4229 - val_loss: 2.0957 - val_acc: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 576us/step - loss: 1.4304 - acc: 0.4186 - val_loss: 2.0964 - val_acc: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 576us/step - loss: 1.4300 - acc: 0.4214 - val_loss: 2.1035 - val_acc: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 583us/step - loss: 1.4310 - acc: 0.4186 - val_loss: 2.0861 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 587us/step - loss: 1.4305 - acc: 0.4243 - val_loss: 2.0996 - val_acc: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.4282 - acc: 0.4243 - val_loss: 2.0936 - val_acc: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.4305 - acc: 0.4157 - val_loss: 2.1060 - val_acc: 0.2367\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4297 - acc: 0.4157 - val_loss: 2.1014 - val_acc: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.4289 - acc: 0.4186 - val_loss: 2.1246 - val_acc: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4303 - acc: 0.4186 - val_loss: 2.1100 - val_acc: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4295 - acc: 0.4214 - val_loss: 2.1052 - val_acc: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4291 - acc: 0.4200 - val_loss: 2.1038 - val_acc: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.4286 - acc: 0.4200 - val_loss: 2.1045 - val_acc: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4282 - acc: 0.4214 - val_loss: 2.0911 - val_acc: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4281 - acc: 0.4257 - val_loss: 2.1101 - val_acc: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4277 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.4278 - acc: 0.4257 - val_loss: 2.0962 - val_acc: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.4273 - acc: 0.4214 - val_loss: 2.1264 - val_acc: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4276 - acc: 0.4200 - val_loss: 2.0961 - val_acc: 0.2400\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4269 - acc: 0.4229 - val_loss: 2.1197 - val_acc: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4269 - acc: 0.4257 - val_loss: 2.1247 - val_acc: 0.2400\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4277 - acc: 0.4143 - val_loss: 2.1096 - val_acc: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4261 - acc: 0.4243 - val_loss: 2.1076 - val_acc: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4263 - acc: 0.4286 - val_loss: 2.1008 - val_acc: 0.2400\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.4271 - acc: 0.4214 - val_loss: 2.1178 - val_acc: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4261 - acc: 0.4286 - val_loss: 2.1092 - val_acc: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4249 - acc: 0.4300 - val_loss: 2.1022 - val_acc: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4265 - acc: 0.4229 - val_loss: 2.1194 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4265 - acc: 0.4200 - val_loss: 2.1078 - val_acc: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4251 - acc: 0.4271 - val_loss: 2.1167 - val_acc: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.4250 - acc: 0.4314 - val_loss: 2.1048 - val_acc: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 584us/step - loss: 1.4249 - acc: 0.4200 - val_loss: 2.1189 - val_acc: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4252 - acc: 0.4143 - val_loss: 2.1010 - val_acc: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4240 - acc: 0.4286 - val_loss: 2.1042 - val_acc: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4257 - acc: 0.4186 - val_loss: 2.1045 - val_acc: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4221 - acc: 0.4329 - val_loss: 2.1158 - val_acc: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4254 - acc: 0.4300 - val_loss: 2.1062 - val_acc: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4251 - acc: 0.4157 - val_loss: 2.1123 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4233 - acc: 0.4257 - val_loss: 2.1289 - val_acc: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.4222 - acc: 0.4271 - val_loss: 2.0960 - val_acc: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4239 - acc: 0.4329 - val_loss: 2.1004 - val_acc: 0.2300\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.4224 - acc: 0.4171 - val_loss: 2.1130 - val_acc: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.4233 - acc: 0.4243 - val_loss: 2.1173 - val_acc: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4223 - acc: 0.4257 - val_loss: 2.1337 - val_acc: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4235 - acc: 0.4271 - val_loss: 2.1186 - val_acc: 0.2333\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4221 - acc: 0.4386 - val_loss: 2.1169 - val_acc: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.4223 - acc: 0.4143 - val_loss: 2.1151 - val_acc: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.4233 - acc: 0.4200 - val_loss: 2.1210 - val_acc: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4220 - acc: 0.4300 - val_loss: 2.1190 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4221 - acc: 0.4271 - val_loss: 2.1112 - val_acc: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4218 - acc: 0.4329 - val_loss: 2.1117 - val_acc: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 586us/step - loss: 1.4215 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4225 - acc: 0.4257 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 678us/step - loss: 1.4215 - acc: 0.4200 - val_loss: 2.1152 - val_acc: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4227 - acc: 0.4300 - val_loss: 2.1314 - val_acc: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4203 - acc: 0.4214 - val_loss: 2.1405 - val_acc: 0.2333\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 450us/step - loss: 1.4217 - acc: 0.4214 - val_loss: 2.1154 - val_acc: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.4217 - acc: 0.4257 - val_loss: 2.1160 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.4205 - acc: 0.4257 - val_loss: 2.1068 - val_acc: 0.2400\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4207 - acc: 0.4243 - val_loss: 2.1165 - val_acc: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4200 - acc: 0.4214 - val_loss: 2.1088 - val_acc: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1229 - val_acc: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4202 - acc: 0.4229 - val_loss: 2.1255 - val_acc: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.4200 - acc: 0.4229 - val_loss: 2.1326 - val_acc: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4191 - acc: 0.4243 - val_loss: 2.1295 - val_acc: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4182 - acc: 0.4286 - val_loss: 2.1295 - val_acc: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4193 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4177 - acc: 0.4314 - val_loss: 2.1345 - val_acc: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.4190 - acc: 0.4214 - val_loss: 2.1203 - val_acc: 0.2333\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4191 - acc: 0.4300 - val_loss: 2.1231 - val_acc: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4190 - acc: 0.4229 - val_loss: 2.1167 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4196 - acc: 0.4214 - val_loss: 2.1239 - val_acc: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.4184 - acc: 0.4257 - val_loss: 2.1057 - val_acc: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.4186 - acc: 0.4329 - val_loss: 2.1295 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4181 - acc: 0.4300 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.4179 - acc: 0.4271 - val_loss: 2.1419 - val_acc: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4180 - acc: 0.4271 - val_loss: 2.1251 - val_acc: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4184 - acc: 0.4243 - val_loss: 2.1135 - val_acc: 0.2500\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4178 - acc: 0.4271 - val_loss: 2.1248 - val_acc: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4173 - acc: 0.4229 - val_loss: 2.1256 - val_acc: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4174 - acc: 0.4314 - val_loss: 2.1284 - val_acc: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4164 - acc: 0.4286 - val_loss: 2.1302 - val_acc: 0.2500\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4171 - acc: 0.4229 - val_loss: 2.1204 - val_acc: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4166 - acc: 0.4257 - val_loss: 2.1365 - val_acc: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4169 - acc: 0.4271 - val_loss: 2.1308 - val_acc: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4164 - acc: 0.4314 - val_loss: 2.1278 - val_acc: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4160 - acc: 0.4300 - val_loss: 2.1290 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.4164 - acc: 0.4200 - val_loss: 2.1355 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4162 - acc: 0.4386 - val_loss: 2.1362 - val_acc: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4152 - acc: 0.4329 - val_loss: 2.1291 - val_acc: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 1.4159 - acc: 0.4200 - val_loss: 2.1378 - val_acc: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.4159 - acc: 0.4329 - val_loss: 2.1350 - val_acc: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4158 - acc: 0.4329 - val_loss: 2.1718 - val_acc: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4146 - acc: 0.4271 - val_loss: 2.1338 - val_acc: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.4148 - acc: 0.4243 - val_loss: 2.1272 - val_acc: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 561us/step - loss: 1.4143 - acc: 0.4329 - val_loss: 2.1285 - val_acc: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4148 - acc: 0.4357 - val_loss: 2.1285 - val_acc: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4148 - acc: 0.4386 - val_loss: 2.1343 - val_acc: 0.2500\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.4143 - acc: 0.4314 - val_loss: 2.1340 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4150 - acc: 0.4229 - val_loss: 2.1349 - val_acc: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4139 - acc: 0.4357 - val_loss: 2.1360 - val_acc: 0.2367\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4142 - acc: 0.4314 - val_loss: 2.1368 - val_acc: 0.2400\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.4141 - acc: 0.4271 - val_loss: 2.1261 - val_acc: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.4139 - acc: 0.4329 - val_loss: 2.1430 - val_acc: 0.2400\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4131 - acc: 0.4286 - val_loss: 2.1356 - val_acc: 0.2533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.4139 - acc: 0.4314 - val_loss: 2.1410 - val_acc: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4136 - acc: 0.4300 - val_loss: 2.1348 - val_acc: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 577us/step - loss: 1.4116 - acc: 0.4300 - val_loss: 2.1359 - val_acc: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4123 - acc: 0.4286 - val_loss: 2.1431 - val_acc: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.4110 - acc: 0.4357 - val_loss: 2.1535 - val_acc: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 583us/step - loss: 1.4131 - acc: 0.4329 - val_loss: 2.1379 - val_acc: 0.2567\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4129 - acc: 0.4300 - val_loss: 2.1497 - val_acc: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4130 - acc: 0.4329 - val_loss: 2.1381 - val_acc: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.4114 - acc: 0.4271 - val_loss: 2.1430 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.4110 - acc: 0.4300 - val_loss: 2.1438 - val_acc: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4112 - acc: 0.4314 - val_loss: 2.1583 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.4122 - acc: 0.4271 - val_loss: 2.1483 - val_acc: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4112 - acc: 0.4300 - val_loss: 2.1481 - val_acc: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.4118 - acc: 0.4343 - val_loss: 2.1369 - val_acc: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.4111 - acc: 0.4314 - val_loss: 2.1411 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.4104 - acc: 0.4271 - val_loss: 2.1457 - val_acc: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4105 - acc: 0.4443 - val_loss: 2.1591 - val_acc: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 625us/step - loss: 1.4111 - acc: 0.4343 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.4110 - acc: 0.4243 - val_loss: 2.1645 - val_acc: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.4106 - acc: 0.4329 - val_loss: 2.1743 - val_acc: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4095 - acc: 0.4300 - val_loss: 2.1435 - val_acc: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1518 - val_acc: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.4102 - acc: 0.4300 - val_loss: 2.1380 - val_acc: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4107 - acc: 0.4329 - val_loss: 2.1500 - val_acc: 0.2367\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.4088 - acc: 0.4300 - val_loss: 2.1492 - val_acc: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.4081 - acc: 0.4343 - val_loss: 2.1386 - val_acc: 0.2433\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4092 - acc: 0.4371 - val_loss: 2.1470 - val_acc: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.4098 - acc: 0.4271 - val_loss: 2.1594 - val_acc: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 641us/step - loss: 1.4090 - acc: 0.4314 - val_loss: 2.1468 - val_acc: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.4082 - acc: 0.4300 - val_loss: 2.1617 - val_acc: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 581us/step - loss: 1.4088 - acc: 0.4314 - val_loss: 2.1402 - val_acc: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4092 - acc: 0.4357 - val_loss: 2.1484 - val_acc: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4075 - acc: 0.4229 - val_loss: 2.1584 - val_acc: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.4079 - acc: 0.4371 - val_loss: 2.1529 - val_acc: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.4086 - acc: 0.4300 - val_loss: 2.1555 - val_acc: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.4071 - acc: 0.4314 - val_loss: 2.1484 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4071 - acc: 0.4229 - val_loss: 2.1482 - val_acc: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.4086 - acc: 0.4371 - val_loss: 2.1509 - val_acc: 0.2433\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.4066 - acc: 0.4329 - val_loss: 2.1501 - val_acc: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.4046 - acc: 0.4371 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.4074 - acc: 0.4271 - val_loss: 2.1510 - val_acc: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.4074 - acc: 0.4357 - val_loss: 2.1598 - val_acc: 0.2500\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 607us/step - loss: 1.4067 - acc: 0.4286 - val_loss: 2.1580 - val_acc: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4066 - acc: 0.4343 - val_loss: 2.1567 - val_acc: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1554 - val_acc: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 594us/step - loss: 1.4057 - acc: 0.4357 - val_loss: 2.1783 - val_acc: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 584us/step - loss: 1.4064 - acc: 0.4343 - val_loss: 2.1655 - val_acc: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.4071 - acc: 0.4271 - val_loss: 2.1672 - val_acc: 0.2533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.4055 - acc: 0.4329 - val_loss: 2.1677 - val_acc: 0.2500\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.4053 - acc: 0.4329 - val_loss: 2.1628 - val_acc: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.4047 - acc: 0.4386 - val_loss: 2.1682 - val_acc: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4049 - acc: 0.4314 - val_loss: 2.1387 - val_acc: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.4052 - acc: 0.4357 - val_loss: 2.1681 - val_acc: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.4054 - acc: 0.4357 - val_loss: 2.1608 - val_acc: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 601us/step - loss: 1.4050 - acc: 0.4386 - val_loss: 2.1594 - val_acc: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4034 - acc: 0.4357 - val_loss: 2.1720 - val_acc: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.4048 - acc: 0.4314 - val_loss: 2.1759 - val_acc: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.4037 - acc: 0.4357 - val_loss: 2.1607 - val_acc: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1424 - val_acc: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 601us/step - loss: 1.4048 - acc: 0.4329 - val_loss: 2.1525 - val_acc: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.4038 - acc: 0.4329 - val_loss: 2.1739 - val_acc: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 584us/step - loss: 1.4035 - acc: 0.4314 - val_loss: 2.1520 - val_acc: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.4037 - acc: 0.4271 - val_loss: 2.1733 - val_acc: 0.2367\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4042 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2400\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.4012 - acc: 0.4371 - val_loss: 2.1696 - val_acc: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4051 - acc: 0.4329 - val_loss: 2.1589 - val_acc: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4035 - acc: 0.4429 - val_loss: 2.1855 - val_acc: 0.2500\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.4035 - acc: 0.4371 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.4044 - acc: 0.4286 - val_loss: 2.1476 - val_acc: 0.2400\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.4027 - acc: 0.4314 - val_loss: 2.1799 - val_acc: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.4031 - acc: 0.4314 - val_loss: 2.1444 - val_acc: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.4036 - acc: 0.4386 - val_loss: 2.1664 - val_acc: 0.2467\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 590us/step - loss: 1.4026 - acc: 0.4371 - val_loss: 2.1546 - val_acc: 0.2367\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 564us/step - loss: 1.4027 - acc: 0.4357 - val_loss: 2.1653 - val_acc: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.4010 - acc: 0.4443 - val_loss: 2.1763 - val_acc: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 671us/step - loss: 1.4028 - acc: 0.4386 - val_loss: 2.1675 - val_acc: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.4024 - acc: 0.4271 - val_loss: 2.1707 - val_acc: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.4024 - acc: 0.4357 - val_loss: 2.1736 - val_acc: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.4018 - acc: 0.4357 - val_loss: 2.1794 - val_acc: 0.2433\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.4020 - acc: 0.4429 - val_loss: 2.1670 - val_acc: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.4012 - acc: 0.4343 - val_loss: 2.1696 - val_acc: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 597us/step - loss: 1.4014 - acc: 0.4357 - val_loss: 2.1745 - val_acc: 0.2600\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.4017 - acc: 0.4343 - val_loss: 2.1688 - val_acc: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 558us/step - loss: 1.4011 - acc: 0.4386 - val_loss: 2.1869 - val_acc: 0.2467\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.4015 - acc: 0.4343 - val_loss: 2.1634 - val_acc: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.4001 - acc: 0.4471 - val_loss: 2.1660 - val_acc: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.3999 - acc: 0.4400 - val_loss: 2.1780 - val_acc: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 584us/step - loss: 1.4001 - acc: 0.4343 - val_loss: 2.1718 - val_acc: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3992 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3991 - acc: 0.4357 - val_loss: 2.1637 - val_acc: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.4010 - acc: 0.4400 - val_loss: 2.1595 - val_acc: 0.2400\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3998 - acc: 0.4371 - val_loss: 2.1560 - val_acc: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.4003 - acc: 0.4386 - val_loss: 2.1815 - val_acc: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3997 - acc: 0.4414 - val_loss: 2.1730 - val_acc: 0.2433\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3993 - acc: 0.4329 - val_loss: 2.1789 - val_acc: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.4004 - acc: 0.4357 - val_loss: 2.1613 - val_acc: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3991 - acc: 0.4371 - val_loss: 2.1790 - val_acc: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3995 - acc: 0.4400 - val_loss: 2.1687 - val_acc: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.4000 - acc: 0.4371 - val_loss: 2.1881 - val_acc: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3988 - acc: 0.4386 - val_loss: 2.1862 - val_acc: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3990 - acc: 0.4343 - val_loss: 2.1746 - val_acc: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3987 - acc: 0.4386 - val_loss: 2.1795 - val_acc: 0.2400\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3978 - acc: 0.4400 - val_loss: 2.1797 - val_acc: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3970 - acc: 0.4386 - val_loss: 2.1789 - val_acc: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3984 - acc: 0.4329 - val_loss: 2.1871 - val_acc: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3988 - acc: 0.4343 - val_loss: 2.1695 - val_acc: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3984 - acc: 0.4357 - val_loss: 2.1721 - val_acc: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3967 - acc: 0.4400 - val_loss: 2.1838 - val_acc: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3966 - acc: 0.4386 - val_loss: 2.1709 - val_acc: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3988 - acc: 0.4414 - val_loss: 2.1766 - val_acc: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3970 - acc: 0.4343 - val_loss: 2.1822 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3972 - acc: 0.4443 - val_loss: 2.1771 - val_acc: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3975 - acc: 0.4357 - val_loss: 2.1778 - val_acc: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3971 - acc: 0.4400 - val_loss: 2.1921 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3971 - acc: 0.4414 - val_loss: 2.1917 - val_acc: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3971 - acc: 0.4357 - val_loss: 2.1789 - val_acc: 0.2467\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3967 - acc: 0.4329 - val_loss: 2.1803 - val_acc: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3962 - acc: 0.4400 - val_loss: 2.1716 - val_acc: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3966 - acc: 0.4314 - val_loss: 2.1818 - val_acc: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3958 - acc: 0.4414 - val_loss: 2.1874 - val_acc: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3966 - acc: 0.4414 - val_loss: 2.1846 - val_acc: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3965 - acc: 0.4429 - val_loss: 2.1883 - val_acc: 0.2500\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3960 - acc: 0.4400 - val_loss: 2.1831 - val_acc: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3953 - acc: 0.4443 - val_loss: 2.1899 - val_acc: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3953 - acc: 0.4386 - val_loss: 2.1980 - val_acc: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3960 - acc: 0.4343 - val_loss: 2.1790 - val_acc: 0.2400\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3957 - acc: 0.4343 - val_loss: 2.1841 - val_acc: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3947 - acc: 0.4357 - val_loss: 2.1692 - val_acc: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3955 - acc: 0.4414 - val_loss: 2.1922 - val_acc: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 446us/step - loss: 1.3944 - acc: 0.4371 - val_loss: 2.1942 - val_acc: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3947 - acc: 0.4329 - val_loss: 2.1898 - val_acc: 0.2500\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3945 - acc: 0.4329 - val_loss: 2.1833 - val_acc: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3939 - acc: 0.4414 - val_loss: 2.1935 - val_acc: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3940 - acc: 0.4300 - val_loss: 2.1744 - val_acc: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3938 - acc: 0.4471 - val_loss: 2.1834 - val_acc: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3929 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2367\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3940 - acc: 0.4429 - val_loss: 2.1889 - val_acc: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3938 - acc: 0.4414 - val_loss: 2.1852 - val_acc: 0.2467\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3935 - acc: 0.4371 - val_loss: 2.1988 - val_acc: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3940 - acc: 0.4471 - val_loss: 2.1858 - val_acc: 0.2567\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3936 - acc: 0.4429 - val_loss: 2.1951 - val_acc: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.3928 - acc: 0.4386 - val_loss: 2.2024 - val_acc: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3925 - acc: 0.4414 - val_loss: 2.1847 - val_acc: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3938 - acc: 0.4343 - val_loss: 2.2130 - val_acc: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3936 - acc: 0.4414 - val_loss: 2.1808 - val_acc: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3930 - acc: 0.4400 - val_loss: 2.1918 - val_acc: 0.2467\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1688 - val_acc: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3931 - acc: 0.4400 - val_loss: 2.1895 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3926 - acc: 0.4386 - val_loss: 2.1845 - val_acc: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3919 - acc: 0.4357 - val_loss: 2.1782 - val_acc: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3913 - acc: 0.4414 - val_loss: 2.1849 - val_acc: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3924 - acc: 0.4429 - val_loss: 2.1969 - val_acc: 0.2567\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3923 - acc: 0.4429 - val_loss: 2.1947 - val_acc: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3913 - acc: 0.4400 - val_loss: 2.1865 - val_acc: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3917 - acc: 0.4414 - val_loss: 2.1907 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 566us/step - loss: 1.3916 - acc: 0.4400 - val_loss: 2.2006 - val_acc: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3916 - acc: 0.4414 - val_loss: 2.1862 - val_acc: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3913 - acc: 0.4386 - val_loss: 2.2011 - val_acc: 0.2333\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.3901 - acc: 0.4400 - val_loss: 2.1959 - val_acc: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3908 - acc: 0.4386 - val_loss: 2.1971 - val_acc: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3907 - acc: 0.4443 - val_loss: 2.2058 - val_acc: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3905 - acc: 0.4429 - val_loss: 2.1920 - val_acc: 0.2500\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3905 - acc: 0.4343 - val_loss: 2.1915 - val_acc: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3904 - acc: 0.4486 - val_loss: 2.1936 - val_acc: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.1917 - val_acc: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3906 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3894 - acc: 0.4371 - val_loss: 2.2124 - val_acc: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3902 - acc: 0.4400 - val_loss: 2.1965 - val_acc: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3897 - acc: 0.4357 - val_loss: 2.2004 - val_acc: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3898 - acc: 0.4414 - val_loss: 2.1945 - val_acc: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3891 - acc: 0.4400 - val_loss: 2.2033 - val_acc: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3891 - acc: 0.4414 - val_loss: 2.2010 - val_acc: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3887 - acc: 0.4414 - val_loss: 2.1880 - val_acc: 0.2400\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3886 - acc: 0.4429 - val_loss: 2.2116 - val_acc: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3903 - acc: 0.4357 - val_loss: 2.2104 - val_acc: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3887 - acc: 0.4443 - val_loss: 2.2221 - val_acc: 0.2533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3890 - acc: 0.4471 - val_loss: 2.1938 - val_acc: 0.2433\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3888 - acc: 0.4371 - val_loss: 2.2048 - val_acc: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3885 - acc: 0.4457 - val_loss: 2.2089 - val_acc: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3885 - acc: 0.4357 - val_loss: 2.1919 - val_acc: 0.2367\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3890 - acc: 0.4429 - val_loss: 2.2041 - val_acc: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3877 - acc: 0.4457 - val_loss: 2.2035 - val_acc: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 591us/step - loss: 1.3879 - acc: 0.4429 - val_loss: 2.2026 - val_acc: 0.2533\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3887 - acc: 0.4386 - val_loss: 2.2113 - val_acc: 0.2533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3881 - acc: 0.4386 - val_loss: 2.2013 - val_acc: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 574us/step - loss: 1.3879 - acc: 0.4386 - val_loss: 2.2080 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 50us/step\n",
      "loss and metrics:[2.25819593334198, 0.2657]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics=model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('loss and metrics:'+str(loss_and_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"211pt\" viewBox=\"0.00 0.00 251.00 211.00\" width=\"251pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 207)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-207 247,-207 247,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2110176408632 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2110176408632</title>\n",
       "<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 243,-129.5 243,-83.5 0,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"52\" y=\"-102.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"104,-83.5 104,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"104,-106.5 160,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"132\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"160,-83.5 160,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-114.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"160,-106.5 243,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-91.3\">(None, 64)</text>\n",
       "</g>\n",
       "<!-- 2110176409752 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2110176409752</title>\n",
       "<polygon fill=\"none\" points=\"3,-0.5 3,-46.5 240,-46.5 240,-0.5 3,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"55\" y=\"-19.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"107,-0.5 107,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"107,-23.5 163,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"135\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"163,-0.5 163,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-31.3\">(None, 64)</text>\n",
       "<polyline fill=\"none\" points=\"163,-23.5 240,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201.5\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 2110176408632&#45;&gt;2110176409752 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2110176408632-&gt;2110176409752</title>\n",
       "<path d=\"M121.5,-83.3664C121.5,-75.1516 121.5,-65.6579 121.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125,-56.6068 121.5,-46.6068 118,-56.6069 125,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2110176410032 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2110176410032</title>\n",
       "<polygon fill=\"none\" points=\"69.5,-166.5 69.5,-202.5 173.5,-202.5 173.5,-166.5 69.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-180.8\">2110176410032</text>\n",
       "</g>\n",
       "<!-- 2110176410032&#45;&gt;2110176408632 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2110176410032-&gt;2110176408632</title>\n",
       "<path d=\"M121.5,-166.254C121.5,-158.363 121.5,-148.749 121.5,-139.602\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125,-139.591 121.5,-129.591 118,-139.591 125,-139.591\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('mnist_mlp_model.h5')\n",
    "model=load_model('mnist_mlp_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23ebe5b4b38>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Programing\\Anaconda3\\envs\\tf1_env\\lib\\site-packages\\keras\\callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 594us/step - loss: 1.3879 - acc: 0.4400 - val_loss: 2.2093 - val_acc: 0.2400\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3880 - acc: 0.4400 - val_loss: 2.2086 - val_acc: 0.2533\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.3865 - acc: 0.4457 - val_loss: 2.2155 - val_acc: 0.2567\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3869 - acc: 0.4386 - val_loss: 2.2161 - val_acc: 0.2433\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.3867 - acc: 0.4457 - val_loss: 2.2102 - val_acc: 0.2333\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3870 - acc: 0.4414 - val_loss: 2.2145 - val_acc: 0.2567\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3871 - acc: 0.4386 - val_loss: 2.2068 - val_acc: 0.2533\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3857 - acc: 0.4486 - val_loss: 2.2231 - val_acc: 0.2333\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3862 - acc: 0.4329 - val_loss: 2.2017 - val_acc: 0.2533\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3856 - acc: 0.4457 - val_loss: 2.2128 - val_acc: 0.2567\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 583us/step - loss: 1.3864 - acc: 0.4429 - val_loss: 2.2039 - val_acc: 0.2533\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3865 - acc: 0.4371 - val_loss: 2.2071 - val_acc: 0.2533\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 451us/step - loss: 1.3861 - acc: 0.4443 - val_loss: 2.2039 - val_acc: 0.2433\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.3855 - acc: 0.4500 - val_loss: 2.1987 - val_acc: 0.2400\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.3856 - acc: 0.4443 - val_loss: 2.2131 - val_acc: 0.2533\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.3860 - acc: 0.4414 - val_loss: 2.2116 - val_acc: 0.2500\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3849 - acc: 0.4429 - val_loss: 2.2087 - val_acc: 0.2467\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3850 - acc: 0.4457 - val_loss: 2.2113 - val_acc: 0.2567\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3861 - acc: 0.4400 - val_loss: 2.2047 - val_acc: 0.2433\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3849 - acc: 0.4457 - val_loss: 2.2214 - val_acc: 0.2467\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3856 - acc: 0.4443 - val_loss: 2.2072 - val_acc: 0.2533\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 562us/step - loss: 1.3856 - acc: 0.4429 - val_loss: 2.2065 - val_acc: 0.2500\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3847 - acc: 0.4386 - val_loss: 2.2234 - val_acc: 0.2533\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.3849 - acc: 0.4386 - val_loss: 2.1959 - val_acc: 0.2333\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3841 - acc: 0.4400 - val_loss: 2.2083 - val_acc: 0.2400\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3836 - acc: 0.4400 - val_loss: 2.1890 - val_acc: 0.2333\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3847 - acc: 0.4386 - val_loss: 2.2103 - val_acc: 0.2500\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3850 - acc: 0.4471 - val_loss: 2.2028 - val_acc: 0.2533\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3832 - acc: 0.4414 - val_loss: 2.2102 - val_acc: 0.2400\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3837 - acc: 0.4443 - val_loss: 2.2251 - val_acc: 0.2500\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 528us/step - loss: 1.3834 - acc: 0.4500 - val_loss: 2.2037 - val_acc: 0.2467\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3844 - acc: 0.4400 - val_loss: 2.2158 - val_acc: 0.2533\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3818 - acc: 0.4414 - val_loss: 2.2060 - val_acc: 0.2367\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.3837 - acc: 0.4429 - val_loss: 2.2123 - val_acc: 0.2433\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3838 - acc: 0.4400 - val_loss: 2.2063 - val_acc: 0.2433\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3824 - acc: 0.4486 - val_loss: 2.2118 - val_acc: 0.2533\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3837 - acc: 0.4429 - val_loss: 2.2143 - val_acc: 0.2500\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3824 - acc: 0.4429 - val_loss: 2.2243 - val_acc: 0.2433\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3841 - acc: 0.4429 - val_loss: 2.2066 - val_acc: 0.2433\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3821 - acc: 0.4486 - val_loss: 2.2099 - val_acc: 0.2500\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3827 - acc: 0.4386 - val_loss: 2.2176 - val_acc: 0.2567\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.3828 - acc: 0.4386 - val_loss: 2.2151 - val_acc: 0.2533\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3815 - acc: 0.4457 - val_loss: 2.2218 - val_acc: 0.2333\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3834 - acc: 0.4486 - val_loss: 2.2104 - val_acc: 0.2467\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3831 - acc: 0.4471 - val_loss: 2.2180 - val_acc: 0.2500\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3813 - acc: 0.4429 - val_loss: 2.2336 - val_acc: 0.2300\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3824 - acc: 0.4471 - val_loss: 2.2047 - val_acc: 0.2433\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3818 - acc: 0.4514 - val_loss: 2.2105 - val_acc: 0.2433\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3817 - acc: 0.4471 - val_loss: 2.2069 - val_acc: 0.2500\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3806 - acc: 0.4500 - val_loss: 2.2323 - val_acc: 0.2567\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3817 - acc: 0.4414 - val_loss: 2.2142 - val_acc: 0.2367\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3817 - acc: 0.4400 - val_loss: 2.2200 - val_acc: 0.2567\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3810 - acc: 0.4386 - val_loss: 2.2076 - val_acc: 0.2533\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3815 - acc: 0.4457 - val_loss: 2.2183 - val_acc: 0.2533\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.3807 - acc: 0.4500 - val_loss: 2.2388 - val_acc: 0.2467\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3810 - acc: 0.4529 - val_loss: 2.2213 - val_acc: 0.2433\n",
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3800 - acc: 0.4443 - val_loss: 2.1985 - val_acc: 0.2433\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3807 - acc: 0.4443 - val_loss: 2.2162 - val_acc: 0.2500\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3807 - acc: 0.4471 - val_loss: 2.2108 - val_acc: 0.2367\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3799 - acc: 0.4471 - val_loss: 2.2356 - val_acc: 0.2567\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.3805 - acc: 0.4414 - val_loss: 2.2241 - val_acc: 0.2533\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3795 - acc: 0.4500 - val_loss: 2.2459 - val_acc: 0.2567\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3803 - acc: 0.4457 - val_loss: 2.2337 - val_acc: 0.2533\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3805 - acc: 0.4443 - val_loss: 2.2136 - val_acc: 0.2367\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3807 - acc: 0.4457 - val_loss: 2.2252 - val_acc: 0.2500\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3797 - acc: 0.4486 - val_loss: 2.2142 - val_acc: 0.2533\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3792 - acc: 0.4500 - val_loss: 2.2230 - val_acc: 0.2467\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.3791 - acc: 0.4543 - val_loss: 2.2406 - val_acc: 0.2500\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 465us/step - loss: 1.3804 - acc: 0.4443 - val_loss: 2.2083 - val_acc: 0.2467\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 518us/step - loss: 1.3796 - acc: 0.4500 - val_loss: 2.2231 - val_acc: 0.2533\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3787 - acc: 0.4443 - val_loss: 2.2191 - val_acc: 0.2400\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3797 - acc: 0.4486 - val_loss: 2.2227 - val_acc: 0.2433\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3788 - acc: 0.4457 - val_loss: 2.2252 - val_acc: 0.2500\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3793 - acc: 0.4486 - val_loss: 2.2204 - val_acc: 0.2500\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.3791 - acc: 0.4386 - val_loss: 2.2312 - val_acc: 0.2467\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3783 - acc: 0.4486 - val_loss: 2.2312 - val_acc: 0.2533\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3786 - acc: 0.4429 - val_loss: 2.2292 - val_acc: 0.2500\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 564us/step - loss: 1.3773 - acc: 0.4429 - val_loss: 2.2251 - val_acc: 0.2533\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3789 - acc: 0.4457 - val_loss: 2.2055 - val_acc: 0.2400\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3782 - acc: 0.4514 - val_loss: 2.2307 - val_acc: 0.2500\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3786 - acc: 0.4457 - val_loss: 2.2205 - val_acc: 0.2367\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3785 - acc: 0.4443 - val_loss: 2.2390 - val_acc: 0.2467\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 453us/step - loss: 1.3784 - acc: 0.4414 - val_loss: 2.2304 - val_acc: 0.2467\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3777 - acc: 0.4514 - val_loss: 2.2339 - val_acc: 0.2533\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3777 - acc: 0.4457 - val_loss: 2.2188 - val_acc: 0.2433\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3776 - acc: 0.4400 - val_loss: 2.2132 - val_acc: 0.2467\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.3774 - acc: 0.4529 - val_loss: 2.2155 - val_acc: 0.2500\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3765 - acc: 0.4457 - val_loss: 2.2379 - val_acc: 0.2367\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.3775 - acc: 0.4457 - val_loss: 2.2477 - val_acc: 0.2533\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.3771 - acc: 0.4457 - val_loss: 2.2164 - val_acc: 0.2467\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3763 - acc: 0.4457 - val_loss: 2.2377 - val_acc: 0.2500\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3767 - acc: 0.4500 - val_loss: 2.2325 - val_acc: 0.2533\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.3771 - acc: 0.4414 - val_loss: 2.2096 - val_acc: 0.2467\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3768 - acc: 0.4457 - val_loss: 2.2295 - val_acc: 0.2333\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 597us/step - loss: 1.3762 - acc: 0.4443 - val_loss: 2.2331 - val_acc: 0.2467\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3754 - acc: 0.4486 - val_loss: 2.2215 - val_acc: 0.2433\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3760 - acc: 0.4471 - val_loss: 2.2460 - val_acc: 0.2500\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3761 - acc: 0.4557 - val_loss: 2.2283 - val_acc: 0.2533\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3763 - acc: 0.4486 - val_loss: 2.2330 - val_acc: 0.2467\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3751 - acc: 0.4486 - val_loss: 2.2307 - val_acc: 0.2367\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3761 - acc: 0.4400 - val_loss: 2.2261 - val_acc: 0.2500\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3760 - acc: 0.4514 - val_loss: 2.2226 - val_acc: 0.2567\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3754 - acc: 0.4486 - val_loss: 2.2249 - val_acc: 0.2467\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.3762 - acc: 0.4457 - val_loss: 2.2338 - val_acc: 0.2533\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 475us/step - loss: 1.3746 - acc: 0.4400 - val_loss: 2.2165 - val_acc: 0.2433\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3751 - acc: 0.4457 - val_loss: 2.2326 - val_acc: 0.2333\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3759 - acc: 0.4486 - val_loss: 2.2304 - val_acc: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.3749 - acc: 0.4471 - val_loss: 2.2213 - val_acc: 0.2500\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3739 - acc: 0.4529 - val_loss: 2.2375 - val_acc: 0.2467\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3756 - acc: 0.4429 - val_loss: 2.2250 - val_acc: 0.2500\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3752 - acc: 0.4500 - val_loss: 2.2288 - val_acc: 0.2400\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3742 - acc: 0.4471 - val_loss: 2.2368 - val_acc: 0.2400\n",
      "Epoch 113/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3754 - acc: 0.4429 - val_loss: 2.2281 - val_acc: 0.2533\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3749 - acc: 0.4443 - val_loss: 2.2358 - val_acc: 0.2433\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3738 - acc: 0.4457 - val_loss: 2.2195 - val_acc: 0.2467\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3745 - acc: 0.4529 - val_loss: 2.2357 - val_acc: 0.2367\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3751 - acc: 0.4543 - val_loss: 2.2463 - val_acc: 0.2467\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3729 - acc: 0.4529 - val_loss: 2.2418 - val_acc: 0.2367\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3744 - acc: 0.4443 - val_loss: 2.2354 - val_acc: 0.2333\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.3733 - acc: 0.4557 - val_loss: 2.2478 - val_acc: 0.2333\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3736 - acc: 0.4443 - val_loss: 2.2408 - val_acc: 0.2533\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 644us/step - loss: 1.3733 - acc: 0.4500 - val_loss: 2.2474 - val_acc: 0.2500\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3730 - acc: 0.4457 - val_loss: 2.2336 - val_acc: 0.2367\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3729 - acc: 0.4586 - val_loss: 2.2469 - val_acc: 0.2467\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3730 - acc: 0.4557 - val_loss: 2.2381 - val_acc: 0.2533\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3732 - acc: 0.4543 - val_loss: 2.2264 - val_acc: 0.2500\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 446us/step - loss: 1.3731 - acc: 0.4543 - val_loss: 2.2405 - val_acc: 0.2433\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3729 - acc: 0.4471 - val_loss: 2.2353 - val_acc: 0.2400\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3728 - acc: 0.4529 - val_loss: 2.2457 - val_acc: 0.2467\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3725 - acc: 0.4457 - val_loss: 2.2344 - val_acc: 0.2367\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3724 - acc: 0.4500 - val_loss: 2.2274 - val_acc: 0.2433\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3720 - acc: 0.4529 - val_loss: 2.2455 - val_acc: 0.2533\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 435us/step - loss: 1.3718 - acc: 0.4414 - val_loss: 2.2306 - val_acc: 0.2333\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3725 - acc: 0.4557 - val_loss: 2.2414 - val_acc: 0.2500\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3712 - acc: 0.4543 - val_loss: 2.2238 - val_acc: 0.2467\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3723 - acc: 0.4529 - val_loss: 2.2499 - val_acc: 0.2533\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 542us/step - loss: 1.3711 - acc: 0.4543 - val_loss: 2.2422 - val_acc: 0.2467\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3714 - acc: 0.4514 - val_loss: 2.2305 - val_acc: 0.2333\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3711 - acc: 0.4557 - val_loss: 2.2303 - val_acc: 0.2467\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3708 - acc: 0.4529 - val_loss: 2.2462 - val_acc: 0.2500\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3711 - acc: 0.4486 - val_loss: 2.2464 - val_acc: 0.2467\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3709 - acc: 0.4471 - val_loss: 2.2211 - val_acc: 0.2467\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3715 - acc: 0.4457 - val_loss: 2.2441 - val_acc: 0.2500\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3712 - acc: 0.4471 - val_loss: 2.2392 - val_acc: 0.2400\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3705 - acc: 0.4500 - val_loss: 2.2363 - val_acc: 0.2367\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3701 - acc: 0.4429 - val_loss: 2.2374 - val_acc: 0.2333\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3710 - acc: 0.4500 - val_loss: 2.2501 - val_acc: 0.2367\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3708 - acc: 0.4514 - val_loss: 2.2579 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3711 - acc: 0.4486 - val_loss: 2.2323 - val_acc: 0.2433\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3710 - acc: 0.4471 - val_loss: 2.2367 - val_acc: 0.2467\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3707 - acc: 0.4486 - val_loss: 2.2368 - val_acc: 0.2467\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3701 - acc: 0.4486 - val_loss: 2.2278 - val_acc: 0.2467\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3711 - acc: 0.4529 - val_loss: 2.2279 - val_acc: 0.2467\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3707 - acc: 0.4514 - val_loss: 2.2354 - val_acc: 0.2433\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3697 - acc: 0.4457 - val_loss: 2.2363 - val_acc: 0.2433\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3707 - acc: 0.4500 - val_loss: 2.2569 - val_acc: 0.2500\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3692 - acc: 0.4571 - val_loss: 2.2340 - val_acc: 0.2467\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3697 - acc: 0.4529 - val_loss: 2.2466 - val_acc: 0.2367\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 568us/step - loss: 1.3700 - acc: 0.4529 - val_loss: 2.2429 - val_acc: 0.2467\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3698 - acc: 0.4529 - val_loss: 2.2509 - val_acc: 0.2500\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3704 - acc: 0.4529 - val_loss: 2.2461 - val_acc: 0.2433\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3691 - acc: 0.4557 - val_loss: 2.2382 - val_acc: 0.2433\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3696 - acc: 0.4529 - val_loss: 2.2434 - val_acc: 0.2433\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 577us/step - loss: 1.3691 - acc: 0.4529 - val_loss: 2.2576 - val_acc: 0.2467\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 588us/step - loss: 1.3687 - acc: 0.4543 - val_loss: 2.2454 - val_acc: 0.2433\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 430us/step - loss: 1.3686 - acc: 0.4529 - val_loss: 2.2370 - val_acc: 0.2333\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3677 - acc: 0.4600 - val_loss: 2.2689 - val_acc: 0.2533\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3674 - acc: 0.4514 - val_loss: 2.2379 - val_acc: 0.2500\n",
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 432us/step - loss: 1.3683 - acc: 0.4586 - val_loss: 2.2538 - val_acc: 0.2333\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3679 - acc: 0.4586 - val_loss: 2.2380 - val_acc: 0.2433\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3694 - acc: 0.4543 - val_loss: 2.2291 - val_acc: 0.2433\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 442us/step - loss: 1.3678 - acc: 0.4543 - val_loss: 2.2573 - val_acc: 0.2367\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 491us/step - loss: 1.3683 - acc: 0.4529 - val_loss: 2.2568 - val_acc: 0.2467\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3678 - acc: 0.4486 - val_loss: 2.2374 - val_acc: 0.2433\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 441us/step - loss: 1.3680 - acc: 0.4557 - val_loss: 2.2469 - val_acc: 0.2500\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3683 - acc: 0.4543 - val_loss: 2.2369 - val_acc: 0.2433\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3674 - acc: 0.4529 - val_loss: 2.2372 - val_acc: 0.2300\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 444us/step - loss: 1.3677 - acc: 0.4514 - val_loss: 2.2425 - val_acc: 0.2333\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3669 - acc: 0.4514 - val_loss: 2.2549 - val_acc: 0.2467\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3662 - acc: 0.4486 - val_loss: 2.2444 - val_acc: 0.2300\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3667 - acc: 0.4529 - val_loss: 2.2496 - val_acc: 0.2267\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3673 - acc: 0.4529 - val_loss: 2.2572 - val_acc: 0.2500\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 468us/step - loss: 1.3674 - acc: 0.4529 - val_loss: 2.2608 - val_acc: 0.2500\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 433us/step - loss: 1.3679 - acc: 0.4500 - val_loss: 2.2706 - val_acc: 0.2500\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3677 - acc: 0.4514 - val_loss: 2.2551 - val_acc: 0.2433\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3672 - acc: 0.4514 - val_loss: 2.2591 - val_acc: 0.2467\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3662 - acc: 0.4543 - val_loss: 2.2441 - val_acc: 0.2300\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3667 - acc: 0.4514 - val_loss: 2.2546 - val_acc: 0.2467\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3665 - acc: 0.4471 - val_loss: 2.2630 - val_acc: 0.2467\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.3663 - acc: 0.4500 - val_loss: 2.2546 - val_acc: 0.2433\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3657 - acc: 0.4543 - val_loss: 2.2528 - val_acc: 0.2433\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3667 - acc: 0.4543 - val_loss: 2.2365 - val_acc: 0.2333\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3665 - acc: 0.4543 - val_loss: 2.2504 - val_acc: 0.2400\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3663 - acc: 0.4614 - val_loss: 2.2560 - val_acc: 0.2433\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3656 - acc: 0.4500 - val_loss: 2.2614 - val_acc: 0.2433\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3667 - acc: 0.4514 - val_loss: 2.2406 - val_acc: 0.2433\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3654 - acc: 0.4557 - val_loss: 2.2657 - val_acc: 0.2467\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.3661 - acc: 0.4557 - val_loss: 2.2610 - val_acc: 0.2467\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3660 - acc: 0.4543 - val_loss: 2.2528 - val_acc: 0.2433\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3655 - acc: 0.4557 - val_loss: 2.2576 - val_acc: 0.2467\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.3654 - acc: 0.4486 - val_loss: 2.2589 - val_acc: 0.2433\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3647 - acc: 0.4571 - val_loss: 2.2459 - val_acc: 0.2467\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3653 - acc: 0.4557 - val_loss: 2.2696 - val_acc: 0.2467\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.3644 - acc: 0.4571 - val_loss: 2.2419 - val_acc: 0.2433\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3650 - acc: 0.4557 - val_loss: 2.2508 - val_acc: 0.2333\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3654 - acc: 0.4557 - val_loss: 2.2610 - val_acc: 0.2467\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 444us/step - loss: 1.3637 - acc: 0.4571 - val_loss: 2.2475 - val_acc: 0.2467\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3641 - acc: 0.4471 - val_loss: 2.2478 - val_acc: 0.2467\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3652 - acc: 0.4543 - val_loss: 2.2533 - val_acc: 0.2333\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 454us/step - loss: 1.3645 - acc: 0.4471 - val_loss: 2.2636 - val_acc: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3646 - acc: 0.4571 - val_loss: 2.2390 - val_acc: 0.2467\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3632 - acc: 0.4614 - val_loss: 2.2650 - val_acc: 0.2467\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3639 - acc: 0.4600 - val_loss: 2.2538 - val_acc: 0.2467\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3632 - acc: 0.4486 - val_loss: 2.2526 - val_acc: 0.2333\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3635 - acc: 0.4571 - val_loss: 2.2495 - val_acc: 0.2467\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.3636 - acc: 0.4657 - val_loss: 2.2547 - val_acc: 0.2433\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3635 - acc: 0.4586 - val_loss: 2.2403 - val_acc: 0.2400\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3632 - acc: 0.4629 - val_loss: 2.2516 - val_acc: 0.2433\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.3634 - acc: 0.4557 - val_loss: 2.2635 - val_acc: 0.2500\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 518us/step - loss: 1.3630 - acc: 0.4514 - val_loss: 2.2655 - val_acc: 0.2300\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.3629 - acc: 0.4543 - val_loss: 2.2550 - val_acc: 0.2300\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 448us/step - loss: 1.3631 - acc: 0.4571 - val_loss: 2.2337 - val_acc: 0.2467\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3637 - acc: 0.4600 - val_loss: 2.2533 - val_acc: 0.2367\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3635 - acc: 0.4586 - val_loss: 2.2560 - val_acc: 0.2433\n",
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3626 - acc: 0.4571 - val_loss: 2.2602 - val_acc: 0.2267\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3630 - acc: 0.4586 - val_loss: 2.2601 - val_acc: 0.2467\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3635 - acc: 0.4614 - val_loss: 2.2628 - val_acc: 0.2367\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3638 - acc: 0.4657 - val_loss: 2.2591 - val_acc: 0.2433\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3625 - acc: 0.4557 - val_loss: 2.2555 - val_acc: 0.2433\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3626 - acc: 0.4586 - val_loss: 2.2660 - val_acc: 0.2467\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3614 - acc: 0.4614 - val_loss: 2.2713 - val_acc: 0.2467\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3624 - acc: 0.4500 - val_loss: 2.2617 - val_acc: 0.2433\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3619 - acc: 0.4543 - val_loss: 2.2609 - val_acc: 0.2400\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3613 - acc: 0.4643 - val_loss: 2.2506 - val_acc: 0.2267\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3615 - acc: 0.4629 - val_loss: 2.2713 - val_acc: 0.2433\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.3619 - acc: 0.4586 - val_loss: 2.2534 - val_acc: 0.2433\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3611 - acc: 0.4629 - val_loss: 2.2674 - val_acc: 0.2467\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.3612 - acc: 0.4514 - val_loss: 2.2558 - val_acc: 0.2267\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3612 - acc: 0.4571 - val_loss: 2.2677 - val_acc: 0.2467\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3616 - acc: 0.4586 - val_loss: 2.2588 - val_acc: 0.2367\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3612 - acc: 0.4600 - val_loss: 2.2461 - val_acc: 0.2467\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3614 - acc: 0.4557 - val_loss: 2.2667 - val_acc: 0.2467\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3611 - acc: 0.4543 - val_loss: 2.2414 - val_acc: 0.2433\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3616 - acc: 0.4571 - val_loss: 2.2645 - val_acc: 0.2433\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3599 - acc: 0.4571 - val_loss: 2.2655 - val_acc: 0.2467\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3610 - acc: 0.4586 - val_loss: 2.2463 - val_acc: 0.2333\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3605 - acc: 0.4600 - val_loss: 2.2788 - val_acc: 0.2400\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3607 - acc: 0.4600 - val_loss: 2.2582 - val_acc: 0.2467\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3613 - acc: 0.4614 - val_loss: 2.2672 - val_acc: 0.2300\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3600 - acc: 0.4571 - val_loss: 2.2623 - val_acc: 0.2433\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3615 - acc: 0.4500 - val_loss: 2.2539 - val_acc: 0.2433\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3603 - acc: 0.4586 - val_loss: 2.2698 - val_acc: 0.2467\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3605 - acc: 0.4643 - val_loss: 2.2620 - val_acc: 0.2267\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 644us/step - loss: 1.3590 - acc: 0.4600 - val_loss: 2.2750 - val_acc: 0.2500\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3588 - acc: 0.4471 - val_loss: 2.2676 - val_acc: 0.2367\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3589 - acc: 0.4586 - val_loss: 2.2769 - val_acc: 0.2467\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3604 - acc: 0.4614 - val_loss: 2.2672 - val_acc: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3596 - acc: 0.4586 - val_loss: 2.2674 - val_acc: 0.2433\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 446us/step - loss: 1.3595 - acc: 0.4614 - val_loss: 2.2704 - val_acc: 0.2433\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3595 - acc: 0.4586 - val_loss: 2.2737 - val_acc: 0.2467\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3592 - acc: 0.4629 - val_loss: 2.2485 - val_acc: 0.2467\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3591 - acc: 0.4643 - val_loss: 2.2716 - val_acc: 0.2467\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3593 - acc: 0.4614 - val_loss: 2.2479 - val_acc: 0.2500\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3596 - acc: 0.4529 - val_loss: 2.2460 - val_acc: 0.2467\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3600 - acc: 0.4629 - val_loss: 2.2611 - val_acc: 0.2433\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 508us/step - loss: 1.3594 - acc: 0.4614 - val_loss: 2.2725 - val_acc: 0.2467\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 475us/step - loss: 1.3581 - acc: 0.4543 - val_loss: 2.2605 - val_acc: 0.2433\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3588 - acc: 0.4586 - val_loss: 2.2869 - val_acc: 0.2500\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 561us/step - loss: 1.3594 - acc: 0.4600 - val_loss: 2.2452 - val_acc: 0.2467\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3588 - acc: 0.4557 - val_loss: 2.2671 - val_acc: 0.2467\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3583 - acc: 0.4557 - val_loss: 2.2593 - val_acc: 0.2433\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3582 - acc: 0.4643 - val_loss: 2.2765 - val_acc: 0.2367\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 593us/step - loss: 1.3585 - acc: 0.4686 - val_loss: 2.2717 - val_acc: 0.2433\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3580 - acc: 0.4686 - val_loss: 2.2919 - val_acc: 0.2500\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3589 - acc: 0.4600 - val_loss: 2.2731 - val_acc: 0.2467\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3583 - acc: 0.4629 - val_loss: 2.2544 - val_acc: 0.2433\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3582 - acc: 0.4671 - val_loss: 2.2755 - val_acc: 0.2433\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3583 - acc: 0.4514 - val_loss: 2.2600 - val_acc: 0.2433\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.3577 - acc: 0.4600 - val_loss: 2.2763 - val_acc: 0.2533\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3566 - acc: 0.4671 - val_loss: 2.2451 - val_acc: 0.2400\n",
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.3570 - acc: 0.4629 - val_loss: 2.2628 - val_acc: 0.2433\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3576 - acc: 0.4600 - val_loss: 2.2767 - val_acc: 0.2467\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.3574 - acc: 0.4600 - val_loss: 2.2682 - val_acc: 0.2467\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3571 - acc: 0.4643 - val_loss: 2.2784 - val_acc: 0.2467\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 532us/step - loss: 1.3572 - acc: 0.4657 - val_loss: 2.2809 - val_acc: 0.2367\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3568 - acc: 0.4686 - val_loss: 2.2800 - val_acc: 0.2500\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3567 - acc: 0.4529 - val_loss: 2.2746 - val_acc: 0.2300\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3564 - acc: 0.4586 - val_loss: 2.2497 - val_acc: 0.2467\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3568 - acc: 0.4657 - val_loss: 2.2677 - val_acc: 0.2433\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.3569 - acc: 0.4657 - val_loss: 2.2566 - val_acc: 0.2467\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3563 - acc: 0.4586 - val_loss: 2.2892 - val_acc: 0.2333\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3571 - acc: 0.4643 - val_loss: 2.2855 - val_acc: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 495us/step - loss: 1.3568 - acc: 0.4643 - val_loss: 2.2769 - val_acc: 0.2500\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3563 - acc: 0.4557 - val_loss: 2.2564 - val_acc: 0.2467\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3571 - acc: 0.4657 - val_loss: 2.2718 - val_acc: 0.2433\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3562 - acc: 0.4657 - val_loss: 2.2872 - val_acc: 0.2400\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3566 - acc: 0.4657 - val_loss: 2.2805 - val_acc: 0.2433\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.3553 - acc: 0.4614 - val_loss: 2.2707 - val_acc: 0.2433\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.3565 - acc: 0.4586 - val_loss: 2.2771 - val_acc: 0.2433\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3555 - acc: 0.4614 - val_loss: 2.2662 - val_acc: 0.2400\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3543 - acc: 0.4714 - val_loss: 2.2830 - val_acc: 0.2400\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 448us/step - loss: 1.3553 - acc: 0.4686 - val_loss: 2.2825 - val_acc: 0.2367\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3554 - acc: 0.4629 - val_loss: 2.2692 - val_acc: 0.2433\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.3548 - acc: 0.4686 - val_loss: 2.2902 - val_acc: 0.2533\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3558 - acc: 0.4543 - val_loss: 2.2712 - val_acc: 0.2433\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3550 - acc: 0.4614 - val_loss: 2.2775 - val_acc: 0.2267\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3548 - acc: 0.4629 - val_loss: 2.2847 - val_acc: 0.2433\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3564 - acc: 0.4629 - val_loss: 2.2687 - val_acc: 0.2300\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3560 - acc: 0.4643 - val_loss: 2.2920 - val_acc: 0.2467\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 598us/step - loss: 1.3557 - acc: 0.4743 - val_loss: 2.2592 - val_acc: 0.2400\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3545 - acc: 0.4600 - val_loss: 2.2885 - val_acc: 0.2533\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3555 - acc: 0.4529 - val_loss: 2.2808 - val_acc: 0.2467\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 436us/step - loss: 1.3544 - acc: 0.4600 - val_loss: 2.2879 - val_acc: 0.2500\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3545 - acc: 0.4600 - val_loss: 2.2745 - val_acc: 0.2467\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3549 - acc: 0.4657 - val_loss: 2.2800 - val_acc: 0.2400\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3535 - acc: 0.4600 - val_loss: 2.2809 - val_acc: 0.2333\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3555 - acc: 0.4629 - val_loss: 2.2874 - val_acc: 0.2467\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.3535 - acc: 0.4657 - val_loss: 2.2643 - val_acc: 0.2400\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3554 - acc: 0.4643 - val_loss: 2.2766 - val_acc: 0.2433\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3534 - acc: 0.4671 - val_loss: 2.2783 - val_acc: 0.2467\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3538 - acc: 0.4714 - val_loss: 2.2880 - val_acc: 0.2500\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.3542 - acc: 0.4600 - val_loss: 2.2786 - val_acc: 0.2467\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3530 - acc: 0.4629 - val_loss: 2.2894 - val_acc: 0.2367\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 568us/step - loss: 1.3535 - acc: 0.4629 - val_loss: 2.2744 - val_acc: 0.2267\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 695us/step - loss: 1.3534 - acc: 0.4629 - val_loss: 2.2904 - val_acc: 0.2467\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 627us/step - loss: 1.3528 - acc: 0.4671 - val_loss: 2.2781 - val_acc: 0.2467\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 485us/step - loss: 1.3528 - acc: 0.4614 - val_loss: 2.2851 - val_acc: 0.2433\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 596us/step - loss: 1.3534 - acc: 0.4629 - val_loss: 2.2952 - val_acc: 0.2400\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3529 - acc: 0.4686 - val_loss: 2.2761 - val_acc: 0.2467\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 581us/step - loss: 1.3533 - acc: 0.4657 - val_loss: 2.2802 - val_acc: 0.2400\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3527 - acc: 0.4700 - val_loss: 2.2931 - val_acc: 0.2533\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3536 - acc: 0.4643 - val_loss: 2.2728 - val_acc: 0.2433\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3526 - acc: 0.4700 - val_loss: 2.2853 - val_acc: 0.2500\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3524 - acc: 0.4629 - val_loss: 2.2914 - val_acc: 0.2500\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 668us/step - loss: 1.3528 - acc: 0.4629 - val_loss: 2.2637 - val_acc: 0.2433\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 710us/step - loss: 1.3532 - acc: 0.4657 - val_loss: 2.2718 - val_acc: 0.2467\n",
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3527 - acc: 0.4629 - val_loss: 2.2888 - val_acc: 0.2500\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3534 - acc: 0.4614 - val_loss: 2.2941 - val_acc: 0.2500\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3519 - acc: 0.4614 - val_loss: 2.3068 - val_acc: 0.2433\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.3522 - acc: 0.4600 - val_loss: 2.2752 - val_acc: 0.2400\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.3521 - acc: 0.4657 - val_loss: 2.2824 - val_acc: 0.2433\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.3525 - acc: 0.4700 - val_loss: 2.2759 - val_acc: 0.2467\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 594us/step - loss: 1.3517 - acc: 0.4657 - val_loss: 2.2866 - val_acc: 0.2533\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 659us/step - loss: 1.3518 - acc: 0.4643 - val_loss: 2.3057 - val_acc: 0.2500\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 1.3522 - acc: 0.4629 - val_loss: 2.2915 - val_acc: 0.2467\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3517 - acc: 0.4586 - val_loss: 2.2924 - val_acc: 0.2400\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3516 - acc: 0.4571 - val_loss: 2.2812 - val_acc: 0.2500\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3515 - acc: 0.4686 - val_loss: 2.2700 - val_acc: 0.2433\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 590us/step - loss: 1.3500 - acc: 0.4686 - val_loss: 2.3199 - val_acc: 0.2467\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.3516 - acc: 0.4643 - val_loss: 2.2899 - val_acc: 0.2433\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 701us/step - loss: 1.3513 - acc: 0.4714 - val_loss: 2.2984 - val_acc: 0.2433\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.3509 - acc: 0.4643 - val_loss: 2.2830 - val_acc: 0.2433\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 608us/step - loss: 1.3518 - acc: 0.4557 - val_loss: 2.2859 - val_acc: 0.2400\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3511 - acc: 0.4657 - val_loss: 2.3006 - val_acc: 0.2433\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 643us/step - loss: 1.3513 - acc: 0.4671 - val_loss: 2.3077 - val_acc: 0.2500\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3506 - acc: 0.4686 - val_loss: 2.2989 - val_acc: 0.2500\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3506 - acc: 0.4643 - val_loss: 2.2858 - val_acc: 0.2433\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3501 - acc: 0.4686 - val_loss: 2.3066 - val_acc: 0.2500\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3495 - acc: 0.4643 - val_loss: 2.2887 - val_acc: 0.2300\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3519 - acc: 0.4629 - val_loss: 2.2822 - val_acc: 0.2433\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3498 - acc: 0.4729 - val_loss: 2.2835 - val_acc: 0.2467\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3502 - acc: 0.4700 - val_loss: 2.3126 - val_acc: 0.2433\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3503 - acc: 0.4671 - val_loss: 2.2750 - val_acc: 0.2367\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3501 - acc: 0.4600 - val_loss: 2.3024 - val_acc: 0.2500\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3496 - acc: 0.4657 - val_loss: 2.2651 - val_acc: 0.2500\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3505 - acc: 0.4657 - val_loss: 2.2802 - val_acc: 0.2433\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3506 - acc: 0.4657 - val_loss: 2.2967 - val_acc: 0.2467\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3497 - acc: 0.4686 - val_loss: 2.2970 - val_acc: 0.2467\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3493 - acc: 0.4629 - val_loss: 2.2720 - val_acc: 0.2400\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3498 - acc: 0.4657 - val_loss: 2.3010 - val_acc: 0.2433\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3502 - acc: 0.4557 - val_loss: 2.2918 - val_acc: 0.2433\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3497 - acc: 0.4657 - val_loss: 2.3045 - val_acc: 0.2467\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3497 - acc: 0.4657 - val_loss: 2.2984 - val_acc: 0.2467\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3492 - acc: 0.4586 - val_loss: 2.2969 - val_acc: 0.2400\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3490 - acc: 0.4700 - val_loss: 2.2955 - val_acc: 0.2433\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3488 - acc: 0.4671 - val_loss: 2.3092 - val_acc: 0.2433\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3489 - acc: 0.4700 - val_loss: 2.3035 - val_acc: 0.2467\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3473 - acc: 0.4643 - val_loss: 2.3085 - val_acc: 0.2467\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3499 - acc: 0.4629 - val_loss: 2.2970 - val_acc: 0.2500\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3491 - acc: 0.4700 - val_loss: 2.2818 - val_acc: 0.2433\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 570us/step - loss: 1.3482 - acc: 0.4700 - val_loss: 2.2973 - val_acc: 0.2433\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 615us/step - loss: 1.3485 - acc: 0.4614 - val_loss: 2.2941 - val_acc: 0.2333\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3489 - acc: 0.4671 - val_loss: 2.2972 - val_acc: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3483 - acc: 0.4643 - val_loss: 2.2840 - val_acc: 0.2467\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3482 - acc: 0.4686 - val_loss: 2.3020 - val_acc: 0.2500\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3493 - acc: 0.4643 - val_loss: 2.2854 - val_acc: 0.2500\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3479 - acc: 0.4671 - val_loss: 2.2786 - val_acc: 0.2467\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3480 - acc: 0.4743 - val_loss: 2.2996 - val_acc: 0.2433\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3476 - acc: 0.4714 - val_loss: 2.2987 - val_acc: 0.2400\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3480 - acc: 0.4600 - val_loss: 2.2888 - val_acc: 0.2433\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3478 - acc: 0.4671 - val_loss: 2.2961 - val_acc: 0.2433\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3474 - acc: 0.4714 - val_loss: 2.3061 - val_acc: 0.2467\n",
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3476 - acc: 0.4657 - val_loss: 2.2946 - val_acc: 0.2467\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3473 - acc: 0.4657 - val_loss: 2.2801 - val_acc: 0.2433\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3471 - acc: 0.4700 - val_loss: 2.3143 - val_acc: 0.2433\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3470 - acc: 0.4671 - val_loss: 2.2959 - val_acc: 0.2400\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3478 - acc: 0.4671 - val_loss: 2.2888 - val_acc: 0.2433\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.3477 - acc: 0.4643 - val_loss: 2.2859 - val_acc: 0.2433\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3470 - acc: 0.4614 - val_loss: 2.2974 - val_acc: 0.2467\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3470 - acc: 0.4629 - val_loss: 2.3057 - val_acc: 0.2433\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3468 - acc: 0.4671 - val_loss: 2.2736 - val_acc: 0.2433\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3471 - acc: 0.4686 - val_loss: 2.2781 - val_acc: 0.2433\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3470 - acc: 0.4700 - val_loss: 2.3161 - val_acc: 0.2500\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3466 - acc: 0.4643 - val_loss: 2.3124 - val_acc: 0.2433\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3463 - acc: 0.4714 - val_loss: 2.2756 - val_acc: 0.2433\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3465 - acc: 0.4657 - val_loss: 2.3171 - val_acc: 0.2467\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 1.3462 - acc: 0.4657 - val_loss: 2.3168 - val_acc: 0.2500\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3460 - acc: 0.4629 - val_loss: 2.2942 - val_acc: 0.2433\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3464 - acc: 0.4700 - val_loss: 2.3040 - val_acc: 0.2500\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3458 - acc: 0.4657 - val_loss: 2.3131 - val_acc: 0.2500\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3470 - acc: 0.4686 - val_loss: 2.2988 - val_acc: 0.2500\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3466 - acc: 0.4729 - val_loss: 2.3066 - val_acc: 0.2433\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3458 - acc: 0.4629 - val_loss: 2.2962 - val_acc: 0.2400\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3463 - acc: 0.4629 - val_loss: 2.2999 - val_acc: 0.2433\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3452 - acc: 0.4714 - val_loss: 2.3043 - val_acc: 0.2467\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.3460 - acc: 0.4657 - val_loss: 2.3100 - val_acc: 0.2433\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3457 - acc: 0.4671 - val_loss: 2.2966 - val_acc: 0.2433\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3460 - acc: 0.4643 - val_loss: 2.3231 - val_acc: 0.2467\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 435us/step - loss: 1.3457 - acc: 0.4614 - val_loss: 2.2902 - val_acc: 0.2400\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3450 - acc: 0.4743 - val_loss: 2.3115 - val_acc: 0.2500\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3458 - acc: 0.4600 - val_loss: 2.3000 - val_acc: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3451 - acc: 0.4700 - val_loss: 2.3168 - val_acc: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3454 - acc: 0.4671 - val_loss: 2.2989 - val_acc: 0.2533\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3441 - acc: 0.4671 - val_loss: 2.3156 - val_acc: 0.2467\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3448 - acc: 0.4657 - val_loss: 2.2975 - val_acc: 0.2467\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3450 - acc: 0.4743 - val_loss: 2.3077 - val_acc: 0.2467\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3432 - acc: 0.4643 - val_loss: 2.3262 - val_acc: 0.2467\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3447 - acc: 0.4700 - val_loss: 2.3027 - val_acc: 0.2467\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3447 - acc: 0.4714 - val_loss: 2.3171 - val_acc: 0.2467\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3447 - acc: 0.4643 - val_loss: 2.3110 - val_acc: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3444 - acc: 0.4657 - val_loss: 2.2991 - val_acc: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3447 - acc: 0.4686 - val_loss: 2.3024 - val_acc: 0.2433\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3446 - acc: 0.4786 - val_loss: 2.2984 - val_acc: 0.2433\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3445 - acc: 0.4671 - val_loss: 2.3049 - val_acc: 0.2433\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3440 - acc: 0.4686 - val_loss: 2.2875 - val_acc: 0.2433\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3445 - acc: 0.4743 - val_loss: 2.3228 - val_acc: 0.2467\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3439 - acc: 0.4757 - val_loss: 2.2980 - val_acc: 0.2467\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3432 - acc: 0.4657 - val_loss: 2.2979 - val_acc: 0.2400\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3449 - acc: 0.4700 - val_loss: 2.3139 - val_acc: 0.2433\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3434 - acc: 0.4671 - val_loss: 2.3196 - val_acc: 0.2467\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3439 - acc: 0.4757 - val_loss: 2.3082 - val_acc: 0.2500\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.3437 - acc: 0.4700 - val_loss: 2.3035 - val_acc: 0.2400\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3438 - acc: 0.4743 - val_loss: 2.3156 - val_acc: 0.2500\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.3426 - acc: 0.4757 - val_loss: 2.3314 - val_acc: 0.2433\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3448 - acc: 0.4657 - val_loss: 2.2931 - val_acc: 0.2467\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3432 - acc: 0.4714 - val_loss: 2.3142 - val_acc: 0.2433\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3434 - acc: 0.4657 - val_loss: 2.3051 - val_acc: 0.2400\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3426 - acc: 0.4657 - val_loss: 2.3196 - val_acc: 0.2467\n",
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3403 - acc: 0.4657 - val_loss: 2.3083 - val_acc: 0.2367\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3427 - acc: 0.4671 - val_loss: 2.3022 - val_acc: 0.2433\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3424 - acc: 0.4700 - val_loss: 2.2976 - val_acc: 0.2433\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3440 - acc: 0.4671 - val_loss: 2.3051 - val_acc: 0.2500\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3420 - acc: 0.4700 - val_loss: 2.3070 - val_acc: 0.2433\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3426 - acc: 0.4657 - val_loss: 2.3072 - val_acc: 0.2367\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3387 - acc: 0.4714 - val_loss: 2.3094 - val_acc: 0.2500\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3427 - acc: 0.4714 - val_loss: 2.3116 - val_acc: 0.2433\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 1.3431 - acc: 0.4757 - val_loss: 2.3150 - val_acc: 0.2433\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3423 - acc: 0.4643 - val_loss: 2.3166 - val_acc: 0.2433\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3422 - acc: 0.4686 - val_loss: 2.3045 - val_acc: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 447us/step - loss: 1.3417 - acc: 0.4700 - val_loss: 2.3177 - val_acc: 0.2367\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 566us/step - loss: 1.3413 - acc: 0.4700 - val_loss: 2.3416 - val_acc: 0.2467\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 651us/step - loss: 1.3414 - acc: 0.4629 - val_loss: 2.3022 - val_acc: 0.2333\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 604us/step - loss: 1.3419 - acc: 0.4686 - val_loss: 2.3191 - val_acc: 0.2400\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.3420 - acc: 0.4686 - val_loss: 2.3117 - val_acc: 0.2433\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 608us/step - loss: 1.3419 - acc: 0.4700 - val_loss: 2.3032 - val_acc: 0.2467\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 596us/step - loss: 1.3411 - acc: 0.4757 - val_loss: 2.3234 - val_acc: 0.2433\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 580us/step - loss: 1.3415 - acc: 0.4657 - val_loss: 2.3107 - val_acc: 0.2400\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.3415 - acc: 0.4714 - val_loss: 2.2970 - val_acc: 0.2433\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.3407 - acc: 0.4757 - val_loss: 2.3282 - val_acc: 0.2433\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 578us/step - loss: 1.3412 - acc: 0.4671 - val_loss: 2.3071 - val_acc: 0.2433\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 600us/step - loss: 1.3418 - acc: 0.4743 - val_loss: 2.3335 - val_acc: 0.2533\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 593us/step - loss: 1.3418 - acc: 0.4700 - val_loss: 2.3305 - val_acc: 0.2500\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 571us/step - loss: 1.3418 - acc: 0.4729 - val_loss: 2.3231 - val_acc: 0.2433\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3410 - acc: 0.4700 - val_loss: 2.3346 - val_acc: 0.2433\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3406 - acc: 0.4671 - val_loss: 2.3194 - val_acc: 0.2500\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 614us/step - loss: 1.3409 - acc: 0.4686 - val_loss: 2.3190 - val_acc: 0.2433\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 594us/step - loss: 1.3406 - acc: 0.4771 - val_loss: 2.3169 - val_acc: 0.2467\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 608us/step - loss: 1.3402 - acc: 0.4729 - val_loss: 2.3128 - val_acc: 0.2467\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3396 - acc: 0.4657 - val_loss: 2.3071 - val_acc: 0.2333\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 623us/step - loss: 1.3403 - acc: 0.4686 - val_loss: 2.3180 - val_acc: 0.2467\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3385 - acc: 0.4686 - val_loss: 2.3193 - val_acc: 0.2467\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 564us/step - loss: 1.3404 - acc: 0.4657 - val_loss: 2.3208 - val_acc: 0.2467\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3399 - acc: 0.4729 - val_loss: 2.3343 - val_acc: 0.2400\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.3405 - acc: 0.4729 - val_loss: 2.3199 - val_acc: 0.2467\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3398 - acc: 0.4671 - val_loss: 2.3313 - val_acc: 0.2367\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3403 - acc: 0.4671 - val_loss: 2.3215 - val_acc: 0.2433\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3414 - acc: 0.4686 - val_loss: 2.3310 - val_acc: 0.2467\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 538us/step - loss: 1.3398 - acc: 0.4700 - val_loss: 2.3187 - val_acc: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3400 - acc: 0.4757 - val_loss: 2.3195 - val_acc: 0.2467\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3397 - acc: 0.4757 - val_loss: 2.3165 - val_acc: 0.2433\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3400 - acc: 0.4714 - val_loss: 2.3382 - val_acc: 0.2367\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.3395 - acc: 0.4686 - val_loss: 2.3288 - val_acc: 0.2433\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.3395 - acc: 0.4700 - val_loss: 2.3283 - val_acc: 0.2467\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3396 - acc: 0.4700 - val_loss: 2.3332 - val_acc: 0.2433\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3387 - acc: 0.4729 - val_loss: 2.3209 - val_acc: 0.2467\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3387 - acc: 0.4729 - val_loss: 2.3192 - val_acc: 0.2467\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 518us/step - loss: 1.3395 - acc: 0.4757 - val_loss: 2.3386 - val_acc: 0.2500\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3379 - acc: 0.4686 - val_loss: 2.3293 - val_acc: 0.2400\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 532us/step - loss: 1.3394 - acc: 0.4757 - val_loss: 2.3034 - val_acc: 0.2533\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3392 - acc: 0.4714 - val_loss: 2.3285 - val_acc: 0.2400\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.3389 - acc: 0.4671 - val_loss: 2.3242 - val_acc: 0.2467\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3385 - acc: 0.4657 - val_loss: 2.3328 - val_acc: 0.2467\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3384 - acc: 0.4771 - val_loss: 2.3465 - val_acc: 0.2467\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3384 - acc: 0.4714 - val_loss: 2.3257 - val_acc: 0.2433\n",
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.3391 - acc: 0.4729 - val_loss: 2.3296 - val_acc: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3378 - acc: 0.4743 - val_loss: 2.3429 - val_acc: 0.2467\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3388 - acc: 0.4757 - val_loss: 2.3404 - val_acc: 0.2400\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3372 - acc: 0.4800 - val_loss: 2.3414 - val_acc: 0.2400\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 1.3379 - acc: 0.4757 - val_loss: 2.3288 - val_acc: 0.2467\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.3385 - acc: 0.4729 - val_loss: 2.3326 - val_acc: 0.2467\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3366 - acc: 0.4757 - val_loss: 2.3226 - val_acc: 0.2367\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3377 - acc: 0.4700 - val_loss: 2.3102 - val_acc: 0.2400\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3385 - acc: 0.4729 - val_loss: 2.3356 - val_acc: 0.2367\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3379 - acc: 0.4757 - val_loss: 2.3450 - val_acc: 0.2467\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3378 - acc: 0.4671 - val_loss: 2.3365 - val_acc: 0.2433\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3376 - acc: 0.4714 - val_loss: 2.3345 - val_acc: 0.2433\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.3375 - acc: 0.4714 - val_loss: 2.3378 - val_acc: 0.2467\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3376 - acc: 0.4800 - val_loss: 2.3480 - val_acc: 0.2500\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3369 - acc: 0.4729 - val_loss: 2.3420 - val_acc: 0.2500\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3362 - acc: 0.4729 - val_loss: 2.3480 - val_acc: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3367 - acc: 0.4729 - val_loss: 2.3426 - val_acc: 0.2467\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3370 - acc: 0.4671 - val_loss: 2.3228 - val_acc: 0.2400\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3364 - acc: 0.4714 - val_loss: 2.3202 - val_acc: 0.2500\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.3379 - acc: 0.4743 - val_loss: 2.3450 - val_acc: 0.2467\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3361 - acc: 0.4771 - val_loss: 2.3621 - val_acc: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3368 - acc: 0.4786 - val_loss: 2.3390 - val_acc: 0.2400\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3364 - acc: 0.4700 - val_loss: 2.3340 - val_acc: 0.2367\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 603us/step - loss: 1.3377 - acc: 0.4743 - val_loss: 2.3260 - val_acc: 0.2333\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 573us/step - loss: 1.3371 - acc: 0.4743 - val_loss: 2.3393 - val_acc: 0.2500\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 583us/step - loss: 1.3373 - acc: 0.4729 - val_loss: 2.3200 - val_acc: 0.2400\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3369 - acc: 0.4686 - val_loss: 2.3251 - val_acc: 0.2400\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3360 - acc: 0.4771 - val_loss: 2.3155 - val_acc: 0.2500\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3369 - acc: 0.4786 - val_loss: 2.3417 - val_acc: 0.2433\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 598us/step - loss: 1.3360 - acc: 0.4700 - val_loss: 2.3289 - val_acc: 0.2367\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 590us/step - loss: 1.3357 - acc: 0.4786 - val_loss: 2.3200 - val_acc: 0.2467\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3358 - acc: 0.4757 - val_loss: 2.3436 - val_acc: 0.2467\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3357 - acc: 0.4671 - val_loss: 2.3591 - val_acc: 0.2467\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3356 - acc: 0.4657 - val_loss: 2.3207 - val_acc: 0.2467\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3359 - acc: 0.4757 - val_loss: 2.3385 - val_acc: 0.2467\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3357 - acc: 0.4700 - val_loss: 2.3625 - val_acc: 0.2467\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3350 - acc: 0.4614 - val_loss: 2.3334 - val_acc: 0.2467\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3355 - acc: 0.4671 - val_loss: 2.3410 - val_acc: 0.2467\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3350 - acc: 0.4757 - val_loss: 2.3510 - val_acc: 0.2500\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3364 - acc: 0.4671 - val_loss: 2.3189 - val_acc: 0.2467\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.3352 - acc: 0.4714 - val_loss: 2.3357 - val_acc: 0.2467\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3353 - acc: 0.4771 - val_loss: 2.3475 - val_acc: 0.2467\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3354 - acc: 0.4686 - val_loss: 2.3434 - val_acc: 0.2500\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3352 - acc: 0.4729 - val_loss: 2.3594 - val_acc: 0.2467\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3357 - acc: 0.4657 - val_loss: 2.3311 - val_acc: 0.2400\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3346 - acc: 0.4814 - val_loss: 2.3259 - val_acc: 0.2433\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3347 - acc: 0.4743 - val_loss: 2.3262 - val_acc: 0.2433\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3344 - acc: 0.4700 - val_loss: 2.3446 - val_acc: 0.2433\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3348 - acc: 0.4714 - val_loss: 2.3475 - val_acc: 0.2467\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3348 - acc: 0.4757 - val_loss: 2.3289 - val_acc: 0.2433\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.3354 - acc: 0.4729 - val_loss: 2.3542 - val_acc: 0.2467\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3346 - acc: 0.4714 - val_loss: 2.3486 - val_acc: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3341 - acc: 0.4729 - val_loss: 2.3361 - val_acc: 0.2533\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 564us/step - loss: 1.3351 - acc: 0.4786 - val_loss: 2.3368 - val_acc: 0.2367\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3345 - acc: 0.4743 - val_loss: 2.3323 - val_acc: 0.2400\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3347 - acc: 0.4686 - val_loss: 2.3383 - val_acc: 0.2467\n",
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3341 - acc: 0.4686 - val_loss: 2.3404 - val_acc: 0.2400\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3343 - acc: 0.4686 - val_loss: 2.3355 - val_acc: 0.2433\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3347 - acc: 0.4786 - val_loss: 2.3298 - val_acc: 0.2433\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3335 - acc: 0.4743 - val_loss: 2.3344 - val_acc: 0.2467\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3349 - acc: 0.4729 - val_loss: 2.3335 - val_acc: 0.2500\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3338 - acc: 0.4757 - val_loss: 2.3347 - val_acc: 0.2433\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3326 - acc: 0.4729 - val_loss: 2.3462 - val_acc: 0.2467\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3326 - acc: 0.4714 - val_loss: 2.3326 - val_acc: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3334 - acc: 0.4743 - val_loss: 2.3408 - val_acc: 0.2433\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3342 - acc: 0.4729 - val_loss: 2.3415 - val_acc: 0.2400\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3336 - acc: 0.4700 - val_loss: 2.3250 - val_acc: 0.2467\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3334 - acc: 0.4771 - val_loss: 2.3391 - val_acc: 0.2433\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3336 - acc: 0.4814 - val_loss: 2.3519 - val_acc: 0.2467\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3337 - acc: 0.4743 - val_loss: 2.3412 - val_acc: 0.2467\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3322 - acc: 0.4686 - val_loss: 2.3513 - val_acc: 0.2467\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3332 - acc: 0.4771 - val_loss: 2.3343 - val_acc: 0.2433\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3326 - acc: 0.4729 - val_loss: 2.3244 - val_acc: 0.2400\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3337 - acc: 0.4729 - val_loss: 2.3375 - val_acc: 0.2467\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3327 - acc: 0.4714 - val_loss: 2.3524 - val_acc: 0.2467\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3328 - acc: 0.4757 - val_loss: 2.3628 - val_acc: 0.2500\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3331 - acc: 0.4771 - val_loss: 2.3365 - val_acc: 0.2400\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3326 - acc: 0.4743 - val_loss: 2.3476 - val_acc: 0.2400\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3322 - acc: 0.4700 - val_loss: 2.3459 - val_acc: 0.2333\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3326 - acc: 0.4786 - val_loss: 2.3344 - val_acc: 0.2367\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3327 - acc: 0.4743 - val_loss: 2.3363 - val_acc: 0.2367\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3330 - acc: 0.4743 - val_loss: 2.3409 - val_acc: 0.2467\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3329 - acc: 0.4729 - val_loss: 2.3382 - val_acc: 0.2433\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3324 - acc: 0.4743 - val_loss: 2.3454 - val_acc: 0.2433\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3314 - acc: 0.4700 - val_loss: 2.3483 - val_acc: 0.2367\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3322 - acc: 0.4743 - val_loss: 2.3631 - val_acc: 0.2467\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3315 - acc: 0.4771 - val_loss: 2.3525 - val_acc: 0.2467\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3317 - acc: 0.4686 - val_loss: 2.3375 - val_acc: 0.2433\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3315 - acc: 0.4771 - val_loss: 2.3290 - val_acc: 0.2467\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3307 - acc: 0.4786 - val_loss: 2.3440 - val_acc: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3310 - acc: 0.4800 - val_loss: 2.3407 - val_acc: 0.2500\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3317 - acc: 0.4786 - val_loss: 2.3385 - val_acc: 0.2467\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3313 - acc: 0.4757 - val_loss: 2.3296 - val_acc: 0.2400\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3319 - acc: 0.4771 - val_loss: 2.3491 - val_acc: 0.2433\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3319 - acc: 0.4743 - val_loss: 2.3427 - val_acc: 0.2433\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3312 - acc: 0.4714 - val_loss: 2.3592 - val_acc: 0.2500\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3317 - acc: 0.4743 - val_loss: 2.3417 - val_acc: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3313 - acc: 0.4800 - val_loss: 2.3622 - val_acc: 0.2467\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3319 - acc: 0.4786 - val_loss: 2.3544 - val_acc: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3314 - acc: 0.4743 - val_loss: 2.3714 - val_acc: 0.2467\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3311 - acc: 0.4757 - val_loss: 2.3438 - val_acc: 0.2467\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3322 - acc: 0.4729 - val_loss: 2.3508 - val_acc: 0.2433\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3300 - acc: 0.4714 - val_loss: 2.3557 - val_acc: 0.2367\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3308 - acc: 0.4729 - val_loss: 2.3460 - val_acc: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3308 - acc: 0.4729 - val_loss: 2.3582 - val_acc: 0.2400\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3302 - acc: 0.4714 - val_loss: 2.3596 - val_acc: 0.2400\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3307 - acc: 0.4729 - val_loss: 2.3410 - val_acc: 0.2467\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3306 - acc: 0.4714 - val_loss: 2.3493 - val_acc: 0.2400\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3303 - acc: 0.4700 - val_loss: 2.3540 - val_acc: 0.2433\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3298 - acc: 0.4757 - val_loss: 2.3505 - val_acc: 0.2400\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3300 - acc: 0.4729 - val_loss: 2.3684 - val_acc: 0.2400\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 573us/step - loss: 1.3300 - acc: 0.4729 - val_loss: 2.3877 - val_acc: 0.2533\n",
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3301 - acc: 0.4757 - val_loss: 2.3631 - val_acc: 0.2433\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.3298 - acc: 0.4700 - val_loss: 2.3671 - val_acc: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 551us/step - loss: 1.3294 - acc: 0.4729 - val_loss: 2.3649 - val_acc: 0.2400\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3294 - acc: 0.4757 - val_loss: 2.3585 - val_acc: 0.2433\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3298 - acc: 0.4786 - val_loss: 2.3636 - val_acc: 0.2433\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3291 - acc: 0.4743 - val_loss: 2.3817 - val_acc: 0.2433\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3288 - acc: 0.4729 - val_loss: 2.3770 - val_acc: 0.2500\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3294 - acc: 0.4714 - val_loss: 2.3694 - val_acc: 0.2433\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3291 - acc: 0.4743 - val_loss: 2.3347 - val_acc: 0.2467\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3293 - acc: 0.4829 - val_loss: 2.3678 - val_acc: 0.2433\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3282 - acc: 0.4714 - val_loss: 2.3568 - val_acc: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 642us/step - loss: 1.3283 - acc: 0.4743 - val_loss: 2.3506 - val_acc: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3285 - acc: 0.4757 - val_loss: 2.3467 - val_acc: 0.2400\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3289 - acc: 0.4800 - val_loss: 2.3667 - val_acc: 0.2433\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 591us/step - loss: 1.3277 - acc: 0.4757 - val_loss: 2.3748 - val_acc: 0.2467\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3286 - acc: 0.4714 - val_loss: 2.3800 - val_acc: 0.2467\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.3287 - acc: 0.4729 - val_loss: 2.3696 - val_acc: 0.2400\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 596us/step - loss: 1.3267 - acc: 0.4786 - val_loss: 2.3680 - val_acc: 0.2400\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3278 - acc: 0.4714 - val_loss: 2.3763 - val_acc: 0.2400\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3282 - acc: 0.4771 - val_loss: 2.3781 - val_acc: 0.2467\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3276 - acc: 0.4786 - val_loss: 2.3623 - val_acc: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3283 - acc: 0.4743 - val_loss: 2.3852 - val_acc: 0.2500\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3275 - acc: 0.4714 - val_loss: 2.3540 - val_acc: 0.2433\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3281 - acc: 0.4743 - val_loss: 2.3619 - val_acc: 0.2467\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 558us/step - loss: 1.3275 - acc: 0.4914 - val_loss: 2.3732 - val_acc: 0.2400\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3278 - acc: 0.4786 - val_loss: 2.3600 - val_acc: 0.2333\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3270 - acc: 0.4786 - val_loss: 2.3708 - val_acc: 0.2367\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3279 - acc: 0.4814 - val_loss: 2.3733 - val_acc: 0.2433\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.3273 - acc: 0.4743 - val_loss: 2.3702 - val_acc: 0.2433\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3270 - acc: 0.4800 - val_loss: 2.3728 - val_acc: 0.2433\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3269 - acc: 0.4771 - val_loss: 2.3522 - val_acc: 0.2500\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3279 - acc: 0.4800 - val_loss: 2.3663 - val_acc: 0.2400\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.3271 - acc: 0.4814 - val_loss: 2.3756 - val_acc: 0.2400\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3267 - acc: 0.4771 - val_loss: 2.3645 - val_acc: 0.2400\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3268 - acc: 0.4743 - val_loss: 2.3786 - val_acc: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3274 - acc: 0.4743 - val_loss: 2.3662 - val_acc: 0.2367\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3274 - acc: 0.4771 - val_loss: 2.3573 - val_acc: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3257 - acc: 0.4757 - val_loss: 2.3696 - val_acc: 0.2400\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3264 - acc: 0.4771 - val_loss: 2.3738 - val_acc: 0.2433\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.3260 - acc: 0.4743 - val_loss: 2.3692 - val_acc: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3261 - acc: 0.4786 - val_loss: 2.3801 - val_acc: 0.2433\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3267 - acc: 0.4800 - val_loss: 2.3647 - val_acc: 0.2400\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3260 - acc: 0.4829 - val_loss: 2.3807 - val_acc: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3250 - acc: 0.4729 - val_loss: 2.3746 - val_acc: 0.2433\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3266 - acc: 0.4714 - val_loss: 2.3617 - val_acc: 0.2400\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.3260 - acc: 0.4786 - val_loss: 2.3730 - val_acc: 0.2400\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.3257 - acc: 0.4757 - val_loss: 2.3700 - val_acc: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3260 - acc: 0.4857 - val_loss: 2.3725 - val_acc: 0.2433\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3258 - acc: 0.4800 - val_loss: 2.3697 - val_acc: 0.2400\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.3254 - acc: 0.4757 - val_loss: 2.3739 - val_acc: 0.2400\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 551us/step - loss: 1.3240 - acc: 0.4829 - val_loss: 2.3932 - val_acc: 0.2500\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3265 - acc: 0.4771 - val_loss: 2.3644 - val_acc: 0.2467\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 604us/step - loss: 1.3249 - acc: 0.4814 - val_loss: 2.3718 - val_acc: 0.2400\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3257 - acc: 0.4843 - val_loss: 2.3590 - val_acc: 0.2467\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3252 - acc: 0.4814 - val_loss: 2.3800 - val_acc: 0.2467\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3248 - acc: 0.4757 - val_loss: 2.3752 - val_acc: 0.2400\n",
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 541us/step - loss: 1.3258 - acc: 0.4800 - val_loss: 2.3564 - val_acc: 0.2433\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 550us/step - loss: 1.3248 - acc: 0.4786 - val_loss: 2.3711 - val_acc: 0.2367\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 670us/step - loss: 1.3249 - acc: 0.4843 - val_loss: 2.3988 - val_acc: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 614us/step - loss: 1.3248 - acc: 0.4829 - val_loss: 2.3698 - val_acc: 0.2400\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 579us/step - loss: 1.3245 - acc: 0.4800 - val_loss: 2.3972 - val_acc: 0.2433\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 633us/step - loss: 1.3248 - acc: 0.4700 - val_loss: 2.3553 - val_acc: 0.2400\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.3247 - acc: 0.4786 - val_loss: 2.3612 - val_acc: 0.2433\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 567us/step - loss: 1.3254 - acc: 0.4771 - val_loss: 2.3897 - val_acc: 0.2433\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 640us/step - loss: 1.3246 - acc: 0.4843 - val_loss: 2.3623 - val_acc: 0.2433\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3250 - acc: 0.4857 - val_loss: 2.3691 - val_acc: 0.2433\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 590us/step - loss: 1.3235 - acc: 0.4786 - val_loss: 2.3964 - val_acc: 0.2467\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 1.3243 - acc: 0.4829 - val_loss: 2.3785 - val_acc: 0.2433\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 1s 905us/step - loss: 1.3241 - acc: 0.4729 - val_loss: 2.3774 - val_acc: 0.2433\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 1s 992us/step - loss: 1.3243 - acc: 0.4800 - val_loss: 2.3878 - val_acc: 0.2500\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 600us/step - loss: 1.3243 - acc: 0.4771 - val_loss: 2.3714 - val_acc: 0.2433\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 675us/step - loss: 1.3240 - acc: 0.4800 - val_loss: 2.3904 - val_acc: 0.2467\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 668us/step - loss: 1.3236 - acc: 0.4786 - val_loss: 2.3755 - val_acc: 0.2433\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 1s 881us/step - loss: 1.3238 - acc: 0.4800 - val_loss: 2.3804 - val_acc: 0.2400\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 1s 826us/step - loss: 1.3253 - acc: 0.4786 - val_loss: 2.3683 - val_acc: 0.2400\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 704us/step - loss: 1.3236 - acc: 0.4743 - val_loss: 2.3668 - val_acc: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.3227 - acc: 0.4814 - val_loss: 2.3817 - val_acc: 0.2433\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 625us/step - loss: 1.3237 - acc: 0.4857 - val_loss: 2.3818 - val_acc: 0.2400\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.3234 - acc: 0.4757 - val_loss: 2.3765 - val_acc: 0.2433\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 574us/step - loss: 1.3240 - acc: 0.4800 - val_loss: 2.3825 - val_acc: 0.2400\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3237 - acc: 0.4800 - val_loss: 2.3714 - val_acc: 0.2433\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3241 - acc: 0.4786 - val_loss: 2.3895 - val_acc: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3232 - acc: 0.4771 - val_loss: 2.3897 - val_acc: 0.2467\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.3238 - acc: 0.4786 - val_loss: 2.3759 - val_acc: 0.2433\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3235 - acc: 0.4743 - val_loss: 2.3766 - val_acc: 0.2400\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3235 - acc: 0.4800 - val_loss: 2.3621 - val_acc: 0.2400\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.3229 - acc: 0.4800 - val_loss: 2.3982 - val_acc: 0.2500\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3219 - acc: 0.4757 - val_loss: 2.3771 - val_acc: 0.2467\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3237 - acc: 0.4800 - val_loss: 2.3703 - val_acc: 0.2433\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3227 - acc: 0.4771 - val_loss: 2.3963 - val_acc: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3243 - acc: 0.4771 - val_loss: 2.3741 - val_acc: 0.2467\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3223 - acc: 0.4729 - val_loss: 2.3899 - val_acc: 0.2400\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 576us/step - loss: 1.3227 - acc: 0.4814 - val_loss: 2.3804 - val_acc: 0.2467\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 568us/step - loss: 1.3212 - acc: 0.4757 - val_loss: 2.3707 - val_acc: 0.2433\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3226 - acc: 0.4800 - val_loss: 2.3782 - val_acc: 0.2433\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.3230 - acc: 0.4814 - val_loss: 2.4010 - val_acc: 0.2500\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 601us/step - loss: 1.3225 - acc: 0.4771 - val_loss: 2.3764 - val_acc: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3222 - acc: 0.4800 - val_loss: 2.3784 - val_acc: 0.2433\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3217 - acc: 0.4800 - val_loss: 2.3539 - val_acc: 0.2467\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3232 - acc: 0.4829 - val_loss: 2.3998 - val_acc: 0.2467\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.3225 - acc: 0.4757 - val_loss: 2.3765 - val_acc: 0.2400\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3221 - acc: 0.4814 - val_loss: 2.3508 - val_acc: 0.2500\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3235 - acc: 0.4814 - val_loss: 2.3913 - val_acc: 0.2500\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3218 - acc: 0.4829 - val_loss: 2.3905 - val_acc: 0.2500\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3222 - acc: 0.4800 - val_loss: 2.3667 - val_acc: 0.2400\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3224 - acc: 0.4857 - val_loss: 2.3933 - val_acc: 0.2467\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3212 - acc: 0.4829 - val_loss: 2.3909 - val_acc: 0.2467\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.3216 - acc: 0.4800 - val_loss: 2.4020 - val_acc: 0.2500\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 621us/step - loss: 1.3221 - acc: 0.4771 - val_loss: 2.3998 - val_acc: 0.2533\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3213 - acc: 0.4871 - val_loss: 2.3993 - val_acc: 0.2433\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3213 - acc: 0.4857 - val_loss: 2.3944 - val_acc: 0.2433\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3212 - acc: 0.4829 - val_loss: 2.3740 - val_acc: 0.2433\n",
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.3220 - acc: 0.4800 - val_loss: 2.3655 - val_acc: 0.2433\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3213 - acc: 0.4771 - val_loss: 2.4010 - val_acc: 0.2533\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.3200 - acc: 0.4814 - val_loss: 2.3974 - val_acc: 0.2400\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.3219 - acc: 0.4871 - val_loss: 2.3773 - val_acc: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 544us/step - loss: 1.3208 - acc: 0.4800 - val_loss: 2.3827 - val_acc: 0.2433\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3213 - acc: 0.4800 - val_loss: 2.3958 - val_acc: 0.2467\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.3209 - acc: 0.4814 - val_loss: 2.3944 - val_acc: 0.2500\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3210 - acc: 0.4743 - val_loss: 2.3870 - val_acc: 0.2433\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3205 - acc: 0.4786 - val_loss: 2.3912 - val_acc: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3208 - acc: 0.4829 - val_loss: 2.3908 - val_acc: 0.2433\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.3204 - acc: 0.4814 - val_loss: 2.3869 - val_acc: 0.2467\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3197 - acc: 0.4843 - val_loss: 2.3994 - val_acc: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3207 - acc: 0.4800 - val_loss: 2.3740 - val_acc: 0.2400\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.3209 - acc: 0.4857 - val_loss: 2.3754 - val_acc: 0.2467\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3201 - acc: 0.4814 - val_loss: 2.3894 - val_acc: 0.2433\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3196 - acc: 0.4857 - val_loss: 2.3979 - val_acc: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 557us/step - loss: 1.3201 - acc: 0.4757 - val_loss: 2.3978 - val_acc: 0.2433\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3198 - acc: 0.4871 - val_loss: 2.3710 - val_acc: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3202 - acc: 0.4857 - val_loss: 2.3877 - val_acc: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3201 - acc: 0.4814 - val_loss: 2.3715 - val_acc: 0.2400\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3192 - acc: 0.4743 - val_loss: 2.3856 - val_acc: 0.2467\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3192 - acc: 0.4757 - val_loss: 2.3725 - val_acc: 0.2500\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3198 - acc: 0.4829 - val_loss: 2.3882 - val_acc: 0.2433\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3198 - acc: 0.4771 - val_loss: 2.3911 - val_acc: 0.2467\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3199 - acc: 0.4843 - val_loss: 2.3968 - val_acc: 0.2467\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3199 - acc: 0.4843 - val_loss: 2.3833 - val_acc: 0.2467\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3192 - acc: 0.4843 - val_loss: 2.3947 - val_acc: 0.2433\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3196 - acc: 0.4771 - val_loss: 2.3859 - val_acc: 0.2433\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3195 - acc: 0.4857 - val_loss: 2.4046 - val_acc: 0.2500\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3192 - acc: 0.4843 - val_loss: 2.3699 - val_acc: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3193 - acc: 0.4843 - val_loss: 2.3912 - val_acc: 0.2500\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3195 - acc: 0.4829 - val_loss: 2.3852 - val_acc: 0.2467\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3190 - acc: 0.4829 - val_loss: 2.3842 - val_acc: 0.2433\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3185 - acc: 0.4800 - val_loss: 2.3847 - val_acc: 0.2367\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 507us/step - loss: 1.3185 - acc: 0.4871 - val_loss: 2.3961 - val_acc: 0.2433\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3199 - acc: 0.4786 - val_loss: 2.4044 - val_acc: 0.2467\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3192 - acc: 0.4771 - val_loss: 2.4029 - val_acc: 0.2467\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3195 - acc: 0.4814 - val_loss: 2.3970 - val_acc: 0.2433\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3183 - acc: 0.4871 - val_loss: 2.3924 - val_acc: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3190 - acc: 0.4871 - val_loss: 2.3971 - val_acc: 0.2433\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.3181 - acc: 0.4814 - val_loss: 2.3952 - val_acc: 0.2467\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 628us/step - loss: 1.3185 - acc: 0.4843 - val_loss: 2.3980 - val_acc: 0.2433\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 572us/step - loss: 1.3190 - acc: 0.4900 - val_loss: 2.3926 - val_acc: 0.2400\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 606us/step - loss: 1.3183 - acc: 0.4829 - val_loss: 2.4236 - val_acc: 0.2500\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 640us/step - loss: 1.3189 - acc: 0.4857 - val_loss: 2.3784 - val_acc: 0.2400\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 700us/step - loss: 1.3184 - acc: 0.4814 - val_loss: 2.3919 - val_acc: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3174 - acc: 0.4729 - val_loss: 2.3940 - val_acc: 0.2467\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 670us/step - loss: 1.3190 - acc: 0.4871 - val_loss: 2.4006 - val_acc: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 590us/step - loss: 1.3180 - acc: 0.4771 - val_loss: 2.4062 - val_acc: 0.2467\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 669us/step - loss: 1.3178 - acc: 0.4829 - val_loss: 2.3910 - val_acc: 0.2400\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3183 - acc: 0.4829 - val_loss: 2.3913 - val_acc: 0.2433\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3171 - acc: 0.4786 - val_loss: 2.3995 - val_acc: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3181 - acc: 0.4814 - val_loss: 2.4044 - val_acc: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.3181 - acc: 0.4900 - val_loss: 2.4043 - val_acc: 0.2433\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3168 - acc: 0.4871 - val_loss: 2.3945 - val_acc: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3178 - acc: 0.4771 - val_loss: 2.3942 - val_acc: 0.2433\n",
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 654us/step - loss: 1.3167 - acc: 0.4829 - val_loss: 2.4075 - val_acc: 0.2400\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3175 - acc: 0.4814 - val_loss: 2.3913 - val_acc: 0.2400\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 594us/step - loss: 1.3170 - acc: 0.4886 - val_loss: 2.4295 - val_acc: 0.2467\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3173 - acc: 0.4757 - val_loss: 2.4121 - val_acc: 0.2467\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3175 - acc: 0.4814 - val_loss: 2.3937 - val_acc: 0.2433\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 641us/step - loss: 1.3160 - acc: 0.4843 - val_loss: 2.3828 - val_acc: 0.2433\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3162 - acc: 0.4871 - val_loss: 2.4052 - val_acc: 0.2467\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3164 - acc: 0.4814 - val_loss: 2.3808 - val_acc: 0.2400\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3160 - acc: 0.4829 - val_loss: 2.4132 - val_acc: 0.2467\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3150 - acc: 0.4900 - val_loss: 2.4168 - val_acc: 0.2433\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3161 - acc: 0.4871 - val_loss: 2.3963 - val_acc: 0.2500\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3168 - acc: 0.4829 - val_loss: 2.4043 - val_acc: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3168 - acc: 0.4814 - val_loss: 2.3954 - val_acc: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3155 - acc: 0.4843 - val_loss: 2.3885 - val_acc: 0.2467\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3161 - acc: 0.4800 - val_loss: 2.4002 - val_acc: 0.2467\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3164 - acc: 0.4843 - val_loss: 2.4015 - val_acc: 0.2467\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 644us/step - loss: 1.3157 - acc: 0.4843 - val_loss: 2.3723 - val_acc: 0.2367\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 580us/step - loss: 1.3158 - acc: 0.4857 - val_loss: 2.4048 - val_acc: 0.2433\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3159 - acc: 0.4871 - val_loss: 2.3962 - val_acc: 0.2433\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3163 - acc: 0.4900 - val_loss: 2.3907 - val_acc: 0.2400\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3155 - acc: 0.4857 - val_loss: 2.3978 - val_acc: 0.2433\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3157 - acc: 0.4914 - val_loss: 2.3977 - val_acc: 0.2433\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3155 - acc: 0.4800 - val_loss: 2.3889 - val_acc: 0.2400\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3158 - acc: 0.4829 - val_loss: 2.3919 - val_acc: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3158 - acc: 0.4843 - val_loss: 2.3906 - val_acc: 0.2433\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3150 - acc: 0.4843 - val_loss: 2.4103 - val_acc: 0.2433\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.3146 - acc: 0.4929 - val_loss: 2.4155 - val_acc: 0.2467\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 638us/step - loss: 1.3151 - acc: 0.4829 - val_loss: 2.3879 - val_acc: 0.2367\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3150 - acc: 0.4857 - val_loss: 2.4148 - val_acc: 0.2467\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.3151 - acc: 0.4757 - val_loss: 2.4212 - val_acc: 0.2467\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3150 - acc: 0.4800 - val_loss: 2.4334 - val_acc: 0.2500\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3149 - acc: 0.4871 - val_loss: 2.4126 - val_acc: 0.2467\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3144 - acc: 0.4886 - val_loss: 2.4173 - val_acc: 0.2467\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3145 - acc: 0.4857 - val_loss: 2.4060 - val_acc: 0.2467\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 453us/step - loss: 1.3156 - acc: 0.4857 - val_loss: 2.4068 - val_acc: 0.2400\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3135 - acc: 0.4829 - val_loss: 2.4008 - val_acc: 0.2467\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3147 - acc: 0.4886 - val_loss: 2.3964 - val_acc: 0.2433\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3137 - acc: 0.4814 - val_loss: 2.4073 - val_acc: 0.2400\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3150 - acc: 0.4886 - val_loss: 2.4168 - val_acc: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3140 - acc: 0.4857 - val_loss: 2.4110 - val_acc: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 448us/step - loss: 1.3141 - acc: 0.4886 - val_loss: 2.4095 - val_acc: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3140 - acc: 0.4914 - val_loss: 2.4159 - val_acc: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3137 - acc: 0.4886 - val_loss: 2.4015 - val_acc: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3137 - acc: 0.4814 - val_loss: 2.4114 - val_acc: 0.2433\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3134 - acc: 0.4786 - val_loss: 2.3831 - val_acc: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 466us/step - loss: 1.3144 - acc: 0.4843 - val_loss: 2.4139 - val_acc: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 1.3137 - acc: 0.4886 - val_loss: 2.3916 - val_acc: 0.2433\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3132 - acc: 0.4829 - val_loss: 2.4145 - val_acc: 0.2433\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3134 - acc: 0.4914 - val_loss: 2.4039 - val_acc: 0.2433\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3131 - acc: 0.4829 - val_loss: 2.3698 - val_acc: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3140 - acc: 0.4971 - val_loss: 2.4146 - val_acc: 0.2433\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 450us/step - loss: 1.3131 - acc: 0.4800 - val_loss: 2.4033 - val_acc: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 453us/step - loss: 1.3145 - acc: 0.4857 - val_loss: 2.3946 - val_acc: 0.2467\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.3140 - acc: 0.4900 - val_loss: 2.4337 - val_acc: 0.2467\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3130 - acc: 0.4814 - val_loss: 2.4161 - val_acc: 0.2400\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.3134 - acc: 0.4843 - val_loss: 2.4140 - val_acc: 0.2467\n",
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3128 - acc: 0.4800 - val_loss: 2.4228 - val_acc: 0.2500\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3129 - acc: 0.4871 - val_loss: 2.3903 - val_acc: 0.2433\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3124 - acc: 0.4886 - val_loss: 2.4032 - val_acc: 0.2467\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3127 - acc: 0.4886 - val_loss: 2.4151 - val_acc: 0.2467\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3126 - acc: 0.4857 - val_loss: 2.4183 - val_acc: 0.2467\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 446us/step - loss: 1.3116 - acc: 0.4886 - val_loss: 2.4050 - val_acc: 0.2433\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3118 - acc: 0.4871 - val_loss: 2.3991 - val_acc: 0.2367\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.3124 - acc: 0.4800 - val_loss: 2.3953 - val_acc: 0.2433\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 445us/step - loss: 1.3126 - acc: 0.4871 - val_loss: 2.4228 - val_acc: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.3132 - acc: 0.4843 - val_loss: 2.3961 - val_acc: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3122 - acc: 0.4900 - val_loss: 2.4001 - val_acc: 0.2467\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 455us/step - loss: 1.3125 - acc: 0.4886 - val_loss: 2.4125 - val_acc: 0.2400\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3126 - acc: 0.4943 - val_loss: 2.3855 - val_acc: 0.2433\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3119 - acc: 0.4871 - val_loss: 2.3952 - val_acc: 0.2467\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3126 - acc: 0.4829 - val_loss: 2.4116 - val_acc: 0.2467\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3124 - acc: 0.4843 - val_loss: 2.4134 - val_acc: 0.2433\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3118 - acc: 0.4886 - val_loss: 2.3946 - val_acc: 0.2433\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3114 - acc: 0.4900 - val_loss: 2.4033 - val_acc: 0.2467\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3117 - acc: 0.4886 - val_loss: 2.4090 - val_acc: 0.2467\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3114 - acc: 0.4886 - val_loss: 2.4048 - val_acc: 0.2367\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3122 - acc: 0.4871 - val_loss: 2.3967 - val_acc: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3109 - acc: 0.4914 - val_loss: 2.3843 - val_acc: 0.2400\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3125 - acc: 0.4843 - val_loss: 2.4207 - val_acc: 0.2433\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3121 - acc: 0.4829 - val_loss: 2.4235 - val_acc: 0.2400\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.3116 - acc: 0.4786 - val_loss: 2.4017 - val_acc: 0.2433\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 441us/step - loss: 1.3117 - acc: 0.4914 - val_loss: 2.4323 - val_acc: 0.2467\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 517us/step - loss: 1.3118 - acc: 0.4829 - val_loss: 2.4018 - val_acc: 0.2467\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 455us/step - loss: 1.3110 - acc: 0.4857 - val_loss: 2.4090 - val_acc: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3111 - acc: 0.4929 - val_loss: 2.4256 - val_acc: 0.2467\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3109 - acc: 0.4900 - val_loss: 2.3934 - val_acc: 0.2433\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 495us/step - loss: 1.3113 - acc: 0.4814 - val_loss: 2.4599 - val_acc: 0.2500\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3114 - acc: 0.4800 - val_loss: 2.4228 - val_acc: 0.2467\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3113 - acc: 0.4929 - val_loss: 2.4211 - val_acc: 0.2433\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.3109 - acc: 0.4943 - val_loss: 2.4150 - val_acc: 0.2433\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 491us/step - loss: 1.3115 - acc: 0.4843 - val_loss: 2.4034 - val_acc: 0.2367\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3104 - acc: 0.4829 - val_loss: 2.4073 - val_acc: 0.2467\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.3105 - acc: 0.4843 - val_loss: 2.4340 - val_acc: 0.2467\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3105 - acc: 0.4914 - val_loss: 2.4198 - val_acc: 0.2433\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 2.4246 - val_acc: 0.2500\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3106 - acc: 0.4857 - val_loss: 2.4201 - val_acc: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.3103 - acc: 0.4886 - val_loss: 2.4341 - val_acc: 0.2533\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 2.3914 - val_acc: 0.2433\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3098 - acc: 0.4843 - val_loss: 2.3945 - val_acc: 0.2433\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3108 - acc: 0.4800 - val_loss: 2.4330 - val_acc: 0.2500\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.3105 - acc: 0.4843 - val_loss: 2.4299 - val_acc: 0.2467\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3104 - acc: 0.4900 - val_loss: 2.4405 - val_acc: 0.2467\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3101 - acc: 0.4886 - val_loss: 2.4064 - val_acc: 0.2433\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3098 - acc: 0.4843 - val_loss: 2.4040 - val_acc: 0.2367\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 443us/step - loss: 1.3109 - acc: 0.4871 - val_loss: 2.4111 - val_acc: 0.2400\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.3096 - acc: 0.4829 - val_loss: 2.4292 - val_acc: 0.2433\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3092 - acc: 0.4857 - val_loss: 2.4074 - val_acc: 0.2500\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3098 - acc: 0.4857 - val_loss: 2.4133 - val_acc: 0.2400\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3101 - acc: 0.4800 - val_loss: 2.4148 - val_acc: 0.2367\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3106 - acc: 0.4871 - val_loss: 2.4031 - val_acc: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3093 - acc: 0.4886 - val_loss: 2.4192 - val_acc: 0.2433\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3091 - acc: 0.4900 - val_loss: 2.4129 - val_acc: 0.2433\n",
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 485us/step - loss: 1.3096 - acc: 0.4914 - val_loss: 2.4243 - val_acc: 0.2433\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.3096 - acc: 0.4886 - val_loss: 2.4240 - val_acc: 0.2400\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.3099 - acc: 0.4786 - val_loss: 2.4173 - val_acc: 0.2433\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3089 - acc: 0.4871 - val_loss: 2.4186 - val_acc: 0.2433\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 506us/step - loss: 1.3093 - acc: 0.4900 - val_loss: 2.4488 - val_acc: 0.2467\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.3180 - acc: 0.483 - 0s 494us/step - loss: 1.3098 - acc: 0.4886 - val_loss: 2.4073 - val_acc: 0.2433\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3088 - acc: 0.4929 - val_loss: 2.4195 - val_acc: 0.2400\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3083 - acc: 0.4857 - val_loss: 2.3901 - val_acc: 0.2433\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3094 - acc: 0.4886 - val_loss: 2.4110 - val_acc: 0.2400\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3086 - acc: 0.4914 - val_loss: 2.4286 - val_acc: 0.2467\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3087 - acc: 0.4929 - val_loss: 2.4221 - val_acc: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3087 - acc: 0.4829 - val_loss: 2.4059 - val_acc: 0.2400\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3077 - acc: 0.4843 - val_loss: 2.4383 - val_acc: 0.2467\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3093 - acc: 0.4943 - val_loss: 2.4261 - val_acc: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3086 - acc: 0.4900 - val_loss: 2.4164 - val_acc: 0.2433\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.3089 - acc: 0.4900 - val_loss: 2.4185 - val_acc: 0.2400\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3089 - acc: 0.4914 - val_loss: 2.4207 - val_acc: 0.2467\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.3090 - acc: 0.4843 - val_loss: 2.4140 - val_acc: 0.2500\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.3084 - acc: 0.4871 - val_loss: 2.4402 - val_acc: 0.2533\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3087 - acc: 0.4871 - val_loss: 2.4347 - val_acc: 0.2467\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3079 - acc: 0.4900 - val_loss: 2.4303 - val_acc: 0.2433\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3081 - acc: 0.4871 - val_loss: 2.4405 - val_acc: 0.2467\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3081 - acc: 0.4829 - val_loss: 2.4127 - val_acc: 0.2500\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3078 - acc: 0.4886 - val_loss: 2.4095 - val_acc: 0.2467\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3082 - acc: 0.4886 - val_loss: 2.4439 - val_acc: 0.2433\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3080 - acc: 0.4971 - val_loss: 2.4416 - val_acc: 0.2467\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3085 - acc: 0.4886 - val_loss: 2.4079 - val_acc: 0.2367\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3078 - acc: 0.4857 - val_loss: 2.4339 - val_acc: 0.2500\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3077 - acc: 0.4900 - val_loss: 2.4147 - val_acc: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.3076 - acc: 0.4914 - val_loss: 2.4297 - val_acc: 0.2433\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.3085 - acc: 0.4929 - val_loss: 2.4188 - val_acc: 0.2433\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.3080 - acc: 0.4900 - val_loss: 2.4106 - val_acc: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.3071 - acc: 0.4957 - val_loss: 2.4148 - val_acc: 0.2467\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3077 - acc: 0.4986 - val_loss: 2.4366 - val_acc: 0.2400\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3074 - acc: 0.4857 - val_loss: 2.4097 - val_acc: 0.2400\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3073 - acc: 0.4886 - val_loss: 2.4056 - val_acc: 0.2467\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 508us/step - loss: 1.3073 - acc: 0.4929 - val_loss: 2.4193 - val_acc: 0.2400\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.3069 - acc: 0.4829 - val_loss: 2.4483 - val_acc: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 451us/step - loss: 1.3071 - acc: 0.4900 - val_loss: 2.4542 - val_acc: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 495us/step - loss: 1.3083 - acc: 0.4943 - val_loss: 2.4364 - val_acc: 0.2433\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 442us/step - loss: 1.3068 - acc: 0.4886 - val_loss: 2.4372 - val_acc: 0.2467\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 468us/step - loss: 1.3065 - acc: 0.4829 - val_loss: 2.4319 - val_acc: 0.2433\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.3073 - acc: 0.4914 - val_loss: 2.4321 - val_acc: 0.2467\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3069 - acc: 0.4900 - val_loss: 2.4356 - val_acc: 0.2467\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.3068 - acc: 0.4857 - val_loss: 2.4202 - val_acc: 0.2433\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3055 - acc: 0.4871 - val_loss: 2.4181 - val_acc: 0.2500\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3071 - acc: 0.4929 - val_loss: 2.4139 - val_acc: 0.2500\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.3061 - acc: 0.4957 - val_loss: 2.4186 - val_acc: 0.2467\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 505us/step - loss: 1.3066 - acc: 0.4929 - val_loss: 2.4181 - val_acc: 0.2467\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.3062 - acc: 0.4843 - val_loss: 2.4270 - val_acc: 0.2367\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.3069 - acc: 0.4886 - val_loss: 2.4316 - val_acc: 0.2400\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3063 - acc: 0.4957 - val_loss: 2.4135 - val_acc: 0.2433\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.3052 - acc: 0.4914 - val_loss: 2.4363 - val_acc: 0.2433\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.3072 - acc: 0.4929 - val_loss: 2.4338 - val_acc: 0.2433\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3060 - acc: 0.4857 - val_loss: 2.4356 - val_acc: 0.2467\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.3064 - acc: 0.4843 - val_loss: 2.4296 - val_acc: 0.2433\n",
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.3057 - acc: 0.4857 - val_loss: 2.4375 - val_acc: 0.2400\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.3060 - acc: 0.4914 - val_loss: 2.4558 - val_acc: 0.2467\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.3064 - acc: 0.4886 - val_loss: 2.4373 - val_acc: 0.2467\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 451us/step - loss: 1.3060 - acc: 0.4886 - val_loss: 2.4383 - val_acc: 0.2500\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.3055 - acc: 0.4900 - val_loss: 2.4406 - val_acc: 0.2467\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.3061 - acc: 0.4929 - val_loss: 2.4216 - val_acc: 0.2400\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3054 - acc: 0.4957 - val_loss: 2.4360 - val_acc: 0.2500\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3059 - acc: 0.4900 - val_loss: 2.4479 - val_acc: 0.2433\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 459us/step - loss: 1.3069 - acc: 0.4943 - val_loss: 2.4218 - val_acc: 0.2400\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3053 - acc: 0.4900 - val_loss: 2.4370 - val_acc: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 499us/step - loss: 1.3043 - acc: 0.4957 - val_loss: 2.4284 - val_acc: 0.2433\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.3055 - acc: 0.4886 - val_loss: 2.4079 - val_acc: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.3062 - acc: 0.4900 - val_loss: 2.4512 - val_acc: 0.2467\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3043 - acc: 0.4943 - val_loss: 2.4259 - val_acc: 0.2467\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.3050 - acc: 0.4900 - val_loss: 2.4364 - val_acc: 0.2400\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.3046 - acc: 0.4914 - val_loss: 2.3958 - val_acc: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 539us/step - loss: 1.3055 - acc: 0.4957 - val_loss: 2.4380 - val_acc: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 497us/step - loss: 1.3050 - acc: 0.4929 - val_loss: 2.4383 - val_acc: 0.2467\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3057 - acc: 0.5000 - val_loss: 2.4404 - val_acc: 0.2433\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3043 - acc: 0.4971 - val_loss: 2.4513 - val_acc: 0.2467\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 591us/step - loss: 1.3046 - acc: 0.4929 - val_loss: 2.4207 - val_acc: 0.2467\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 524us/step - loss: 1.3045 - acc: 0.5014 - val_loss: 2.4483 - val_acc: 0.2467\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.3049 - acc: 0.4914 - val_loss: 2.4389 - val_acc: 0.2467\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.3043 - acc: 0.4943 - val_loss: 2.4358 - val_acc: 0.2400\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 664us/step - loss: 1.3049 - acc: 0.4943 - val_loss: 2.4226 - val_acc: 0.2467\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.3051 - acc: 0.4886 - val_loss: 2.4470 - val_acc: 0.2467\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 541us/step - loss: 1.3043 - acc: 0.4914 - val_loss: 2.4295 - val_acc: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.3046 - acc: 0.4957 - val_loss: 2.4337 - val_acc: 0.2400\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.3047 - acc: 0.4886 - val_loss: 2.4299 - val_acc: 0.2433\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3046 - acc: 0.4914 - val_loss: 2.4447 - val_acc: 0.2433\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.3040 - acc: 0.4943 - val_loss: 2.4310 - val_acc: 0.2433\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3049 - acc: 0.4886 - val_loss: 2.4289 - val_acc: 0.2433\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.3039 - acc: 0.4886 - val_loss: 2.4583 - val_acc: 0.2533\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.3044 - acc: 0.4929 - val_loss: 2.4295 - val_acc: 0.2467\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 546us/step - loss: 1.3046 - acc: 0.4900 - val_loss: 2.4616 - val_acc: 0.2467\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.3043 - acc: 0.4914 - val_loss: 2.4408 - val_acc: 0.2433\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.3043 - acc: 0.4929 - val_loss: 2.4442 - val_acc: 0.2433\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.3038 - acc: 0.4929 - val_loss: 2.4266 - val_acc: 0.2433\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.3039 - acc: 0.4957 - val_loss: 2.4255 - val_acc: 0.2467\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.3037 - acc: 0.4900 - val_loss: 2.4263 - val_acc: 0.2467\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 512us/step - loss: 1.3035 - acc: 0.4914 - val_loss: 2.4576 - val_acc: 0.2467\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 483us/step - loss: 1.3035 - acc: 0.4986 - val_loss: 2.4452 - val_acc: 0.2467\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.3036 - acc: 0.4914 - val_loss: 2.4384 - val_acc: 0.2433\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 487us/step - loss: 1.3032 - acc: 0.4929 - val_loss: 2.4405 - val_acc: 0.2500\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.3030 - acc: 0.4829 - val_loss: 2.4574 - val_acc: 0.2467\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.3029 - acc: 0.4914 - val_loss: 2.4499 - val_acc: 0.2433\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.3040 - acc: 0.4900 - val_loss: 2.4274 - val_acc: 0.2400\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 514us/step - loss: 1.3029 - acc: 0.4829 - val_loss: 2.4446 - val_acc: 0.2467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23ebed30b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tensorboard\n",
    "import keras\n",
    "tb_hist=keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
    "model.fit(x_train, y_train, epochs=1000, batch_size=10, validation_data=(x_val, y_val), callbacks=[tb_hist])\n",
    "# 命令行tensorboard --logdir=D:\\Projects\\python_projects\\DA_and_ML\\graph --host=127.0.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 1s 783us/step - loss: 2.2576 - acc: 0.1643 - val_loss: 2.2272 - val_acc: 0.1633\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 518us/step - loss: 2.2072 - acc: 0.1657 - val_loss: 2.1908 - val_acc: 0.1800\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 2.1730 - acc: 0.1729 - val_loss: 2.1631 - val_acc: 0.1867\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 2.1441 - acc: 0.1786 - val_loss: 2.1372 - val_acc: 0.1867\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 2.1177 - acc: 0.1900 - val_loss: 2.1141 - val_acc: 0.1867\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 2.0940 - acc: 0.2029 - val_loss: 2.0931 - val_acc: 0.2033\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 452us/step - loss: 2.0721 - acc: 0.2071 - val_loss: 2.0727 - val_acc: 0.2067\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 525us/step - loss: 2.0520 - acc: 0.2129 - val_loss: 2.0564 - val_acc: 0.2067\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 2.0342 - acc: 0.2157 - val_loss: 2.0410 - val_acc: 0.2033\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 456us/step - loss: 2.0190 - acc: 0.2143 - val_loss: 2.0269 - val_acc: 0.2067\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - ETA: 0s - loss: 1.9978 - acc: 0.224 - 0s 552us/step - loss: 2.0041 - acc: 0.2186 - val_loss: 2.0125 - val_acc: 0.2100\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.9911 - acc: 0.2200 - val_loss: 2.0037 - val_acc: 0.2100\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.9789 - acc: 0.2286 - val_loss: 1.9955 - val_acc: 0.2100\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 559us/step - loss: 1.9685 - acc: 0.2329 - val_loss: 1.9833 - val_acc: 0.2067\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 457us/step - loss: 1.9582 - acc: 0.2214 - val_loss: 1.9753 - val_acc: 0.2100\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 486us/step - loss: 1.9484 - acc: 0.2357 - val_loss: 1.9686 - val_acc: 0.2000\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 632us/step - loss: 1.9393 - acc: 0.2343 - val_loss: 1.9612 - val_acc: 0.2033\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 472us/step - loss: 1.9309 - acc: 0.2314 - val_loss: 1.9537 - val_acc: 0.2100\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.9232 - acc: 0.2286 - val_loss: 1.9452 - val_acc: 0.2100\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.9156 - acc: 0.2386 - val_loss: 1.9392 - val_acc: 0.2100\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 549us/step - loss: 1.9085 - acc: 0.2343 - val_loss: 1.9363 - val_acc: 0.2100\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 533us/step - loss: 1.9011 - acc: 0.2386 - val_loss: 1.9289 - val_acc: 0.2033\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 492us/step - loss: 1.8954 - acc: 0.2357 - val_loss: 1.9234 - val_acc: 0.2100\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.8895 - acc: 0.2314 - val_loss: 1.9201 - val_acc: 0.2067\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 529us/step - loss: 1.8830 - acc: 0.2343 - val_loss: 1.9178 - val_acc: 0.2167\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.8769 - acc: 0.2300 - val_loss: 1.9105 - val_acc: 0.2167\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.8715 - acc: 0.2357 - val_loss: 1.9098 - val_acc: 0.2167\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.8662 - acc: 0.2400 - val_loss: 1.9094 - val_acc: 0.2000\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.8615 - acc: 0.2400 - val_loss: 1.9041 - val_acc: 0.1900\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 537us/step - loss: 1.8565 - acc: 0.2243 - val_loss: 1.8976 - val_acc: 0.2167\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.8513 - acc: 0.2471 - val_loss: 1.8971 - val_acc: 0.1933\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 501us/step - loss: 1.8463 - acc: 0.2371 - val_loss: 1.8925 - val_acc: 0.1900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.8423 - acc: 0.2229 - val_loss: 1.8874 - val_acc: 0.2067\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 508us/step - loss: 1.8382 - acc: 0.2371 - val_loss: 1.8808 - val_acc: 0.1933\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.8335 - acc: 0.2471 - val_loss: 1.8836 - val_acc: 0.1900\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 553us/step - loss: 1.8299 - acc: 0.2343 - val_loss: 1.8756 - val_acc: 0.1967\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.8257 - acc: 0.2486 - val_loss: 1.8745 - val_acc: 0.1800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 464us/step - loss: 1.8220 - acc: 0.2371 - val_loss: 1.8700 - val_acc: 0.1933\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 521us/step - loss: 1.8184 - acc: 0.2457 - val_loss: 1.8706 - val_acc: 0.1767\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 463us/step - loss: 1.8144 - acc: 0.2314 - val_loss: 1.8677 - val_acc: 0.2000\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.8105 - acc: 0.2400 - val_loss: 1.8668 - val_acc: 0.1833\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 526us/step - loss: 1.8075 - acc: 0.2471 - val_loss: 1.8635 - val_acc: 0.1800\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.8046 - acc: 0.2429 - val_loss: 1.8611 - val_acc: 0.1700\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.8001 - acc: 0.2371 - val_loss: 1.8566 - val_acc: 0.1967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.7970 - acc: 0.2429 - val_loss: 1.8564 - val_acc: 0.1700\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 475us/step - loss: 1.7939 - acc: 0.2271 - val_loss: 1.8528 - val_acc: 0.1933\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 554us/step - loss: 1.7913 - acc: 0.2600 - val_loss: 1.8551 - val_acc: 0.1833\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 535us/step - loss: 1.7886 - acc: 0.2471 - val_loss: 1.8543 - val_acc: 0.1867\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 442us/step - loss: 1.7858 - acc: 0.2486 - val_loss: 1.8504 - val_acc: 0.1867\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.7819 - acc: 0.2471 - val_loss: 1.8443 - val_acc: 0.2267\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.7794 - acc: 0.2643 - val_loss: 1.8468 - val_acc: 0.1900\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 458us/step - loss: 1.7762 - acc: 0.2486 - val_loss: 1.8411 - val_acc: 0.1933\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 503us/step - loss: 1.7744 - acc: 0.2514 - val_loss: 1.8486 - val_acc: 0.2000\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.7716 - acc: 0.2700 - val_loss: 1.8472 - val_acc: 0.1800\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 460us/step - loss: 1.7687 - acc: 0.2500 - val_loss: 1.8364 - val_acc: 0.2033\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 547us/step - loss: 1.7672 - acc: 0.2543 - val_loss: 1.8430 - val_acc: 0.2200\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.7641 - acc: 0.2714 - val_loss: 1.8390 - val_acc: 0.2167\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.7616 - acc: 0.2557 - val_loss: 1.8347 - val_acc: 0.2267\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 536us/step - loss: 1.7590 - acc: 0.2671 - val_loss: 1.8329 - val_acc: 0.2233\n",
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.7552 - acc: 0.2614 - val_loss: 1.8256 - val_acc: 0.2500\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 462us/step - loss: 1.7566 - acc: 0.2814 - val_loss: 1.8336 - val_acc: 0.2400\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 513us/step - loss: 1.7531 - acc: 0.2729 - val_loss: 1.8312 - val_acc: 0.2267\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.7505 - acc: 0.2857 - val_loss: 1.8299 - val_acc: 0.2000\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 479us/step - loss: 1.7484 - acc: 0.2800 - val_loss: 1.8268 - val_acc: 0.2200\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 527us/step - loss: 1.7457 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2033\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 470us/step - loss: 1.7439 - acc: 0.2786 - val_loss: 1.8296 - val_acc: 0.2067\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.7419 - acc: 0.2700 - val_loss: 1.8299 - val_acc: 0.2067\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 525us/step - loss: 1.7405 - acc: 0.2729 - val_loss: 1.8238 - val_acc: 0.2000\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 485us/step - loss: 1.7376 - acc: 0.2814 - val_loss: 1.8298 - val_acc: 0.2167\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.7356 - acc: 0.2857 - val_loss: 1.8269 - val_acc: 0.2433\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 511us/step - loss: 1.7345 - acc: 0.2800 - val_loss: 1.8214 - val_acc: 0.2167\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 438us/step - loss: 1.7328 - acc: 0.2857 - val_loss: 1.8226 - val_acc: 0.2133\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.7298 - acc: 0.2800 - val_loss: 1.8252 - val_acc: 0.2467\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 519us/step - loss: 1.7283 - acc: 0.2857 - val_loss: 1.8257 - val_acc: 0.1967\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.7268 - acc: 0.2786 - val_loss: 1.8190 - val_acc: 0.2267\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 489us/step - loss: 1.7255 - acc: 0.2857 - val_loss: 1.8196 - val_acc: 0.2233\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.7228 - acc: 0.3057 - val_loss: 1.8232 - val_acc: 0.2033\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 449us/step - loss: 1.7212 - acc: 0.2857 - val_loss: 1.8187 - val_acc: 0.1933\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 593us/step - loss: 1.7199 - acc: 0.2829 - val_loss: 1.8203 - val_acc: 0.2433\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 647us/step - loss: 1.7188 - acc: 0.2929 - val_loss: 1.8197 - val_acc: 0.2067\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.7165 - acc: 0.2843 - val_loss: 1.8256 - val_acc: 0.2067\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.7142 - acc: 0.2829 - val_loss: 1.8144 - val_acc: 0.2667\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 496us/step - loss: 1.7132 - acc: 0.2857 - val_loss: 1.8190 - val_acc: 0.2400\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.7127 - acc: 0.2986 - val_loss: 1.8220 - val_acc: 0.2167\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.7097 - acc: 0.2971 - val_loss: 1.8159 - val_acc: 0.2267\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 484us/step - loss: 1.7082 - acc: 0.2800 - val_loss: 1.8136 - val_acc: 0.2633\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.7051 - acc: 0.3100 - val_loss: 1.8191 - val_acc: 0.2733\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 455us/step - loss: 1.7062 - acc: 0.3043 - val_loss: 1.8125 - val_acc: 0.2433\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 480us/step - loss: 1.7043 - acc: 0.3043 - val_loss: 1.8167 - val_acc: 0.2167\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.7027 - acc: 0.2843 - val_loss: 1.8151 - val_acc: 0.2233\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 560us/step - loss: 1.7017 - acc: 0.3086 - val_loss: 1.8185 - val_acc: 0.2167\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 488us/step - loss: 1.6987 - acc: 0.3129 - val_loss: 1.8215 - val_acc: 0.2067\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.6980 - acc: 0.3071 - val_loss: 1.8173 - val_acc: 0.2767\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 502us/step - loss: 1.6970 - acc: 0.3157 - val_loss: 1.8176 - val_acc: 0.2100\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.6943 - acc: 0.2986 - val_loss: 1.8194 - val_acc: 0.2833\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 500us/step - loss: 1.6948 - acc: 0.3014 - val_loss: 1.8095 - val_acc: 0.2233\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 477us/step - loss: 1.6930 - acc: 0.3057 - val_loss: 1.8228 - val_acc: 0.2300\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.6921 - acc: 0.3043 - val_loss: 1.8117 - val_acc: 0.2200\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 493us/step - loss: 1.6901 - acc: 0.3129 - val_loss: 1.8252 - val_acc: 0.2233\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 515us/step - loss: 1.6890 - acc: 0.3129 - val_loss: 1.8210 - val_acc: 0.2267\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.6878 - acc: 0.3143 - val_loss: 1.8190 - val_acc: 0.2200\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 516us/step - loss: 1.6877 - acc: 0.3014 - val_loss: 1.8219 - val_acc: 0.2300\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.6843 - acc: 0.3000 - val_loss: 1.8102 - val_acc: 0.2500\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 520us/step - loss: 1.6842 - acc: 0.3200 - val_loss: 1.8122 - val_acc: 0.2200\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 534us/step - loss: 1.6821 - acc: 0.3071 - val_loss: 1.8063 - val_acc: 0.2067\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 469us/step - loss: 1.6814 - acc: 0.3114 - val_loss: 1.8173 - val_acc: 0.2200\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 523us/step - loss: 1.6805 - acc: 0.3071 - val_loss: 1.8228 - val_acc: 0.2367\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.6784 - acc: 0.3071 - val_loss: 1.8167 - val_acc: 0.2767\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 498us/step - loss: 1.6782 - acc: 0.3143 - val_loss: 1.8178 - val_acc: 0.2300\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 540us/step - loss: 1.6775 - acc: 0.3171 - val_loss: 1.8147 - val_acc: 0.2133\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 510us/step - loss: 1.6775 - acc: 0.3043 - val_loss: 1.8173 - val_acc: 0.2233\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 474us/step - loss: 1.6745 - acc: 0.3129 - val_loss: 1.8193 - val_acc: 0.2267\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 505us/step - loss: 1.6737 - acc: 0.3100 - val_loss: 1.8196 - val_acc: 0.2300\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.6724 - acc: 0.3014 - val_loss: 1.8221 - val_acc: 0.2300\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 467us/step - loss: 1.6711 - acc: 0.3071 - val_loss: 1.8128 - val_acc: 0.2333\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 509us/step - loss: 1.6703 - acc: 0.3157 - val_loss: 1.8255 - val_acc: 0.2300\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 476us/step - loss: 1.6694 - acc: 0.3100 - val_loss: 1.8228 - val_acc: 0.2333\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 485us/step - loss: 1.6682 - acc: 0.3114 - val_loss: 1.8262 - val_acc: 0.2333\n",
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 644us/step - loss: 1.6670 - acc: 0.3257 - val_loss: 1.8216 - val_acc: 0.2200\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 617us/step - loss: 1.6661 - acc: 0.3129 - val_loss: 1.8219 - val_acc: 0.2200\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 531us/step - loss: 1.6646 - acc: 0.3071 - val_loss: 1.8132 - val_acc: 0.2233\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 494us/step - loss: 1.6637 - acc: 0.3229 - val_loss: 1.8194 - val_acc: 0.2200\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 481us/step - loss: 1.6629 - acc: 0.3100 - val_loss: 1.8139 - val_acc: 0.2200\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.6619 - acc: 0.3143 - val_loss: 1.8187 - val_acc: 0.2267\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 461us/step - loss: 1.6606 - acc: 0.3257 - val_loss: 1.8212 - val_acc: 0.2333\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 478us/step - loss: 1.6592 - acc: 0.3143 - val_loss: 1.8245 - val_acc: 0.2233\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 504us/step - loss: 1.6583 - acc: 0.3129 - val_loss: 1.8147 - val_acc: 0.2333\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 471us/step - loss: 1.6565 - acc: 0.3300 - val_loss: 1.8280 - val_acc: 0.2300\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 482us/step - loss: 1.6570 - acc: 0.3143 - val_loss: 1.8193 - val_acc: 0.2200\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 490us/step - loss: 1.6548 - acc: 0.3214 - val_loss: 1.8124 - val_acc: 0.2533\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 448us/step - loss: 1.6547 - acc: 0.3229 - val_loss: 1.8202 - val_acc: 0.2500\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 543us/step - loss: 1.6545 - acc: 0.3200 - val_loss: 1.8133 - val_acc: 0.2267\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 556us/step - loss: 1.6524 - acc: 0.3143 - val_loss: 1.8317 - val_acc: 0.2400\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 473us/step - loss: 1.6514 - acc: 0.3214 - val_loss: 1.8226 - val_acc: 0.2733\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 530us/step - loss: 1.6512 - acc: 0.3314 - val_loss: 1.8233 - val_acc: 0.2267\n"
     ]
    }
   ],
   "source": [
    "# 早停\n",
    "from keras.callbacks import EarlyStopping\n",
    "es=EarlyStopping(monitor='val_loss', min_delta=0, patience=30, verbose=0, mode='auto')\n",
    "es_hist=model.fit(x_train, y_train, epochs=3000, batch_size=10, validation_data=(x_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23ec6f96048>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAEGCAYAAADv6ntBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAACeJklEQVR4nOydd3gU1frHP2d30zY9IQ1C6L0lgEhREBUFLKhY8Nrr9VoRr9eueNWflWsv194LtmtDsIGogPQqHUISSEjvfff8/jg7u7ObTbLphMznefbZ3Zk5M2c3MN99y3lfIaXEwMDAwMCgM2Pq6AkYGBgYGBi0FEPMDAwMDAw6PYaYGRgYGBh0egwxMzAwMDDo9BhiZmBgYGDQ6bF09ASaislkkkFBQR09DQMDA4NORXl5uZRSHrUGTKcTs6CgIMrKyjp6GgYGBgadCiFERUfPoS05alXawMDAwKDrYIiZgYGBgUGnxxAzAwMDA4NOT6eLmXmjpqaGjIwMKisrO3oqnZbAwEASExPx8/Pr6KkYGBgYNJmjQswyMjIIDQ2ld+/eCCE6ejqdDikleXl5ZGRk0KdPn46ejoGBgUGTOSrcjJWVlURHRxtC1kyEEERHRxuWrYGBQaflqBAzwBCyFmJ8fwYGBp2Zo0bMGsNmq6CqKgO7vbajp2JgYGDQZB58EH76qaNnceTSZcTMbq+iujoLKata/dyFhYW89NJLzRo7c+ZMCgsLfT5+/vz5PPXUU826loGBQeektFSJ2R9/dPRMjly6jJiZTAEA2O2tHxdqSMxsNluDYxctWkRERESrz8nAwODI4q674MMPmzd282aQEkaPbt05HU10QTFrfcvszjvvZO/evSQnJ3P77bezbNkypk6dyt/+9jdGjBgBwFlnncWYMWMYNmwYr776qnNs7969yc3NJTU1lSFDhnDNNdcwbNgwTjnlFCoqGq4+s3HjRsaPH8/IkSM5++yzKSgoAOC5555j6NChjBw5kjlz5gDw66+/kpycTHJyMikpKZSUlLT692BgYFA/L70EH3zQvLHr16vnlJTWm8/RxlGRmq9n9+65lJZu9LrPZitFCAsmU2CTzhkSksyAAc/Uu/+xxx5j69atbNyorrts2TJWr17N1q1bnanub775JlFRUVRUVHDMMccwe/ZsoqOjPea+m48++ojXXnuN888/n88//5yLL7643uteeumlPP/880yZMoX777+fBx98kGeeeYbHHnuM/fv3ExAQ4HRhPvXUU7z44otMmjSJ0tJSAgOb9h0YGBg0n+Ji9ThwoHnjN2yAmBjo0aN153U00WUsMwAhTIC9Xa41btw4tzVbzz33HKNGjWL8+PGkp6eze/fuOmP69OlDcnIyAGPGjCE1NbXe8xcVFVFYWMiUKVMAuOyyy1i+fDkAI0eO5KKLLuL999/HYlG/VyZNmsS8efN47rnnKCwsdG43MDBoe9LT1XNqqnIXNpX165VVZiQd189Rd0dryIKqqEjFZisiJGRUm88jODjY+XrZsmX89NNPrFy5EqvVygknnOB1TVdAQIDztdlsbtTNWB/fffcdy5cv5+uvv+ahhx5i27Zt3HnnnZx22mksWrSI8ePH89NPPzF48OBmnd/AwKBpZGSo57IyyM8HD6dMg1RVwbZtcOqpbTM3PUKI6cCzgBl4XUr5mMf+WcBDKKugFpgrpfxdCNETeBeId+x7VUr5rGPMfOAaIMdxmrullItae+5dyjIzmQKQsgYpG07KaCqhoaENxqCKioqIjIzEarWyY8cOVq1a1eJrhoeHExkZyW+//QbAe++9x5QpU7Db7aSnpzN16lSeeOIJCgsLKS0tZe/evYwYMYI77riDsWPHsmPHjhbPwcDgaCU9Hc4/H5oaWn7nHXj8ce/n02jA4eKVbdugpqbtkz+EEGbgRWAGMBS4UAgx1OOwn4FRUspk4Ergdcf2WuA2KeUQYDxwg8fYp6WUyY5HqwsZdEExg9ZPAomOjmbSpEkMHz6c22+/vc7+6dOnU1tby8iRI7nvvvsYP358q1z3nXfe4fbbb2fkyJFs3LiR+++/H5vNxsUXX8yIESNISUnh1ltvJSIigmeeeYbhw4czatQogoKCmDFjRqvMwcDgaGTxYvj0U1ixomnjXnoJnnyyritRL2ZNjZtt2KCe2yH5YxywR0q5T0pZDXwMzNIfIKUsldL56YIB6dieKaVc73hdAmwH2jfCJ6XsVA+r1So9+euvv+ps80ZtbaksLl4jq6vzfTq+q+Hr92hgcLRz551SgpTPPef7GJtNyuBgNS4ry33fFVdIGRKi9i1Y0LS5XH+9lKGh6vwtAagC1uoe10rdvRU4F+Va1N5fArwgPe7BwNnADiAfmOBlf28gDQhzvJ8PpAKbgTeBSM8xrfHoOpZZWRmmA4fB1jbp+QYGBkcPe/eq55076+7Ly4Nly+puT0tTMTFQrkE96ekwbBiEhta1zOx2+N//VCzNGxs2QHIymFp+t66VUo7VPV712O8tvaROuoqU8ksp5WDgLFT8zHUCIUKAz1GxtGLH5peBfkAykAksaNGnqIeuI2a1tYj8fMxVpjapAmJgYHD0oInZrl119z39NJx8sqrKoUcvYN7ErGdP6NXLPWZ2+DDMmAFnnw1/+1td96TNBps2tdti6Qygp+59InCovoOllMuBfkKIbgBCCD+UkH0gpfxCd9xhKaVNSmkHXkO5M1udriNmVisAlmqLYZkZGBg0yL596tmbZbZ3rxKZPXvct2sCFhzsLmZSqmzGxETo3dtlme3fryyu5ctVssmSJfDaa+7n3LULysvbbbH0GmCAEKKPEMIfmAN8rT9ACNFfOKqSCyFGA/5AnmPbG8B2KeV/PMYk6N6eDWxti8kfdan59eLnB35+mKrapqSVgYHB0UF+PhQWQlSUch1WVEBQkGu/JkY7dyox0ti6VS1q7tNHvdYoLFTux549VVaiIwGZ995Tltn69TByJOTmwm23wSmnKNED+PVX9dxKOWMNIqWsFULcCCxBpea/KaXcJoS4zrH/FWA2cKkQogaoAC6QUkohxHGoGNsWIcRGxym1FPwnhBDJKJdlKvD3tph/1xEzAKsVU2UZUtYipd2xiNrAwOBI4aefYM4cZZFERXXMHDSr7JRT4OOPlQXmqEoHuNyEni7IbdtUXKxPH/jkE2WRCeHKZOzZU8XHioqUwP34o3IfaoL45pvqOvPmwRcOJ92PP6pxAwe20Yf1wCE+izy2vaJ7/ThQZ/GBlPJ3vMfckFJe0srT9ErXuptbrYjKWrCD3V7d0bMxMDDwYO1alWCxeXPHzUGLl2mrV/SuxqoqyMxUr/ViZrfD9u1KzIYPV2KlHacXs1691OutW2HVKpg2zXWOXr3gmmvg22/VeJsNfvlFHWNU/micridmgKmaDk8CCQkJadJ2A4OugDehaG80y2z69Lpz0a8X04vc/v3KHTl8uBI0cMXN9GKmuQ/feQdqa93FDFTsrKZGZTeuXatEzfMYA++0mZgJIXoKIZYKIbYLIbYJIW7xcsxFQojNjscKIUTb1plyJIGYK424mYHBkUhWlnpuqpi98gq8+27rzGHvXoiLg9hYlbShFy3NxThsmJqjln2oxcg0ywzcxcxshvh4l2X20UcqDjdpkvu1x41TxyxcqFyMQqjMSYPGaUvLrLHyJgD7gSlSypGo9Qqe6x5aF39/pNmMqcqEzVbeaqe944473PqZzZ8/nwULFlBaWspJJ53E6NGjGTFiBF999ZXP55RScvvttzN8+HBGjBjBJ598AkBmZiaTJ08mOTmZ4cOH89tvv2Gz2bj88sudxz799NOt9tkMDNoTzTLzlkVYH7//DtdfrypvtAZ790Lfvur1wIHuwqolf5xyiop9ZWer95pwDR2qqtvHxLgELiMDundXghYTo0SsrAymTAFdOVZAidf55ysh+/RTlcXYrVvrfK6jnTZLAJFSZqIWyCGlLBFCaOVN/tIdoy8Wswq1rqFlzJ0LjlYs3hDl5fhJO+ZAAebgeo9zIzkZnnmm3t1z5sxh7ty5XH/99QAsXLiQxYsXExgYyJdffklYWBi5ubmMHz+eM888E+GDA/yLL75g48aNbNq0idzcXI455hgmT57Mhx9+yKmnnso999yDzWajvLycjRs3cvDgQbY6/vc0pXO1gUFTKSyEUaPg1Vdbv/htU92MZWVwxRXKQtq9W8WufF1cnJurEi7eftv9c+zbB5Mnq9cDB7onc6SmqvOfeKJab7Zrl7Litm2DpCS1KBqUhaa3zHo6Vm8JoSyvHTvqdx9ecIES5s2b4Y47fPssBu0UMxNC9AZSgD8bOOwq4Pt6xl8rhFgrhFhbW1vbssmYzWCXSOzIuovbm0VKSgrZ2dkcOnSITZs2ERkZSVJSElJK7r77bkaOHMnJJ5/MwYMHOXz4sE/n/P3337nwwgsxm83ExcUxZcoU1qxZwzHHHMNbb73F/Pnz2bJlC6GhofTt25d9+/Zx0003sXjxYsLCwlrlcxkYeGPFCpWyvnJl88bbbOoc3lqhaG7GfftU7Kgx7rpLZRtedJFKzkhL830ey5er6/33v65tVVVKfPr1U+8HDYKCApWUAsoyS0x0xcU00d22zeVeBPV62zb1GfViBq64WX1iNnq0yzI04mW+0+ap+fWUN/E8ZipKzI7ztt9RduVVgODg4IYVqAELCoDcXERqKlW9ISBiMBZL6yRcnHvuuXz22WdkZWU5uzt/8MEH5OTksG7dOvz8/Ojdu7fX1i/ekPU0PZo8eTLLly/nu+++45JLLuH222/n0ksvZdOmTSxZsoQXX3yRhQsX8uabb7bK5zIw8EQrvqtPhvCVQ4fg4oth6VL4+ms44wzXvtJS9Rg6FP76SyVVNJSSnp0NL7ygXIwXXKC6OO/a5RILXz/HokWqOr5WakpKdzcjKLdnt25qf69eygoLCFDbMzOVcJ12muvc48eruZ13nnIznnWWa19KihJgvfjpEUJZm88+WzemZlA/bWqZ1VfexOOYkag2ArOklHltOR/AmQSiFk+Xtdpp58yZw8cff8xnn33GueeeC6jWL7Gxsfj5+bF06VIONKFc9uTJk/nkk0+w2Wzk5OSwfPlyxo0bx4EDB4iNjeWaa67hqquuYv369eTm5mK325k9ezYPPfQQ67Ue6wYGrcD336tq8BqaCGg9uhrjo4/UTf2885TH/k+Hf2bLFvfjNBfjCSeo58biZj//rITn8svdRQeUKN5yixLP+li5EiIjlTX2taPOhZaWr7fM9OdNTVViaTZD//5KPJ9/XlmbV17pOveFFypX4VdfQWWlu2X273+rSEhD0Ya77lLWqdEQ3nfaMpux3vImumOSgC+AS6SU7ZOMGxQEJhOWChM2W+uJ2bBhwygpKaFHjx4kJKjqLRdddBFr165l7NixfPDBB01qhnn22WczcuRIRo0axYknnsgTTzxBfHw8y5YtIzk5mZSUFD7//HNuueUWDh48yAknnEBycjKXX345jz76aKt9LoOuTU0NXHutEoaCApVOvnq12uerZfbAA2ox9F9/qUoXa9eqShmeYqW5GLV4VWNxsx9+UGI0erSKW4WFucYsWQLPPeeKp3lSVaXmceWVai4LF6rtWlq+Jma9e6vF27/8oj77wYOujMRBg5Qovfyyqq2ojQEVV/vnP1W1jxkzXGn+ABaLKnnVEGazK/5m4CNtUYrf4SI7DlW+ZDOw0fGYCVwHXOc45nWgQLd/bWPnbUkLGCe7dknb5nWypGRL08Yd5RgtYAw8+eAD1bYEpHzjDSnXr1ev4+NVSxO7veHx2dnq+Mcfd99+4olSjh/vvu2TT9SxmzdL2a2blNdco84/Y4aUt93mfqzdLmWPHlKed55r29ixUk6bpl7Pm+ea9yuv1J3XihVq3xdfSHnrrVL6+0u5f7+UU6aoNi76z3X11eqzbt+uxrz2mtqutYkBdb4jHaBMdnALr7Z8tJllJqX8XUoppJQjpa7DqJTyFekojyKlvFpKGanbP7at5uNGaCimKjvUVNLaXacNDDoD27erRb4NISUsWACDB6sY0sKFLhfjeecpV15RUcPn0JJEJk503z5woLLM9FaT5mZMSFBWz65dKknj+++VlaXt1+Z/8KB7goQ2RrvupElqjdZtt6n4m7d5TZig4m3V1Sqp448/4Kmn3F2AF1ygPuvLL6v3WkxOc0FOmKAeBh1L16oAouGw383ltOp6MwODzoDdDsccA/fc0/Bxy5apIrjz5qm1Tz/9pGJLCQmuxITGXI0rVyq32pgx7ts9swRBuRn9/CA62iV2Tz0F4eHKxffCC65jf/xRPevFbOBAlc1YWAjr1ikBfeMNJZiea9BWrFA1FOPj1ULlwYPVIunff4frrnM/9oQT1Pqw119X7zU3o9aW5c47G/4ODNqHo0bMZD3Zf16xWpEmE+YKWjVu1plp0vdn0KkpKlLrsz7+WAlbffznP+omfsklSsxsNhWnmjjRldDQmJitWKFu+vqq81A3YQOU5RUfr6yigQOVuH37rVo6etZZyjLSml/++KNKwNBnLg4cqITrk0+UpTVxoso6PO44ZXFpSKnmpVmLQqg6iTt2wLHH1v0MFgvMnq1asYA6J6j4X1YWnHlmw9+BQftwVIhZYGAgeXl5vt+QhUCEhmIpF62a0dhZkVKSl5dHoJE61SXQ1tRnZipLpD5+/VW5EwMDVRbigAFqu17MGsporKlRySKeLkZwuej0SR6amOn3Bwaq1PvbblOW3NtvK6FatqzuGixtzNtvq2fN9TdxosqcLHYsDEpLU9fSzys8vG41Dj0XXKCeExLcj4uLq3+MQftyVLSASUxMJCMjg5ycHN8HOfowVNXkE2A1KugHBgaSmNjyAiwGRz4FBa7XCxe6sgf1VFWptVfdu6v3WpmlRx5RIpGQoDL2GrLMNm5Uaene4km9eimXot4yy8qqG4+69FLl/ouJUWu3brkF/vUvZSV5ipkmtqtWqRifJjQTJihrbPVqFUPTBLwpca7jj1dC6+saNoP256gQMz8/P/r06dO0QWvWwIwZ/HUf9L5rL0FBfdtmcgYGzSQ/X7n2YmJa97yaZZaQAJ99phbnms3ux2ixLH1dwFtvVcJy7LFKyLp3rytmUip33eDB9Sd/gHLd9etX1zLTBGbIELV+6/zz1XshVDHh995T1wgNhZkz3c8ZEqLS7A8edL/msceq8StWKDH74gslTCNHNvpVOTGb4f33G7beDDqWo0LMmkVKCjIshIgNpRQWLjfEzOCI4+9/h5wc5VJrTTTL7Kqr4OGHlTvxxBPdj9GcHHoxi46Gm292ve/Zs66YffSRKi01a5ay7nr2VOWfvDFokMsyq6lR13Qs0UQIuPFG9+NHjVKPhhg4sK6YhYerahsrVihrc9EiuPrqugLeGCed1LTjDdqXoyJm1iwsFpg8hcgNJoqKlnf0bAwM6rB7t3q0NppldtFFavHuHXeouNTjuv7BubnquSGr0FPMpIQnnlDuvUWLYPFi71aZxsCBqqyTzeaqPq/FzJqL5p70vO7Eicr9qFXk0GJgBkcPXVfMADHtFIIO2qn46+eOnoqBQR0yM+HwYXWzb000y6x7d7jhBlVv8L33VIq5JireLDNPNDHT8q5+/hk2bYL/+z9XtuDFF9c/ftAglcyhJWSAyzJrLmecoVyJnnUPJ0xQYfJHHlGuyIZE1qBz0qXFTIsgW/9Io6rqYAdPxsDARW2tEhSbzX0tVmtQWKhiXqGhyhrLzoa33lL7NFHRLLOGxCwxUVk5+fnq/YIFyiq76CIYO1alw59+ev3j9en5rSVmM2eqtH1PF6ImXjt2qAxNX9vEGHQeuvafdPBg7N1jiVwHhYW/dfRsDAycZGe7LB595YvWoKAAIiLcq1xo7j2tPmJurtofFVX/efRrzbZtU27Fm27yPUlCn56vXbelYlYf/fu7hNlwMdaPEGK6EGKnEGKPEKLOcnAhxCwhxGYhxEZHW67jGhsrhIgSQvwohNjteI5si7l3bTETAjFtOpEboCh/WUfPxsDAiV7AWlvMCgtVgV49moho18rJUcdYGkgR04vZXXephhSe1TMaIiZGWXLPPOOq6BEb6/v4piCEquTRt6/3hdEGIIQwAy8CM4ChwIVCiKEeh/0MjJJSJgNXourrNjb2TuBnKeUAx/g2qZnStcUMEKecil8x1Kz+qaOnYmDgRLNUPF+3BpplpsdTzHJzG3YxgkvMnngCvvlGZUZGR/s+DyFUmnxtLXz6qbqev7/v45vKq6+qKvY+NHrvqowD9kgp90kpq4GPgVn6A6SUpdJVnSIYnB2OGxo7C3jH8fod4Ky2mHyXFzNOPhmAoN/3Ul2d3cGTMTBQtLdlZrWqFip6N2Nj69vi4tTC599/V4uKb7ml6XOZOFEtrr7gApXO35ZERroWgXdRLA7XoPa41mN/D0C/2CLDsc0NIcTZQogdwHco66yxsXFSykwAx3Ob2N9dd52ZRmwsthEDiFy3m4KCX4iLm9PRMzIwcAqY1dp8Mbv3XiVKTz7p3huroEBl9HkSH+/uZuzbyNJLk0mdR0sgaW5SRVSUqhNp0ObUNtKZxJvNWqdGoJTyS+BLIcRk4CHgZF/HtiWGZQaYTjmD8K1QlPF9R0/FwABQohIVpVx5zRWzV1+F//5XVazfuNG13ZtlBsrVqHcz+lJ55JFHVEksfWNKg05LBqDriU0iUG+vbinlcqCfEKJbI2MPCyESABzPbeICM8QMEKefgakG5I+LO3oqBgaAcvclJKhHc2JmBQXKujrvPFVpfvp0V3akt5gZuK4lpW8xM4C//Q1OO63p8zM4IlkDDBBC9BFC+ANzgK/1Bwgh+guhoo5CiNGAP5DXyNivgcscry8DvmqLyRtiBjBpEvZwK2G/ZlNRsa+jZ2NgQGamS8yaY5lpNQ8vugj++U+1+LqgQK0Lq6pq2DIrLlblpXwRM4OjByllLXAjsATYDiyUUm4TQlwnhNDyVGcDW4UQG1HZixc4Gll7HesY8xgwTQixG5jmeN/qGDEzAD8/7KdOJXrJd+Tm/khQz7939IwMujiZmSqpIiZGvZayaVl4mpgNGqSECVQKvZb67s0yi49XVpzWlbm1CxwbHPlIKRcBizy2vaJ7/TjwuOe4+sY6tucBbV7Z0rDMHJjPugj/Iqj8dWFHT8WgiyOlu2VWXq4K5DaFnTtVFYy+fd3Xg2l1GeuzzED1/gLDMjPoXBhi5kDMmIG0CPyXrETKBtrvGhi0MYWFqmahJmZQN25WXu6yuLyxaxf06aPWbenFTKvLWF/MDAwxM+icGGKmERFB9fghRP5WQWnppo6ejUEXRl+nUCsz5Rk3GzdOFQauj507XbUP4+JUJY/GLDPtWpqYGW5Gg86EIWY6zLMuIPgAFG94v6OnYtCF0YuZZ2UOUOu6tm2DJUu8j7fbVesYrfah2exqpGlYZgZHK4aY6bDMvgQA+cXnHTwTg66M5lKMj/cuZhs2qOdt21yWlp6DB6GiwmWZgatdS0OWWVSUcksePKieQ0Ja+kkMDNqPNhMzIURPIcRSIcR2IcQ2IUSdYjdCiMFCiJVCiCohxD/bai4+06cPVSO7E7b4ANXVuR09G4Muit4yi4xUwqKPmWliBvDnn3XHa92bvYlZQ5aZEC5XY0yMUcPQoHPRlpZZLXCblHIIMB64wUsF5nzgZuCpNpxHk5DnnUvYTija8G5HT8Wgi5KZqcpYhYa6BEZvma1fr7aZTKoJpif6tHyNnj0hI0P1HrNa6y/oq4mZ4WI06Gy0mZhJKTOllOsdr0tQC+l6eByTLaVcAzSQl9W+BFw8FwD7J4aYGXQMWlq+Zhl5LpzesEEV6B0xAlaurDt+504IDnYvqtuzp8qQ3LPHu1Wmobk1jeQPg85Gu8TMhBC9gRTAi1PkyEL07kPFyBiCv9uK3V7b0dMx6IJkZbksJHAXs6IiJUijRytBW7VKdaPWs2uXcjHq3YRaev6WLb6JmWGZGXQ22lzMhBAhwOfAXCllcTPPca3WtqC2tu0FxjZ7JiG7bJRuNBZQG7Q/mmWmER/vipltcqwaSUlRYlZSohJB9OjT8jU0MUtN9Z78oWGImUFnpU3FTAjhhxKyD6SUXzT3PFLKV6WUY6WUYy0Ntb5tJQIvvh2Amg9faeRIg6OZP/5QPbpkMxtZfPEF3H+/631NDVxzjXsCx7JlcOutrmvoq39oJCRAXh6Ulqp4GSjLbMIE9VrvaiwpUYKlj5cBJCa6XjdkmekTQAwMOhNtmc0ogDeA7VLK/7TVddoCS99hlI2MIPCbP5HNvZMZdHreew+eew7WrWv62OpquPlmeOghlXgB8Msv8Prr8JQu3enhh+GZZ2DvXvV+zx7lShw82HXMiSeq5/vvV0IYH68effuqWov6JJC77lKCOH26+3xiYlxJH4ZlZnA00paW2STgEuBEIcRGx2OmvgKzECJeCJEBzAPuFUJkCCHC2nBOPlN7zjSCd1VTvvHbjp6KQQehpbgvbIa3eeFCtV4L4LPP3M/z9ddqHVh2Nixdqrb9+KP787RprnMddxxcf70SvW+/VVYZqJjYpEnwzTfKwvv5Z3jxRWVNalabhsnkss4assySktSzPmZnYNApkFJ2qofVapXtQeWedVKCzL/txHa5nsGRR/fuUoKUvXpJabf7Ps5ulzI5WcohQ9Tz+PFSVlVJGREhZf/+6pyffy7lSy+p1yEhUp59thp71llS9u5d93olJVL27auOv/de1/bt26UcOFBKk0nKqCgpBwyQsqzM+7ymTFHj77uv4bl/9ZWU1dW+fdZ/fPsP+cTvT/h2sEGHApTJI+Ae3lYPowJIPQT0G03pqFACvvKykMfgqKe0FA4dgiFD4MABWL3a97G//KI6O992G1xwgco4fP11VX3jqaeUy++TT9RjyBCYM0dZVZWVauy0aXUXLIeEwNtvK1fhlCmu7YMHKzfoxRer9i3vvKPWkXlDSwJpyDITAs48E/z8fPusP+//meVpy3072MCgDTHErAFqzjkJ655KKjf82NFTMWhjpITbb4etW9V7beHxP/+pBOSTT1T1jJtvVoLTEE8/rWJZF10E55+vtv3rX0pEZsyA2bOVq3H5crV/2jTVEPOll9Sz3sWo5/jjVTzt5JPdt4eEKBErLKzrXtSjiVlDMbOmUm2rprK2svVOaGDQTAwxa4DAi/6FFFD1/oKOnopBG5OZqaym//5XvdfEbNw4lUzxwQeQnAzPP6+srexs7+eprIQffoBLLoHAQJWkMXassprOPlsJ4wUXqOOkVGJ20knKInrkEfWsJXx4IzCwefvAt5hZU6mqrTLEzOCIwBCzBgjqN4GS5GACPvtVlSI3OGrRFiVrae47dyph6ddPCU52tqo+/+67ynr6xz+8p+yvX69S8I8/3rVNs8605+OPVwkWw4fD0KEQHQ1jxqhSU2PHqvdtQe/e6rk1MxWrbIaYGRwZtP2irU5O1eUzCbvlU6q/egf/s6/o6OkYtBHaouSNG5UVtWuXyuwLClKWFMDpp0N4uBK+O+6ADz9UrkQ9Wpq83t13ww2qtNQpp6j3ZjN8+aU6t8a0abB2bf0uxtbglFOUhTlpUuuds6q2ioqaitY7oYFBMxGyk62jCg4OlmVlZe12vYriHZj6DUEO6k/g77vb7boG7cvrr6sFzaDS5f/5T2UheesZZrPB+PFqgfKOHe77zjkHNm9W68Wawp9/KpFZsUK5NjsL/g/5kxSexJ6bm/iBDdodIUS5lDK4o+fRVhhuxkYIChtMzpxEAv/Y4+paaHDUoS/ku2KFq76hN8xmlcSxcyfk6joFSanGTpzY9Osfe6yq8nGkC5nN7ioEaZd2auw1HeJm1M/DoPUQQkwXQuwUQuwRQtTpZS6EuEgIsdnxWCGEGOXYPki3nnijEKJYCDHXsW++EOKgfr1xW8zdEDMfENdehy0Aap96sKOnYtBGZGaq5pSDBikXYElJ3ZJQejTBWrXKtS01FQ4fbjijsCHCw5s3rr1Yun8p4Y+Fk1+RD6hMRqDdxWxD5gas/2clrSitXa97tCOEMAMvAjOAocCFXtp27QemSClHAg8BrwJIKXdKKZOllMnAGKAc+FI37mltv5RyUVvM3xAzH+g28AqyTgXTx/+rP43NoFOTlaVKOU2cqGJXUL9lBipRw2JxLyWlvW6OZdYZ2JO/h7KaMrLL1P+BqtoqACpq2zdmtitvF9W2ag4UHmjX63YBxgF7pJT7pJTVwMfALP0BUsoVUkpHi1dWAYnU5SRgr5SyXf9Ahpj5QEBAd4qvGIep2oZ8+eWOno5BG6AV99ULUUNiZrWqyvWeYhYSorIUj0aqbEq8NEtMb5m1Z+y9tLoUgLKa9ouddxF6AOm69xl49KD04Crgey/b5wAfeWy70eGafFMI0YorHV0YYuYj4eOuIe9YkC89B1VVHT0dg1YmM1Oly2suwoAAV53C+pgwAdasUan4oMTs2GNVTO1Ip6CigNom9uvTLDHns0Pc7NLe5HO1hJLqEgDKa8rb7ZodSV55XmudyqK10nI8rvXYL7yM8forRQgxFSVmd3hs9wfOBD7VbX4Z6AckA5lAmyzcNcTMR2Jjz+fgeQGYsvPh4487ejoGrYiULjfjkCEqdjVggCrO2xATJ0J5ucpeLC5Wz53BxVhtq2bA8wN4cfWLTRrnaZlpoqbf1h44LbPqo98y25a9jZgnY9iUtak1TlcrHa20HI9XPfZnAD117xOBQ54nEUKMBF4HZkkpPZV2BrBeSnlY2yClPCyltEkp7cBrKHdmq2OImY9YLGH4z7yQsj4C+fR/mt/kyuCIo7BQGdsJCUrAbrpJVfBoDE24VqyA++5T6+pPO61Np9oqbMveRl5FHvsK9jVpnKdFprkZoX3jZl3Jzbi/cD8S2V7JLmuAAUKIPg4Law7wtf4AIUQS8AVwiZRyl5dzXIiHi1EIoevOx9nA1ladtQNDzJpAQvdrSJ8tEZs2u3p3GBzxFBerUlRaYocnWlq+1vbkoYdULcXG6NlTlYh65RXV9+zGG5Wb8Uhnfabq8FlQWdDIke5oIuYpatC+lllJVddxMxZVFgHtI9xSylrgRmAJsB1YKKXcpm/bBdwPRAMvOdLsnf+rhBBWYBpK7PQ8IYTYIoTYDEwFbm2L+RsVQJpAWNgEdp05iJq39uH3yCMNF9EzaHfS09VCZ8+q8X/9BZs2qd8fY8fWHadV/9B3d/aVCRPg00+hf3947LGmj+8INmSpVteFlYVNGqcJVoe7GWu6jpuxqEqJWXsJtyNtfpHHtld0r68Grq5nbDlK6Dy3++DnaDmGZdYEhBDE976WA+fXqNLp+lQ2gw5FSiVU3gQl3ZGfdaCeRGHNMmuOmE2dqlyTb78NwZ2ktoImZk22zDwsso6yzDQ3Y5eyzLqAcLcUQ8yaSFzcpWTNCqA2MlD5owyOCIqK1BLA3V4qjmlilprqfWxLxOyaa2D//tatd9iW2Ow2NmZtBJpumdWXmg+0a31Gzc3YFWJm7W2ZdWYMMWsi/v7diO1zJWnn1cDixSo326DDOXhQPevLUmn4YpkFBUFoaNOva7E0nsJ/JLE7fzflNeUEWYIoqGhhzMzIZmxz2jNm1tkxxKwZ9Ox5Gwdn2bFFGNbZkcIhRwKxFv/So7fMtCTUN95wtWTR0vI9uzt3JmrttfyZ8Wejx2nJH5OSJjXdMqv1SM3vqAQQbZ1Z7dFvrRRXFwNdQ7hbiiFmzSAoqB9Rvc4jfbaEb75RfUMMOhRfLLPSUtUtGlTSxqefqs7SWvWPzszXO79m/BvjG02335C5gQBzABMTJ1JWU0aNrcbna3jGygzLrO3RLDPDzdg4hpg1k6Skf5FxVhX20AB4+OGOnk6XR7PMiovVQmY96ekQ6Sigo7kat21TzwsXuqp/dGa04r+ZJV7UXMeGrA2MiBtBTHAM0LS4mad7saPXmXWFG7wWMzPcjI1jiFkzCQ0dQ0jiSRw8xw8+/1z9xDdoc5Yvhz/+qLtds8zA3dVYU6PeawkaqakqWSQjQ73/5JOjwzLTLKO8ivpLH0kpWZ+5ntHxo4kIjACaltFYpwJIB68z6wo3eMMy8x1DzFpAUtIdHDi7FHtwAPz73x09nS7Brbeqxpme6MVM72o8dEjFyY4/Xr0/cMBllZ1+uupbVlR09IiZZqF5I60ojYLKAlISUogMVKZqsyyzDnQz1thqnNfvEm7GLmaZCSE+F0KcJoRosjYZYtYCIiNPJrBHCofmhKgAzDvvdPSUjnrS0ryn2B865BIkvZhp8bJRo1RF+9RUl5jdd5+rKHBndzNqqfENFaXdmbcTgGExw1yWWRMyGo8Ey0x/U+8K1koXXGf2MvA3YLcQ4jEhxGBfB7aZmAkhegohlgohtgshtgkhbvFyjBBCPOfoarpZCDG6rebTFggh6NnzX+y9MI/q40fA3/8O69Z19LSOWioqVGfnrCyo9Lh3HjwIY8ao197ErGdP6NXLZZlZrWqR9Uknqf1dwTLTboyRQZFOMWuJZdYR68w0F6NZmI96a0VKSXGVymbsCsINIKX8SUp5ETAaSAV+dHS0vkII4dfQ2La0zGqB26SUQ4DxwA1eupbOAAY4HteiVLlTERNzLgHBfdh+vwUZGwvnnGM08Gwj9K7EdF3XJZtNCdzIkWrdlz5m5ilmmmU2dKiq3HHhhWp/nz5tPv02xZeYmXZjDPUPJTJIuRlbFDPrADejlvwRExxz1N/gS6tLkY4OLEe7cOsRQkQDl6PKZm0AnkWJ248NjWszMZNSZkop1ztel6AKV3o2epsFvCsVq4AIjwrLRzwmk4WkpLspsGyg8I0bICcHzjqrrulg0ChLl7pcgN7QC5je1Xj4sKpYn5gIcXF1LbOwMLUgundvZZlt3QrDhqn9l12mjOnBPjszjkx8scy09VlhAWEts8x0FpqfyY9AS2C7iZn2GeKC4yirLmvXpqDtjRYvg65jmQkhvgB+A6zAGVLKM6WUn0gpbwJCGhrbLjEzIURvIAXwXNXpU2dTIcS1WkO52tr2awLoK/Hxl2O1DmNn6GvY33kLVq6EK64w2sQ0kWuugbvuqn+/Xsz01Tw0i61HDxX70otZRoayykBZZgUFynLTukELAaM7lXPbO1pqvE+WWUAoQZYg/M3+zYqZ6d2MAZaAdhUzzTKLC4nDJm3U2H1fJ9fZ0NzC0UHRXSlm9oKUcqiU8lEppds6EymllzLhLtpczIQQIcDnwFwpZbHnbi9D6iiAlPJVraGcxXLkFfo3mSz06/cElZV7OTThsKp2+/HH8MILHT21TkV+PuzcWf9+TcxMJnfLTFtj1qOHin15uhk1Mevd27Vds8yOFnyyzKpKCLIEYTFZEEIQERjRLMtM72YMMAcQZAlqt3VmTjELjgOO7sQIzTLrHtq9y1hmwBAhRIT2RggRKYS43peBbSpmjoDd58AHUkrPHjfgY2fTzkBU1AwiIk4iNfVBam69Fk45Be6/H/JareX5UY2UasHzvn1qbZg30tOhWzclTt4ss+7dlZh5uhn1lpnG0SpmDWUzFlcVExrgKkAZGRjZrJiZ3s3Y3paZlgDiFLOjOJakWWbdQ7tTUVuBXdo7eEbtwjVSykLtjZSyALjGl4Ftmc0ogDeA7VLK/9Rz2NfApY6sxvFAkadp2VkQQtCv31PU1haQlv4Y/Oc/6u78wAMdPbVOQVmZSuSorVVV6L2hCVPv3nUtM7MZYmOVmzE7W52nqkq99hSz0FDXtqMFX2NmYQFhzvdNsczs0u7MXtSn5vub/TvMzQhHdyxJcwsnhKo0gqP5s+owObQDACGEGfD3aWCbTQkmAZcAJzo6km4UQsz06Fq6CNgH7AFeA3wyJ49UQkOTiYu7hIyMZ6nsFwLXXafaEDeU1WAAqIXLGvW5GjMyVJKHlmKvcfCgEjGzWVlmUioR06p8aMIVFweBgcoq68xFhb2hiUlZTZlblqGekuoSQv11llmQ75aZPg3fLWZmbmfLrNrDMusKbsaQ7kCXEbMlwEIhxElCiBOBj4DFvgxsswCUlPJ3vMfE9MdI4Ia2mkNH0KfPw+TkLGTfvnsY+uAz8OGHcNVVKlUvKKijp3fEohezXbu8H5OeDscdp1yNBw8qd6Sfn3rdw5E2pK0Xy8pShjG4xEwI1Rz8mGPa5jN0JPqYVX5FvvPXvJ7iquI6ltme/D0+nd9bGn5VrcvN2N4xs9jgWODovsFrbkbtb1lWXQadpAFsC7gD+DvwD5R+/AC87stAowJIKxMY2JPExFvJzv6AYv/98PrrsHq1ygG3dwmfd7NozDIrK1OZiNp6MbvdZXkdOlRXzDIzXdZbYqLrPN99B/Pnt/r0Oxy9ZVRfRmNJVUndmJmP2Yz6ah/6mJm/2Z8gv6B2dTNa/azOz3FUx8yqijAJEzFWVRT6aBZuDSmlXUr5spTyXCnlbCnlf6WUNl/GGmLWBiQl3Ym/fzw7d16F/ewz4IknVLmrO+800vXrQRMzf3/vlpl+8bOWlajFzQ4eVMkf4CpLlZmpjOKEBOjbt61mfeRQWVtJVFAUUH8SiDfLrLCy0Ke1WpqAmYXZLRGk3d2MVcpVavWzAp3bzXi49DDzlsxzJrV4UlRZRFhAGCH+annV0SzcGkKIAUKIz4QQfwkh9mkPX8YaYtYGWCxhDBz4KmVlWzhw4CG47Tb4xz/gySfhnnsMQfOCJmYpKd4tM89KHqAsr/JyKCx0WWaamC1ZAj/8ADfdpFyRRzuVtZX0CFVfQn1JIHViZoGR2KTN6bprCE3AwgPDncLVIevMakoJ8Q8h2E/52zqztfLTvp94etXTPLzcewupoqoiwgPCCfZXn7UzC3cTeAtVCaoWmAq8C7zny0CfxEwIcYsQIsyRdfiGEGK9EOKUZk+3C9Ct2xnExV3GgQOPUlyyTq05u/ZaePRRmDfPEDQPNDE75hj3eJeGXsx69lTxr9RU1xozzTILCICoKPjsM1V/8e9/b5fpdzgVNRX0CFNiVp+b0ZtlBr5VAdEss7CAMPfUfIdl1l61GUurlZg5LbNObK1oCR5Pr3qa3Xm7ve4PDwx3ftb2EG4hxHQhxE5Hvdw7vey/yFFHd7OjZuIo3b5UIcQWR7LfWt32KCHEj0KI3Y7nyAamECSl/BkQUsoDUsr5wIm+zN1Xy+xKx4LnU4AY4ArgMR/Hdln6938Gf/94duy4DJusVpmNN98MzzwDt99uCJoOvZhBXVejFh/r3l25Irt3V5bZ+++r7UOGuI7VrLOrrlLC1hVozDKrsdVQWVtZJ5sRfBQzzTILCKfKVoWUkqpaR8zM0n4xMy3up1krndky01Lv/cx+/PPHun2NiquKlWXmsELbWrgdafAvomrmDgUu9FJPdz8wRUo5EngIeNVj/1QpZbJHtY47gZ+llAOAnx3v66PS0f5ltxDiRiHE2UCsL/P3Vcy0rMSZwFtSyk00kqloAH5+EQwa9Drl5X+RmjpfmRPPPAM33AALFsD//V9HT/GIoahIpdanpKj3nmKWnq5S6wMC1PveveGXX+CRR+Dii2HcONexCQmqSsjcuY1f91DJIS7/3+Wd3oVTWVtJdFA0/mZ/rzEzfV1GjaY06NSssfDAcEC5GFvTzfi/Hf/j6ZVPN3qcZpk5b/Cd+O9WVFmEn8mP+ybfx9c7v2bp/qV19rezZTYO2COl3CelrAY+RtXPdSKlXOFYyAywClXoojFmAVp/rHeAsxo4di6qLuPNwBjgYuAyXybvq5itE0L8gBKzJUKIUMBIzfOB6OjpJCRcTXr6kxQVrVKC9txz6g58771GySsHRUWqIPCAAeor0sRMK8Wpr+QBKm6WlqYWSj/3nPu5rrlG/U7wJfHj530/886md1h+YHnrfJAOQEpJla2KIL8gooOivVpmWpKBZzYjNM0y08SwsrbSzc3YUjF7bf1rPL2qcTHT4n5+Zj8sJkundzOGB4Zzy7GqO9Zvab/V3d+6MTOLVuPW8bjWY79PtXJ1XAV8r3svgR+EEOs8zh2nFcNwPHu1tByW4flSylIpZYaU8gpHRuMqXz6cr2J2Fco0PEZKWQ74oVyNBj7Qr98CAgISlbvRVq7MhrfeglmzVIbCu+929BR9ZsECGDGi9c9bVATh4WpRc69esGWL6iodHKyE6cABdzHr1089v/46RHp44C+4AO64w7fravGl9ZnrW+FTdAyakARaAokKivIaM9NcWl4tMx/S852WWYCyzKpsVW7ZjBW1FS2qYJ9ZkumTqGqWGUCwX3CndjNqYhXkF0R4QDg5ZTnu+x3ZjK0YH6zVatw6Hp4uQp9q5QIIIaaidEH/P22SlHI0yk15gxBiclMm50jBH6OvANIUfBWzCcBOKWWhEOJi4F6gqJExBg4sljAGD36biord7NkzT9uoihGfeCJceSX873/tOicp4ccfVQmphli2zL2bze+/qxYqvrRskxK+/95lXTWEJmYAgwbBF18oj+zw4SoBdMcOdzG76SZYvBhmzGj83A2hWTHrs44OMYu21mOZOdyM+phZkxJAPCyzqtoq1zozSxB2aafW3vyOFlmlWZRUlzR6Dr2YWf2snd7NqLltY4JjyCl3iZmU0il27ehm9KlWrhBiJGoh8ywppfOXk5TykOM5G/gS5bYEOKy19nI8N3T32AB8JYS4RAhxjvbwZfK+itnLQLkjc+VfwAFUyqSBj0RGTqVnz9vJzPwvOTn/UxsDA5WIjRkDf/sbrG+/G+rmzaoW8uef13/M3r0wdSq8/bZr2z7Hig9fKnT9/DPMnAkvvdT4sXoxO/54ZW198QWsXQuvvqqKp+grd8TEwKmnNn7extDiSxsyN7T8ZE3gsd8f479r/9sq52quZabdSJsUM3NYZpW1lW4xM/08morNbuNw2WHAVfXCG1JK5zozgGD/YMprO69lps8ujbG6i1lFbQW19lrCA8MxCRNBlqD2EO41wAAhRB8hhD8wB1U/14kQIgn4ArhESrlLtz3YEX5CCBGMShbc6tj9Na6412XAVw3MIQrIQ2UwnuF4nO7L5H0Vs1pH6alZwLNSymeB0EbGGHjQp89DhISMYefOq6isdKTnhYbC119DdLRq6nn4cLvMRcsOXLOm/mPWOpJrNeGSUgmc57a77oKNG+uOX7JEPT/zTOPWmV7M7roLcnPh7LNV/Oyaa6CkBC66qLFP1XTyK5UVs79wf5N6e7WU9za/x2fbP2uVc2kiEmRpWszMYrIQ6h/aPMvMw82on0dTySnPcVaEb0hYq2xV2KTt6LHMHJYXqPJc2WUug0X78aHtt/pZ29wyk1LWAjei6iNuBxZKKbd51NO9H4gGXvJIwY8DfhdCbAJWA99JKbWaio8B04QQu4FpNJAJ74iTeT6u9GX+vtZmLBFC3IUqHHy8I1DXBZaiti4mkz9Dh37IunVj+OuvC0hOXobJ5KfS9P73P1V4cPZs5ZsLbdvfCjmOH4EbGjBINENRS8bIyVFlpUC5GgH27FHt22pqIDnZffwPPyiB2r8fvvwSzjuv/msVFbkaZpq8/MQymxv8OM0mrzwPgUAi2Zi1kal9prbNhTwoqixyJmC0lDqWWXkeUkr0oQdvlhn4XmxYv84M1Lq2GnuNm2XW3PqMmSWuRhkNCau2uFsfM+vUCSB6N6M1hlUZq9z2gct6DvZvn88qpVyEKgCv3/aK7vXVwNVexu0DRnlud+zLA07y5fpCiLfw3tOyUUHz1TK7AKhCrTfLQmW4POnjWAMdVutABg16neLiFezb9y/XjjFjVCLIqlXKz6aZTm2EFvNav77+5W6a0GkVOTSrzGx2WWYrVrjv0zh8WLkyb79dJWs89VTDy+r0lll7kl+Rz5juY4D2TQIpqipqtV/amogEWgKJDoqmylZVR1i8xczA9zYw+gog4BJHrTYjNN8yyyp1dVNtyDr2tC6D/Y+OBBBQMbPc8lynhaotqG5Py+wI4VvgO8fjZyAMaLxEDT6KmUPAPgDChRCnA5VSSiNm1kxiYy+gR4+byMh4huzsha4d552nKuHu2wfHHqsyHsvb5h+wJmYFBSrF3RMpXZZZWhpUVLgE6/jjlZhJCStXqm2eYvbTT+r51FNVwZPVq+GPP1z7q6tdY6XsODHLq8hjUPQgEsMS2ZDVunGzNze8yZVf1f1BabOrElJNvTkVVxUz4Y0JbM/Z7rbd0zKDuvUZvbkZwfdiw9o1NMtME7PWcDNmljbPMuvMbkYppXNRNCjLzCZtzs9fxzLr5Faor0gpP9c9PgDOB4b7MtbXclbno/yg5zlO/qcQ4tzmTtgA+vV7irCwiezYcTklJbqb6Kmnqrt+ZKTKckxMhDfeaPXr5+iygL3lnWRkqCbZxx+vxGbPHqWxQsBppykRzMpyWWb79rlbXj/8oMKAKSlw+eXq47zyimv/M8/AxInqOuXlKquyoyyz6KBoUuJTWt0yW7J3CZ9vr5tho1lJTRWzvfl7WZWxitUHV7ttd8bM/IKItkYDdauAFFcVE2QJwmJyjyxEBUU12NBTwzMBRPsMrZEAonczNuTy9LQuO3Nqfml1KXZpd8tmBJzp+Zplpv14CPYP7rTC3UIGAEm+HOirm/Ee1Bqzy6SUl6JSLu9r5uQMUPGzYcM+x88vmq1bZ1FdrUv8GDFCLbRatkwFoq6+Gt55p75TNYvsbNWk0mz2HjfTBG7OHPW8a5eyvnr0UB5RUEK2dasK+ZWVuaw9Le3/pJPU+a1WFQr86itl4QF89JF63rvXVcqqvcWsxlZDcVUx0dZoRieMZmfezla9YeSV51FcVUyNrcZtu/aru6k3Yu14zSrS8GqZeWQ0enaZ1qgv+9ETzwQQ7TPoLbPm1mfMLM0kwKxKuzTZMuuk1opnDFPrz6ZlNDotsy7mZhRClAghirUH8A3ua9nqxVcxMznWDmjkNWGsQT0EBMQzfPjX1NTksnXrWWpBtYYQMGUKLFoEJ5+srLRPP221a2dnq8XJgwd7F7MNG1QixrkO+3vnTmV99eunRBCUwSglXHiheq+5Gv/6S7VgmTbNdb7zz4fSUrU2bNcuV/ZjamrHiZlmBUQFRZESn4Jd2tl8eHOrnV+zeDytDe1Xd3PFTLNQNDQR0WJm+mtrFFcV13ExAs7sx8YWPFfVVmExWZzxMX3MrKWWWVZpFn0i+2AxWRp0eXpNAOmk1opnTEzrWaZlNDqzGbuemzFUShmmewyUUjawgMiFr4K0WAixRAhxuRDiclRwblEjYwx8IDQ0hSFDPqC4eDXbtp2H3e7+K965Fm3CBFXa4rHHfC5QXF4O/fsrUTKZlIGnkZOj1mqlpHh3M65frxYvx8aqor6aZda3r9rWrZsSJiFcYqatQdPiZXoxmzpVjVm4UD00DhzoODHT4krRQdGkJKiikK0ZN9MsHs/4lfaru6K2whnw94UmWWaeMbMGLLNqW3WjN0qtdJVmQTljZpYAgiwtSwDJLM0kISSByMDIBi0zz7hfZ7ZWPGNinm5G7XvQXKqd+bM2BSHE2UKIcN37CCHEWb6M9TUB5HZUdeSRqPTLV6WUPhYMMmiMmJizGTjwFfLzF7Fz51VIaWfdOl1j6uBgij9dQtrp16tFWOee6+pM2QBvv60E6MYbledyqaOOqZTKMouNhdGjVRsVz+VtGzaofaBEbcMGZW1pZaSGDVPnGTECRo5UoqZZZr//rgoBa33HQBU8mT0bvvlGVbqfNEmJZEdaZpr1EhUURc+wnoT4h7Az10sztRae39NK0n6VQ9MEwGmZeTRz1ItZN2s3ALcFuOCwzPy9WGb1xNg8qaqtcouPtWoCSEkmCaEJRARGNBgzq2OZ+QdTY6+p48btDNRnmWl/t9SiVBLDEjGb1JqUzmyFNpEHpJTO/yBSykLgAV8G+uwqdGSXzJNS3iql/LLpczRoiO7dr6FPn4c5fPg9vv32P4wdCy+/7Np/7mXBDF/2PAfu/q9ShP794dJL4bffvNakstng6adVUuSzz6qyT+npantJCVRVKTHTqtTrXY05OSoxQ9s3cKBKsweXmGlrwiZMUMZjjx6uJJAVK9R2T84/X8XWdu5URmavXsoyKyxU+9vdMnNYTtHWaIQQ9I/qz+78un2lmkO1rdp58/WMSemrXDQlzuS0zKq9W2ZBliACLAGEBYTVqfNXUlW/ZQb1d6fWcFpmFmWZaTfjlq4zk1K6LLOghi0z7fvUJ4BA52wD42mZBVgCCPUPdf7dduftZkDUAOfxnTk+2ES8aZJP66EbFDPPYJzuUeIIzhm0IklJd9Ojx00sW6ZWKf/nP0p8Nm5UCRUlJYKr/rwW+559qi/a55/D5MlKSZ5/3u1cX3+tMhBvu01ZTb17q4XNmZmuTMaYGNdCZ72Yaa/1lpmGVolei5tNnKie+/VTlll6urL0tO16pkxRAiqEMi579z5yLDOAAVEDWk3M9JaOt/iVRlNuxPVZZvp1ZlC3NJJ2zfpiZt7m6EmVrYpAS2Ady6ylMbPiqmIqayuJD4lv1DIrqS7BJEzO63XmBp3eFrHHBsc6/267893FTFtT15Jizp2EtUKI/wgh+gkh+gohngbW+TKwQTHzEozTHqFSyro/8wxahBCC/v2fISPjfEBZOv/7n6pUHxICjz+u6h2+8m2iUrqsLFWsePhwJW7PPus814IF0KePKgkFLpffgQOurMPYWIiIgKQklbShob3WrK+BA137NMts+nSlo9Onu7bv3etaO+bNMjOblZf0hhtUz7FevZT4FTjuXx0ZMwMlZvsL9reK20pv6dSJmencjM0Ss+r63YxQt2itNibMvwHLrJGMRs3NqMXMnKn55oAWLZrW1pglhCQ0uoC7uKqYEP8QZ2WTztyg09PNCOrvll2WTWFlIbnluQyI1omZwwptbpWVTsRNQDXwCbAQqABu8GWgr+WsDFqJ/fvhjDNUe5Mrr1RWih4hTKSmnsjo0VvJygrk7ru7sW9fBDfcoKpp/PKLej7rLOjePVT562bPVjn0c+dCSQlr4s/gjz9G8exj5VhEAGCmd291/tRUJYygxAxcQqSxd6/qLdZNhV+clllYmKtzc58+8OuvrjF9+ypt/eknlYo/cqT3z69vmKlZi9u3qwQVbV7tRX5FPmZhdv46HhA9AJu0kVqY6nYjae65vb0GdzdjU27E2o3MWwKISZica8hirDEcKDrgdky9lpmvMTOHm9FsMmMWZldqfgvXmWlrzBJCExpdwH2o5BDdQ7s73zsts04YSyqqLMIkTM74H7j+brvzlHfA080I6t+L9vpoREpZRsOdqOvFSK9vZ37/XVXPuPpqVTi3xP1HNrW1sHmzieOPH8wllyxi164I7HbJ3LlK+F58UbVk0ff0zC20UPLfD+H00+G++/jwml/wp4rL7kwAf3+49lqSYtSN8MABdzcjKCHSMhFBve7b1yW0vXuDn58Svfo6DWkW22efqa7Pfj5U7tSsxc2blVA2r4tR88mryCMqKMr5S1+7ebSGq1Fv6dSJmbXUMvOSABJkCXJ+jtjgWLeYWY2thsraypbFzByWGSgLUJ8AollrzVln5s0yq8+Vll6cTs8wV4cSZ7fpTuhmLKpSvcr09TNjrDHklOWwK0+FGdwss9Zr0HlEI4T4UQgRoXsfKYRY4svYNhMzIcSbQohsIcTWevZHCiG+FEJsFkKsFkL4VLKks7N3r7ppP/AAfPIJXHaZe6b9jh1KrMaOtXD33VcREVHI1KkfExLyDaBE4+yzVXJIaakSpmHD4IzZ/vDVV9g3b+XT6H8wIzmL8P/MVyXnX3uN4BOPJSaq1s3NqIlZv34qm7G01DVHTZxAZSKOGqUe9aHF0goLvbsYvaFZi9u2dVwpK80yAdfNQ7uZtATN0rH6WRvMZmyOmHlaZhU1FU7rCNRNMbc81ykK9dVlBCVM3uboiWaZgbLG9DEzIQQB5oBmWWZaXcb4kHgiAyOpsdfU60pLK0ojKdxVDKIlfb48RaG8ppyduTvZmbuzwTY0jVFtq64j6t7Op6/LqKHVZ9yVtwuBoG+kq1V6Z44PNpFujgxGAKSUBdTTmdqTtrTM3gamN7D/bmCjlHIkcCnwbAPHdlq++EIV8tDYu1c1mZw/Hx59VFWT//BD134t+SIlBcLCgtmyxcyDD77Etm3nkp//A6CSOgoL4c034frrlTj9+iv8ucbEiqJhHMwL5Pzbeylf5iuvqCr8hw7Rq2gzqZsKyc5WRfmDVKjDKVz79qmEk/373cUMVDsXjxwTN/THe0v+8EaS475UXd1xpaw0ywSUCIQHhDvdPC1Bs3T6R/WvY5kVVxVjEuq/XmvFzNzELDiGGnuNUzQ1S86bZQYqZuhrzAyUAOqzGUGV0mqumzHAHEBEYESDna+raqvIKs1yE7PmWivP/fkcsU/FOhfIl9eUk/xKMoNfHMzgFwcz+tXRTf4cGld+dSWnvu9qtJdRnEHMkzG8svYVt+P0FfM1YoNjqbHXsC5zHUnhSW5/086cudlE7I6eaQAIIXpTT7drT9pMzKSUy4GGfu4NRVVFRkq5A+gthIhrq/l0BHl5cPHFcJ+u8JfmwgMlShMmqHVghxz9XNevVyKjxakSE0MZN+4rrNYhbNlyBllZ7zBhghKMe+5Rbr177lFisGCBsvYCA1Vczsn06bBmDb0DsziwOpucDRnERNucKf3afPbtU/OornZt04iKajimFRWlXIUA48f79v1Yra64XYdYZuV5zuQPUAk4A6JbJ6MxvyIfP5MfvcJ7eY2ZaeWLmiNmWl0/jUpbZR3LDFwLcDUrylvMDHwraeVmmZkDnB2htW2BlsBmJ4AkhCYghCAySLXE8ZYEcrDkIIBXN2NTvsOs0izu/eVeymvKmbt4LlJKnlrxFLvzd/OfU/7DJSMvYV/BvjrWry9U1Vbxvx3/Y2XGSmcty1UZq6ix13D3z3e7uXL1jTk1tL/bivQVdWK2XcXNiCqd+LsQ4j0hxHvAr8BdvgzsyJjZJuAcACHEOKAXqk13HYQQ1woh1goh1tY21uXxCOLll1UtQq3CPLi78MxmtbC5qkp5A6VUltnIkcq1p+HnF0Vy8lLCw49nx47L2bv3TubNs1NaqtaRzZ8P112nMvU/+EB1d67TDq1PH3pdPJkDJHF4+Q5iU1crNbn7bvr1qHTOTUsE8bTMGkMINWbgQFfiiC9ocbMjwTKD1kvP1+Jx0dZor9mMCSEJQNOy0/Q3bW3NFThiZo6MQtBVk3BkNGqWXL2WmdV7Q089npaZhn5bczLtMksziQ+JB3BZZl7S89OKVGsHb27Gprje7vn5HiprK5k3fh5LU5fy7J/P8tjvj3H+sPO5dcKtnD1Ypf82xzr/Le03ymrKqLXXsjVbRVfWZ65XCTNVRTywzLX2tz43I6jPr0/+0H/Wo90yczT0HAvsRGU03obKaGyUjhSzx4BIIcRGVDrmBsCrUkkpX5VSjpVSjrVYOkcCppak4eenUs8zM9WC4cOH3YVi4EDlbly0SNU61Ffe0OPnF8nIkd/Tvft1pKc/Tr9+5/LMM1UsXKiE76abVEZgQYFanOyN3sNDqJSBbA2fRMzwOLXY69FHiTxpNJFhtS0SM1BLBxpyRXqdU2/1HBHR9Ou1lLwKd8sMlJilFaU5f1m36NzWaK+dn4sqi0gIVWLWHMsM3ONmnm5GzerT6vw5y0B5iZkBzoaeDeEZM9PwN/sD7pZZamGqT58HlKWkCbvWrNSbZeZNzHy1Vg6XHuaPtD9YuG0hb218i7nj5/L4tMcZETuCW5fcikTy5DTVnrElcdNFuxchUAkdWlm0DVkbGBY7jH+M/Qcvr32ZLYe3AN7djJplBtQRs86c7NIUhBBXozx2tzke7wHzfRnbYWImpSx2tMRORsXMYoD9HTWf1uaDD5Rw/cvRf3PbNlfGoKcL76ab1ILiG2+E4mJX5Q1PTCY/Bgx4if79n6Ow8CsmTjyW2FjVxLNHD+XSDA1VSY3e0Kygw0VBxB7bV03y+++hpIS+xZvY9/N+9u2VWCwqrtdUpk2DU05p2piOsswqaysprymva5lFD8Au7ewr2FfPSN/QrL6ooCjKasrcxLGoqoj4YGWNNFfM9BmN3hJAoK6bsaGYWWOWWWVtpVPENFHTv9bEbPGexfR5to9P7XSklKQXpTvT7RuKmaUXpQOQGOZy3mg3+IZcgpklmQx6YRDHvXUcF3x2AXEhcdw7+V4sJgvPTldh+jsn3ekUyX6R6ldcc6zzRbsXMa3fNMICwlifuR4pJesz1zM6YTQPnvAgof6hLFi5AGjYMgPquBm7imUG3AIcAxyQUk4FUoCchocoOkzMHAUk/R1vrwaWSymPiqoiUqo1zaNGqbXMoFql1Gf1mEwqmUMzOr1ZZhpCCBITb2LEiO+orNzHhg0TKCtTq5xffBE2bYLgYO9jNSsIXLEqpk+HTZvo16OSvbtq2fvOb/RKstNeBrA2p46q/qHPZoTWS8/X4nGa5afFpLSmjJprrali5mdSax4asszqczM2FDNrrHJ+VW2Vm3BpaJZZkEUlgHy5XVW6W5G+otHPs79wPyXVJYyMU4sSG4qZpRWlEWONcXOnBlgC6Gbt5oyneeOun++ioraCz8//nB8u/oFN121yivrUPlPZf8t+7p9yv/P4IL8geob1bPLff2/+Xnbm7eT0AaeTHJ/MhqwNZJZmkl2WTUp8CtHWaCb3msyaQ2uQUirLzFPMGrLMuk7MrFJKWQkghAhw5FMMamQM0Lap+R8BK4FBQogMIcRVQojrhBDXOQ4ZAmwTQuwAZqAU+ahg+3ZVReP665VoxMQ0bJlp2156SZWXGu7DIoXo6OkkJy9Hylo2bDiOoqI/sFrVYub60Bf+jYnR7YiKou/FE0k19WX3oWD6FqxTC+A2blTZJZ5tpFuRjrLMPEtZaWi/iFua0ai3zPTXK6spwy7tRARGEGQJavKiac2FqM9o1NaZaQRaAgnxD2mSZWaTtgYtHG9uRi0tX7tmRW0Fi/aoZhq+WGYbMpUrLiVeuSK0m7vXmFmxe1q+Rs+wnqQXp3s9/+qDq3ln0zvMGz+Pc4acw7R+05zfn0bviN5ua71A/Rto6t9/0W71uWcMmMHo+NFsytrEmoNrABidoH6dpsSnsCN3B/kV+dTYa+q4GYP8ggjxD8EkTPSJdP+P3IVS8zMc68z+B/wohPgKOOTLwLbMZrxQSpkgpfSTUiZKKd+QUr4ipXzFsX+llHKAlHKwlPIcx3qCowKt+/IJJ6jnYcOUmO3dq2JDUVHex116qYqZBQR43+9JaGgyKSkr8fOLYdOmk8nN/arB48PCVMdn0FlmDvr1F9TazWwUKfQrXKdMppQU+L//U9Zbbq5vk2oivlpmO3J3NLv5o569+XvJK8+rU8pKQxOgFltmjnicZvlp19MXmNW39ZBSsvbQ2gato/KacuJCVMJvQ5YZuNdn1FyS+moTepxzbCCj0VsCiGaVads2ZW0iozgDszB7baVTUVPBpqxNzvcbsjZgFmZGxI0AwM/sR4h/iFfLLL0onZ7hdX3fSeFJzniaHru0c/P3NxMfEs/dx99d7+fyRnOSgBbtWcTA6IH0j+pPSkIKFbUVfLztYwSCUXFqgebohNHYpZ3f034HvP+4iLHG0Duit9t3C+2Xmi+EmC6E2CmE2COEqFOJQwhxkWNt8GYhxAohxCjH9p5CiKVCiO1CiG1CiFt0Y+YLIQ4KITY6HjPru76U8mwpZaGUcj6qAfQbwFm+zN2oANIGrFgB0dEwwOEp0ItZcxIrGiIoqDcpKb8THDySrVvP4dCh/zZ4vGYJ1REzx7zs0kS/y45TXTufflrF1NLTYdYsldXSygwdCg8/rMpz1UdFTQUp/03h9fWvt/h6J793MjM/nEluuRJnTzcjqLhJS2JmFTUVVNZWEm2NrmOZaeuzwgLC3MRsVcYqjnntGF5b/1q95y2vKXe6J91iZrUVdcQsNjjWmQCSXZZNqH+os9yVJ55z9ERKWSc1X/8MSsw0a/GikRexNXtrnSSaGxbdwNjXxnK4VPUbWp+5nqExQ93m7q3YsJSSA0UHSAqra5nVJ2YfbP6APw/+yWMnPVave7U+BkQNIL8iv9E4okZ5TTlL9y9lZn91j9YssS+2f8GA6AHO62s985amql5Mnm5GgEHdBjG2+9g6280mMwHmgDZ1MwohzMCLKE/ZUOBCIcRQj8P2A1Mc64MfQrUGA5W8d5uUcggwHrjBY+zTUspkx8OnXphSyl+llF9LKat9Od4QszZg5Uq1fkzzXgwbprx2K1Z4dzG2FH//GJKTfyEq6lR27bqOnTv/js3mXXg0S8jNzYj7vPqeMRz++EMVUpw+Hd57T02+Tx849VR46CHV+bMVMJmUJzOugRWGWmV1rfRRczlcepjUwlRWH1zNc6ufA+q6GUHFnBpbd9UQ2tiooKg6MTOnZRbgbpkdKlGelHt+uafe+oTlNeXEBasvytPNWMcy0xUb3nR4k9P68YZzjvVkNNY4GsZ6Wmb6rEYtlpUSn8JpA06j1l7Ltpxtzv1rDq7hrY1vUWuvZfGexYCyzLQbvIa3YsNFVUWUVpd6dTMmhSdRXFXsVmWjtLqUO366g3E9xnHJqEvq/dz1MTBaVdb21dW4dP9SqmxVzBygxGxwt8EEWgKptlU7hQ2USzQ6KJplqcsA6rgZAT477zPemvWW1+usvGolc8fPbcInaTLjgD1Syn0OAfkYmKU/QEq5QudFW4VjOZWUMlNKud7xugTYDvRoy8l6YohZK5OXp0pS6atgaDGwkpLWt8w0zOZghg//mqSku8jMfJUNGyZRUVE3ObQ+yywx0VVPsc4czztPrc4++WTlbrz/ftWV86uvVD+1r792rfpuA7Qbt2dNwqaiub6igqJYfmA5UNfNqG3z9Ve5N5zJJUH1W2aam1Fbm6VZI7nlufz713/XOadd2p2tUsBHN2NZDnZpZ2PWRmdcyhuNWWaahdWgZWZW1585YKbzBq7FxKSU3Lz4ZuKC44gLjmPRnkVklmSSVZrF6Hj3bCdvxYa1TEZvbkZtEbU+bvbob4+SWZrJs9OfdVZaaQrOuKmPrsbvdn9HsF8wk3tNBsBisjAiVv140H/vQghSElLYdFi5Wr1ZZsH+wfUWEk5JSHEu6WgmFm29ruNxrcf+HoA+AJlBw4J0FfC950ZH1Y4U4E/d5hsdrsk3hRCRzZt+wxhi1sqsWqWe9fUJtd5f0DaWmYbJZKFv3/9j+PCvqajYy7p1o8nL+87tmBNPVKEwTzEzm13JI17nOHu2stDWrVP1ucxm5RucPFm5IJOS4Jxz1DErV7r6urQC2gJhz6aUTUW7uX54jqof5m/293rj8GXdVUNoY6OCorD6WQkwB9SNmXlYZpo1cuHwC3lhzQtsz9nudk4tXhgZGImfyc9N2D0TQMAVM9uTv4eS6pIGxUwfM5NSsnjPYmeFD1DJH+CyxPQJIBqamM4cMJO+kX0J9Q91JoF8sOUDVmWs4rGTH+O0AaexZM8S1hxSyRG+WGbe1phpaNu0Y/YV7GPBygVcMvISxif6WIrGg76RfTEJUx3LbE/+HvYXuP9AlFKyaPciTu57spulqgm63jID3MTbm2XWxtRq63Udj1c99nsr9e01iCuEmIoSszs8tocAnwNzddnpLwP9gGQgE1jQ/I9QP4aYtTIrV6r7/DHHuLZFRUG8+kHdZpaZnm7dzmDs2PUEBvZhy5bT2bv3dux2dUM680xVMstb6n3fvsr9WKd6iCdTpqhS9//7H/zwg3JJzpunrLRLL1VmaVyc6nGzY0eLP48mZi21zNZnradvZF9O7X8q14y+hsHdBtfJZANlUZVUl1Bt88lVXwd92r8Qwpn6Di6LKjwwnCC/IDcxMwkTz0x/BoHg3U3vup1TO87qZyUsIMx5HimlV8ssNjiWalu10wL1vKnq0RYr55XnsfzAcmZ8MIN3Nr7j3K9ZZto1vLkZ+0b2pU9EH47tcSwmYXKmp2suv7Hdx3LpqEuZOWAmRVVFvLjmRQCS45Pd5xIUWSdmplld+lJWGpqYadbb6+tfxyZtPHbyY/V+3sbwN/vTK7wXu/JdC6eLKouY+MZEjn/reLe41fbc7RwoOuB0MWqc3PdkwgLCGJMwxm27Xrzryy7tQDIA/ZeciJdMQiHESOB1YJaUMk+33Q8lZB9IKb/QtkspD0spbVJKO/Aayp3Z6hhi1sqsWKHS6z3XemnWWXuIGUBQUF9SUlbQvfs/SE9/inXrjqG0dEuDY267DR7z9R4QGKgssmnTlHg98YRyNW7fDt99B9deCx99BEOGqLTO116r2+/GRzQR8yyw21Q2ZG5wWiivnP4Ka65Z4/U4zVJpqLdWQ+hjZtr5nDGzKu+WWUFFARGBEcQGx9I9tHudtVN6MQsNCHV+F5rV5C1mBrBk7xL8TH4Mix1GffiZ/QgLCCO/Ip9vd30LKNeZhtMya8DNOG/CPHbeuBOzyQwo8dx0eBMPL3+YQyWHeG76c5iEiZP7nozFZOGHvT/QP6p/nRt6RIB3y8xisjhdrHriQ+KxmCxOy2x95nqGxQxz63vWHDzT8//967/JLc/lYMlBHvvd9Z/EmZLff4bb+NlDZpNze45z7ZyG/keFNzdjB7MGGCCE6ONYAzwH+Fp/gKMI8BfAJVLKXbrtApV5uF1K+R+PMXrf6NmA104qLcUQs1akthZWr/beAiUlRQlcotfqk22D2RzIwIEvMWLEd1RXZ7Nu3VjS0xcgdUVq9Zx8sjKmmo2fn8qCnDlT1fI6cEAli2RlKXEbMkTF15qI083YjOKvGkWVRewt2OsUM5Mw1Ul/1vC1+3J96GNm2rMzZlZZhEAQ4h/i7masKnRaSPEh8XWSXeqzzDy7TGtoC3B/2vcTw2OH1/tZNbRiw9o6sR/3/ei0TJ0xswYSQIQQ+JldTexS4lMorynniT+e4OKRFzOhp/pPER4YzvFJxzuP8SQyKJLiqmJsdptzW1pRGolhiU6h1GM2mekR2oO04jS3ihstRUvPl1KyM3cnz61+jitTruRvI/7GkyuedJbsWrR7ESNiR9SJ5wkhvH7n/aP6O5dIHGmWmZSyFrgRWIJK4FgopdzmsT74fiAaeMmRZr/WsX0ScAlwopcU/CeEEFuEEJuBqcCtbTF/Q8xakQ0bVP1Fby1Q7rnH5YJsb6KjZ3LMMVuIjp7J3r3/ZNOmk6iszGj7C8fGwr33Kmtt+XK1yG3WLKXsU6ao2pC/qzU3SAlr16peNvv3qxbUDprrZiyoKOCTrZ8gpWRj1kagYXebhiZCmgDZpZ0Pt3zodoNtiLzyPIIsQc4MP31Ven1TRqulrmUGquuy1udLQ0sUCfILItTfZZlpYqavjAEuy6ywsrDBeJn+M6/PXM9fOX8xtfdUSqtLneuh6lhmXmJmnmjfc5BfEI+d5G7uay45b38L7TvQ93zzbMrpiZaef6jkEDnlOT593sYYEDWA4qpiHvz1Qa746gqsflYeOfERHj/5ccwmM5f97zL+77f/47e03+q4GBtCc8GG+Id4FeeORkq5SEo5UErZT0r5iGObfn3w1VLKSF2a/VjH9t+llEJKOdIzBV9KeYmUcoRj35lSypalJdeDIWatxM8/q3iU1epaLK0nIkIlAHYU/v4xDBv2BYMGvUFx8RrWrh3V6CLrVkMIOP54lTzy+ONK5IRQMbbjj1dJJL16qUDjCSeo4F2PHqoXW22t88bdVMvs3U3vMufzOXz616fOTEbPhANveHZfXn5gORd9cRE/7P3Bp+tqFfM13CyzKleBWc8EEM0llRCSQGaJb5aZlhhSn2UGvn3maGs023NV0smCUxbgb/bnu13K1ehpmXlzM3oyJGYIfSP78siJj9AjzD0h7pwh5xBjjWFa32l1xmnz1ov5/oL99IroVedYjaTwJNKL0p1/49awzCb0nICfyY8Hf32Q1QdX8+S0J4kLiSMxLJFHT3qU39N+555f7kEgOG/oeU069xkDz+DYHse2eI4G7nSOEvRHOG+8oVq4DBqk8iESWpQ923YIIUhIuJLw8OP4668L2br1LLp3v4F+/Z7EbA5q/AQtxd9fVV7Wqi+Xl6saXv/9rwo0PvwwdO+u3JPvvQf/+Ae8+CKlD54MNBAzy8lRJUT83S2FA0UHALj9x9sZ12McCSEJXuMunmgxM02AMooz3M7XGPkV+W6LsbXsSK0uoxYrcYuZVRY4b/oJIQnkVeRRbat2Wj+eMTNtUXe9bkZd0Vpfbu6a+PaL7EdyfDIn9D6BRXsWseDUBXUsM29uRk8sJgt7btrjNcGmb2Rfsm/P9jquf1R/QGUODo0ZSkVNBenF6XVqFerpGdaTjOIM1h5aqypuxDfQEt1HxvUYR9ndqvSYp8vw5mNv5rqx1yGlxGwy17sYvT7+Nelf/GvSv1o8RwN3DMushVRWwt13w3HHKS9ZR1pfvmK1DmT06BUkJt7GoUMvsn79sZSWbmp8YOtPBP75T9i9W8XSLr1UBe6uugqWLlVtuLOzKX1TdektqSpBLlig2ndrPPecsvRCQ5Vl9+OPzl1pRWkE+wWTVpTGZ3995pOFAnVjZpqV5K3ShDfqWGbWaKpsVVTUVri1/rD6WamsrcQu7coy08XMwN06cbPM/BuPmVn9rAT7BSMQzkK+DaG5VmcOmIkQgpn9Z7Ijdwf7CvbVtcy8VM/3hjchawzP2ph7C1Rd0IbELCk8iRp7DYv3LGZg9MB6y3Y1FT+zHwGWAK/uVH+zPwGWgCYLmUHbYfwlWsgHH0B2tkrcq69afVvz9c6v+TX1V7dtoQGh3HXcXXV+PR8sPsjP+3/m0lGX0r//U0RGnsyOHZexdu1ounf/B336/Bs/v3qKR7YnQqh1bCNHUnLvGKASiaTs7n8SUg3ccouy5m65RSWcDB+uFnb/7W8qRtetG2kFqUwKHkxE974s/OvTOgt060Mr/aRZZpqo+Cpm+RX5DOk2xPle77bUN+bU1rhV1lbWiZlp19VSz+vLZnTGzCx1LeuY4Bhn0eHG0OaoxX9mDpjJ3CVzWbR7Eb0jegN1LbPGkkqag2dtTE3UPFui6NG+oz8P/smc4XNafU4GnQNDzJqI3a6WV02dqjxbCxaoe+rUqR03p+u/u57DZYedNxmb3UZFbQXHJx3PSX1Pcjv2rY1vcd/S+zhz0JlEBEYQHT2dceO2s3///Rw69DLZ2R/Tp8/DdO9+DapUWwfTty+ls2bAjo8AKP7zV0Le/Z+qGwnqi//8c7VU4OKLVf+cefPgmWdIS93EyL9qub+wlm2z+vocqNfWhmkxMy2z0FcxO1x6mMlJk53vh8aoEnWfbPuEosoiBncbDLjELL8inypbldMy08ROHzfzjJmVVpc6q4JAXcsMYGb/mc7CxI0xqeckju1xLFN6TQGUePSO6M3yA8udlmJTYmYtQV/oV3tu0M2oyyRsjeQPg86J4WZsIs8+q4phpKTAI48oI+Cf/3TVYWxvDpce5mDJQZ44+QlK7iqh5K4Stl6vlnF4u/lqBXa1IrQAfn5RDBz4AmPHbiA4eDi7d/+DdevGUlLSeBuP9qDU5MpsLEmMU83i3n4bLrpI/bIIdNzIR4yAO++E996j6pjRHA6sJWnUZJJ2ZrH1n/uZ8H/vQr5vZaqig1xrwzQxq6/ViJ7ymnLyKvLcqlVM7DmR0weezr9//TdZpVnOmJmWgXiwWK0p87TM9On5bpaZo2N0aXWpM8vRm5i9eNqLbr26GuLU/qey6upVblmRYxLGsCFrQ51yVr7EzFqCfo3X7rzdxFhjGqyWof+uWyP5w6BzYohZE9ixQ8XHJk9WBXLvv1+tGzv//I6bk7csvR6hKpHAm5hprjOt15WekJCRJCcvZejQT6iuPsy6dePYv//+eosWtxf6lHxnRuNll8H776u+NnruvRcGDyajQrkGk865AnbuVF1SX31VZek88IAqyeXZBeCvv5xluPRVOzQ3Y0ZxRqPp+VolCs/SSwtOWUBlbSVlNWXO9UWaZaYVGdayGWODYxGIBi0z7btoyDJrKSnxKezJ3+MsWNzUmFlzGRA1gPTidCpqKtidv7tBFyOoxceawBuWWdfFEDMfqa1V90+rFT75RK0pu+kmeP55V4HejkCrN6gvCxRgCSA+JN6rJaFZG9oNyhMhBLGx53PMMduIi7uIAwceYvXqgRw69Dp2Xb2+9qS0utTZYbnRKiABAfDrr6R99gbgKIEUHg7PPKPqeI0apbImp05VwrbfUWvv889V3C0+HmbNIjq7hLzcdCgtJbMkkyBLELX2WrIKM5QI2u1gs6mFhVWuVifaDwjPRbQDowdyy7GqxZM+mxFwVvvQLDOLyUJMcIxbAkhFTQUCQYA5wNlSpKSqpN51Zq2B9gNp9cHVQF33YlvEzMDlUtxbsFeJWQMuRlD/ZnuG9yQpPMlrS59Oydatqpegzbe1jQaGmPnMm2+q6h4vvqjud+HhKpGuoT5c7cGGrA30jezrvBFq1NfnqSHLTI+fXyRDhrzDqFE/4+/fnV27rmHt2lEUFCxttbn7Sml1qddq8fUSG0t6sLoJuFlIo0bBTz+p1gaff67Ka518snp98cVw7LFw442wbh3RqzaTf3APFd1jKKoqYkywShlPnzAUgoLU6neLBUJCoFs31UEASN+hCoUnzb5S/QMpci3+vXfyvUzrO43je6kKGHUss0BX6aOEkIQ6bsYgvyCEEE7LrKS6pE0tM81ltzJjJdBwBZDWRLPENmZt5FDJoUbFDOCiERdx7WjPIvBHGL/9Brt2NX4cqNjFPfeoH14GPmGImY+8/75qJHnBBR09E3fWZ6736lrpGdbTq5hpSQ36mFlDREaeyOjRKxk27Evs9go2bTqRbdvmeG0v01aUVJc4a+35WgVE++yJYV7qh0VEqAr/ixerVNRzz1X+4m++URk96elEXXwNeRH+ZF54BgDjvld1LdNOcHTfnj9fPR5/XJXwOvtsmDuXtOcfRkjoYYlUmZYDBqhlBqhSTj9c8gPHBQ+Bl1/G+tzLABz8RQmh/gdJQmhdMdPET3OpFVcVU7HqN6BtxCw+JJ74kHhn6SbPCiA+uxl/+QU+/lhZsz6giZdW97AxNyPA3cffzT2T7/FtPhqVlXD77WpNY3m5ckdfeaWqfrBtW+PjG6KwENboan+mp6s6pscfDxmNVN/JyFALVrt1gwcfVP9ODRrFEDMfOHhQVV264IKOS/TwhlZv0FvQOyk8ifTidKR07+DgtMzqcTN6QwhBTMxZHHPMNnr3nk9e3tesXj2I3bvnUl2d27IP4QOl1aVOMfO1CkhaURox1piG3W/jxqmiyKeeqjpqd+umtgtBdFwfKmQ1++/4uzr0rOvVeS87C+66S8XdHnhALQBftkzdAJ99lrQEKwnBcfitWgN//qlajk+bpn5l338/nH66WlV//fVYF6k1cYfS/wIg0u5y28VX+ZN5YJvqJZeaSnmtS8ycltkbL1H53tsABC773f2zVVTAO++oubUA/b8tnyyz9HRVQSDL4SItLFQZUxde6FqMqf2bLC1VQrLbvdVKeGA4MdYYluxdAjiaZUoJL7+szt2cgtUlJWodzbffura98AI89ZRa3xgXp2qHfvyx6gIxerT6Oz//vEo4ysqq/9x6MjLgjjtUS6Rx41SCEqgapXa7Es3Zs91c03V49131eZcuVa7vCy5QGWcJCeo8Bl4xUvN94PPP1b+t+hI9vt/9PS+secFNOAIsATw09SGGx6rOnMtSl/Hj3h955KRH6ox/Z+M7fLLtE6/nFkJw4zE3MmOAqsq9r2Afj//+OAtOXeCsN+jNMksKT6K8ptytGoVd2p3tNZoiZhpmcxC9ez9AQsI1pKbO5+DB58nKeoukpDtITJyL2ey9qWBL0YuZr5Xz04vTvfa/qsPkyerhgbbu6q8cJTSDz76W0LfecyZ4uBEcrP6RfPMN6QXPkmR3JJaMG6d801dcoaw5k0lZajfdBJddhrVHILwwiEODe0DNQSJmngMjU+DAARLELxyeCPbF32NatIjyW7pjteVBt26ExgfAeVD83ZdUnjgWWEvg3H/CiTPUP9Qnn1Q36txc5Q7VRECjpkb5y6dOVa5Xb0gJS5aQ8st2FvUEkx0sl10BTz5JgEX9ovPftgMW3qqsjXPOUePuvBM+/FCJ2KefqiUUhYXKin3xRbWwvW9fGDNGWRwlJSoL1aMv0cDogfyR/gcA/QO7K8F5/321c+1a9SMkIUGJTGyse9HT3FxYskTV+SwoUK7e339XAm82K5EYNkylI0+frub8/vtK0G6+WZ3j5pvdW0i8+65qiWG1qjqjS5YosQsJUd/VwoWqM8Qvv6hfvBdcoFKdr75a9YB68024/npVrm32bFXd5o031LFpaer4yy6Dv/8d3npL1S4dPlwVCJg7Vx03diyMbHwBfFfFEDMf+OQT9W9o8OC6+/LK87joi4sI8gtyZhEC7MrbxWVFl7H66tVU2aq49MtLSS9OZ96EeW5Baikl9y29jypbFb3C69af25W3i5KqEqeYvbbuNV5d/yrR1mhig1WHTW+WmVaYNa0ozXm9osoi7I6K+Y3FzBoiIKA7gwa9SmLiXPbtu4v9++/h4MEX6N37QeLjr8DUilURbHYb5TXlxFhjMAtzkyyzgdEDm31d7Tvbmq2WOSSEJqg4ZHE9a80czUrTXrjDvUdXaKi6qR84oIKtgS53oNVRJuuQuQxrbQD+B7Mg6weIiSHhzOnUmhaTt+53YubdS3nqd1hjA+GsswirKQI+o+Sic6kcMwjTb+vx27Nf3ThXr4Y9e5SleP31ai3JtdeqTM2bblLCe955Kn4TGgqLFqk2D6++qgRi1CjVpfWVV2DdOlImRkBPCBAW9R/h/fdJMMFlZ8KJL74GOTiPpbZWVQ/o108tYH/nHSVms2crK/bmm9X+xYuVIMyapXz3d9+tBPemm5zfzYDoAfyR/gcJIQmEnOkoSP3QQ0oEzz9fiVFNjUrA6ddP3fDDwpTo/PKLEpioKCVQVqsSinPPVSIyZw6ccgoUFyvhHz5ciYeejz9WSUMWi+q4e+aZ6vs94wx1rpoaZXW99JI6x3ffqXncf7/a36ePSn8ePVrFZf391eeMj1fH/Pvf6t/CQw8pQd2+XV1H+/vde6+aR//+7takQf1IKTvVw2q1yvYkLU1KkPLhh73vv/7b66X5QbPcenir2/YPN38omY98fd3r8oGlD0jmI5mP/GnvT27Hbc7a7DzOG/f8fI80P2iW+eX5UkopR7w0QjIf6f+Qvzz+zeNlwlMJXsetzlgtmY/8asdXzm2783Y755H8SrKvX0GjFBT8JtetmyCXLkX++edQmZu7SNrt9lY5d1FlkWQ+csGKBTLysUh543c3NjrGbrfLkP8LkTcvurnZ1/1538+S+chJb0yS5gfN0ma3yRnvz5Cj/zu6wesGPhwob1tym0/XyCvPc/49ui/o7rbv022fSuYjN2VtklJKeeJbJ8jj3jxOSillZU2lZD7ykeWPyNuW3Catj1ilvPhi9Q+1Tx8pf/nFdaKaGin//ne1D6QMDpYyKEjKF16QctAgKa1WKZOT1b5evaQ0m9Xrvn2lfP11ue/wDsl8ZORjkVLu2CHlAw+o/wxPPy3l8uXqP0hMjDrHjBlShodLmZUl5bBh6jxCSLnV/f+Gx5cm5bRpatzhw2rshg3ykeWPSOYjJz/cT53nzTddY9avl/KCC6S8+WYpn3pKyvHjXZ+vb18p77tPytWrpbTZ6l5v40YpAwPVsVde6dPfSUop5SOPuK4xZYqUX3whZbdu6n1goJTPPuv9ei+/rI654w73z3zHHWp7dLSU/v5S/vCDlOeco7aFhEhZWur73HwEKJNHwD28rR6GZdYIn36qnr25GDcf3swr617hhmNuqNP8cM7wOby45kXu/PlOSqtLOaXfKfyw9wfWZ653q8rhbO43wL25n8bMATN55LdH+GHvD0zsOZEt2VuYe+xcXlv/Gr+l/cZpA07zOs6znTy4kj/iguN8TgDxhYiI40hJ+YPc3C/Zt+8OtmyZSUTESfTsOY+oqOkI0fzQrJbwEeIfQmhAKMXVjVtmRVVFlFaX+uZmrAetVuG2nG3EhcRhEiZ6hvVk7aG19Y7Jq8ijsrbS5+vqS1DpMxnBVZ8xsySTkXEjKbdVOmNlWr1ALTU/0BKo3IqTJ6vYVIiufJXFoiynO+9U/5g3bFBxvuRkZamccgocPqwspgsuUDGd3buVtWKx0FtKIgIjVHxs0CDlLvTkjTeU5bJxo3LdxcWp4tHHHaesoGHD6o7REEJlfY4YoR7Z6t/lgHnTIQwGrD+gLJfLL3eNSUlRlpPGbbcp12NNDYwf33Bge9QoZYU++qiyjnzlrruUO9BmU3G0wEDl9nvuOVVL1JvbBpTbcOhQNS/9Z370UWXNP/GEiuVNm6ZckLfdBr17d1xtvE5Mm4mZEOJN4HQgW0o53Mv+cOB9IMkxj6eklG+11Xyag5Tw1K8vY73lTf62DPpu6stbs97C6mdFSsncxXOJDIxk/gnz64wVQvDs9Gc55rVjCLQE8toZr3Hcm8c5FzlrLNqziOT45Ho74x7b41iigqJYtGeRs8fTNWOuITY4lrt/ubveRaIxwTEEmAPcxExL/hjcbTAr0lcgpXQrBvvx1o/Znbeb+6bc15Svyfl5Y2LOITr6dA4efJH09CfYsuU0AgP70aPHDcTHX46fX2TjJ/JA62UW4h9CWECYT9mM9a31agpazKywspB+kao9eFJ4EjnlOVTUVPDupnd5fcPrAHQP7c6n533qvK6vYqbPQPRcWqGVtNLWmpXXlLtV/A8LCOPNjW9il3Z1nvBw97iYJ717q8w9PXFxSgTAtVgyOFgJnQMhBMnxyewvaCB79Ywz4NZblTvsFrWWjkmT1LmHDKl/nMbgwSo+pY0/fJgBHz4H18GAfAFvvtR45tXYsY1fR+OSS9SjKQihfhTo6dlTuRgbG+clJosQSvjvvtslXH5+ShwNmkVbWmZvAy8A79az/wbgLynlGUKIGGCnEOIDKWV1G86pSbz+1XYyR91MYuBgooN6sHDbQoZ2G8oDJzzAlzu+ZGnqUl6a+ZJbhXQ9Y7qP4cWZL9LN2o2k8CRGJ4x2E7PCykL+SPuDO4+7s945mE1mpvefzve7v6egooBe4b0Y0m0IfSf05WDJQS4aeZHXcSZhIjEs0W3htLZgelD0IH498KtqR6IrE/T2xrdZlbGKeyff26yK5wAmkz89e95Kjx43kJPzBQcPvsDevfPYv/9eEhNvoVev+5rUbkYTs1D/ULemlA3RVFHxhj6uqZWX0s738/6fufH7GxkUPYiIwAi+3vk1yw8sd861oUaSeoQQzjYwWvUPz2tq6fkVNRVulty88fP4PV1lMGr1FJuFDyv+/zXxX86WM/Xyn/+oG7s+EWPMGN/ncdtt6uFg+LAh3PzVDZx/xp0q/nS0YlhgrUabiZmUcrkQondDhwChQt01Q4B8oGNKTHhBSsldy25FWINZdf0v9IiIYc5nc3j8j8e5cMSF3PbDbYyIHcE1Yxr4NQz845h/OF+nxKfw9c6vKa0uJcQ/hB/3/ohN2hotgDuz/0w+3PIh3+76luvGXocQgkBLIC/MfKHBcZ4Lp/WWGaiMRr2YpRWlUVRVRG55rls/rOZgMvkTFzeHuLg5lJRsID39KdLSHiUn51P693+eqKhTfRJMTbw0y0zLxmyI+kpKNYUgSxAB5gCqbFVOK0mz9K795lqsflZ+vvRnQvxDiH4imkW7F9Enok+Tr6uJmadlppWt0kpa6deZAdx1/F3N/mxNpT4XeB1asY265drrePbiS1XyhoGBD3TkOrMXgCHAIWALcIuU0uuqSiHEtUKItUKItbW17aN3L/zwHXmRS5hpfYAeEerG/sS0JwCY9OYkUgtTeXb6s03qZzQ6YTQSyebDmwHlYowKimq06+z0/tMRCCSy3hiZNzzFLK88D4FwZvnpMxqllM5jtUrlrUVoaApDh37AqFE/IaVky5YZrFs3mqys97DbGzbEnZZZQKhqfeKjm9FishAX7FvFeG8IIZzWmebe00QqszST+yffT1xIHMH+waqR5e5FpBWlEWgJpJu1m8/X0QQqIiCizr74kHiyylxuRr2YdQkMITNoAh0pZqcCG4HuQDLwghAizNuBUspXpZRjpZRjLZb2yVm5b/ntiLxBvHHdDc5tSeFJ3DHpDnLLc5k9ZDZT+zSt74tW62595noqaytZtHsRp/Y7FbOp4V+00dZoxieOJ8Ac0KRr9gzryaGSQ9Q6airmV+QTERjhbAuiTwIprCykrKYMcPWQam0iI09i3LhtDBr0BnZ7NTt2XMqqVX1JS3ui3sXXbjEzXVPKhkgrTqNHaI9Gv9fG0JJANMssMSzR+WPgpmNdaeQzB8xkZ95Olh1YRs+wnk1y0WoC5elm1K6rlbrqkmJmYNAEOlLMrgC+cGSN7gH2A/WkBLUv+WXFFPnvYJz/FcR1cy+m+q9J/+LhqQ/z/Iznm3zeHqE9iLHGsCFzA8+seobssmyuSrnKp7GPnfwYr5z+SpNuaEnhSdil3XlDzKvII9oaTYxVWZr6hdN6C661LTM9JlMACQlXcswxWxgxYhFW6yD27buDlSu7s3XrbHJzv3UraOyZzehLzCyrNKvehJqmoMVCtfiVv9mfp099mg/P+dCtyK7mJl57aG2TXZtOy8zDzQiqrNNfOX9hs9uoslUZYmZg0AAdKWZpwEkAQog4YBDQSJS5fVj1l4q5pPSpu4g5yC+Ieybf47zBNQUhBCkJKfyS+gsPL3+YWYNm1WmeWR+Te03m8uTLm3Q9z/T8/Ip8ooKinPEwvZtRnyjSlmKmIYSJ6OgZJCf/zNixm+nR4yaKin5j69YzWLWqJ3v3/ovy8t1uCSBaNqNaMlM/OWU5LY75AXXcjAC3jL+FMd3dExv6R/V3um6bK2aeqfmgLPn8inx25u10O9bAoK0QQkwXQuwUQuwRQtTJTBNCXCSE2Ox4rBBCjGpsrBAiSgjxoxBit+O56WnNPtBmYiaE+AhYCQwSQmQIIa4SQlwnhLjOcchDwEQhxBbgZ+AOKWXbF/rzgTW71c0/pW/zEwjqY3T8aFILU6mx17DglAWtfn49WsKCJmZ5FXlEB0Vj9bMS7Bfs1TJLjk9uMzdjfYSEjKB//wVMmHCQ4cO/IixsPBkZT7N69UB2pykLONg/mFD/UCTS6Q6tj5zyHKf12RKiAh2WWUjjP1xm9lfWma+ZjBoNWWZaZZff0353O9bAoC0QqrX8i8AMYChwoRBiqMdh+4EpUsqRqHv4qz6MvRP4WUo5AHWvrz99uwW0mZhJKS+UUiZIKf2klIlSyjeklK9IKV9x7D8kpTxFSjlCSjlcSvl+W82lqWxNUzf2CcPaQMwcN6h54+fRL6pfq59fj2YlHCg8ALgsM1Dr0DzFzM/kx3E9j2NX3q5GrR9v3PHjHfzrx381e74mkx/dup3J8OFfMn58Gn36/B9FFdn4m2Dn9r/hJ1Umoz5ullqYytAXhzoFWEqpsjFbQcy6WbshEG6WWX1orsamWmZaur23mNnIuJGYhMlZo9AQM4M2ZhywR0q5z7FE6mNglv4AKeUKKaWWUrwKSPRh7CzgHcfrd4Cz2mLyRtV8L+zNTQe7maGJTXclNsbpA09nwSkLuHfyva1+bk9C/ENIDEtka46qL5hXnudMaoixxrglgKQXp9MzvCeDug2irKbMrTGkryzZu4Rvd7VOHbmAgAR69bqLsG4XEupvJS/vO3IPPgrAztSnqa1VC8g/3fYp23O3s+aQardRWFlIrb3WWbeyJVw39jo+nP2hT327TuxzIs/PeJ5zh57bpGs0ZJlZ/awM7jaYP9IMMTNoFSxaVrjj4dkArgegr6Sd4dhWH1cB3/swNk5KmQngeG75f04vGOWsvHCoLA1/S8uz4bwR5BfEvAnzWv289TE6YTTrM9dTa6+lqKrIaZnFBsc6E0NAWWY9w3o6e0ntzt/d5LhgTnkORZVFdSqLtISymirCAuOYMGEd+9feDzteYOf+p7AUvkpCwlV8vf0XAOd6LE2gWyNm1iuiF70i6sZNvWE2mblx3I1NvkZDMTNQaxM/2PIB4F7+ysCgGdRKKRsqleLtP61XF40QYipKzI5r6ti2wrDMvFBgTyNCtL6LsSNIiU9hZ+5ODhYfBFxJDZ5uxvQi1TJFa4TY1LiZlJKcshzKasoorCxsncmjFk2H+Ifg5xdJ7wRl9ST2e5moqOnsPPAcKw9tAmDbgTcoKvrDJWat4GZsDxqyzMC9I4JhmRm0MRmAPuibiFoH7IYQYiTwOjBLSpnnw9jDQogEx9gEoPUKw+owxMyDkhKoDkwn3tr8un5HEtpC7aWpqtuxM2ZmjSGnLAcpJTa7jYziDJLCk0gKT8LP5Fcno3HmBzO5++e7671OUVURNfYaAK8drjXu++U+Zi+c7fP8S6tLCQ1QnZW1Qru15niGDfuE0ti3sUn1kzCjaA8bNhzHys0XAxAZ0Pqdl9uCsIAw/M3+zs/oib72piFmBm3MGmCAEKKPEMIfmAN8rT9ACJEEfAFcIqXc5ePYr4HLHK8vA75qi8kbbkYPduy0Q3g6faPP6+iptArazfCnfT8BuMXMqmxVlFaXUlRVhE3a6BnWE4vJQt/Ivm5idqjkEN/v+d6ZJu8NfZp/WlEao+K9N31cfWi1s0eYL5RWlzpFTLvha2vPluz7hYjACAZEDaDW38rAgRfxwyrViTd12wmQOYSwsIn06PEPQkObUCewHbnhmBs4ofcJmOrpLKAttAdDzAzaFillrRDiRmAJYAbelFJu0zLQHcl79wPRwEuOUEKto6CF17GOUz8GLBRCXIVaktUmN1dDzDxYs/0wmGsY1uPocDMmhiXSzdrNKWb6bEZQca7DpYcBVybewOiBbm7GxXsWAw1bXG4uy+L0eo/LK88jrzzP57haSVWJs+mpJmrFVcXYpZ3v93zPqf1OpcZew47cHXTvfg3WboeB+xg14D6qyzeSk7OQrKw3iIg4gYSEv9Ot26wmFTpuaxJCExqMTUYERtAnog/7C/cbYmbQ5kgpFwGLPLa9ont9NXC1r2Md2/NwrCluSww3owcb9joWTPc7OtyMQghS4lM4XKYES4uZadl+2WXZdarMD4gawJ78Pc6u1FrPtYziDGx2m/Pc1TZXXUVPy6w+8ivyqbJVUVFb4fU8nmhFmUEtnAYVR9uYtZGs0ixmDphJQkiCMwEktzyXUP9QBvX7NyNGfM2ECen06/cUFRX72L79QlasiGPHjqsoKFhGPaVAjzi0uJkhZgYG9WOImQfbD6kbcf9uR4dlBu5JBJplpq2d2pq9tU7/r0HdBlFRW8HGrI3U2Gr4Ye8PBPsFY5M2Z8r+moNrCPm/EPbm7wVcllmgJbBBMdPa0GiNQvMr8ol6PKrelH69mAVaArGYLBRXFfPB5g8QCKb3n058SDwFlQVU1laSXZbtlslosYTTs+dtjB+/n1GjfiEmZjY5OQvZtGkqq1cPJjt7oaNTrY2Kir3YHXG/I4ljuh+DSZjqjasZGBgYYlaH1IKW98I60tDiZmZhJjxAtXwZFTeK0QmjefDXB9mRu4PwgHCnG2/2kNlEBUXxzx/+ye9pv1NSXcJFI1TfNE2oVmaspMZew5bsLYArJX5U3Kh63Yw1thrngmdN1PYX7Kespoyf9/3sdUxJdYnTIhNCEOofyoasDbyw5gUuGXUJscGxzgodh0sP11v9QwgTkZFTGTz4LSZOPMyQIR9gMgXw118X8OefffnttzD+/LM/q1cPJjPzLbf6kB3NTcfexLLLljn/PgYGBnUxxEyHlJBdlYafDK43VbozoiURRAZFOuNUZpOZZ6c/S0ZxBu9sesdNvKOt0fz7hH+zNHUpty65FT+TH1ekXAG4xEyLqWnvc8pyCPEPYWD0wHotM30vMq23mmbRrc9aX+f4als11bZqp2UGKm62eM9i/M3+PHbSY4B7I8ucspxGF0ybzVbi4v7G2LEbGTz4bazWISQkXE3//s9jsUSwc+eVrFrVm3377qKsbHuD52oPrH5Wju91fEdPw8DgiMYQMx2ZmVATlE60JanVFv0eCfSP6q+aSAZFu20/Luk45gyfozIZw91jhH8f+3eGxw5n0+FNTOk9haExqsyaZnVp2Y5aI0zNIkoKT+Jg8UG32JqG5lrUv9ZibRuzNjpjdBpl1aoGo17MNFfbvcff6xQxzTLLLMlsUl1GIczEx1/GyJGLGDDgWRITb2TMmLUMH/4NoaEppKU9yZo1Q/nzz8Hs3XsnpaVbfDqvgYFB+2OImY6dO4HwNHqEHD0uRgCTMHFsj2NJDEuss++Jk5/A6md1Vv7QsJgsPDv9WQDOHHgmYQFhhAeE12ngmVbssMzKVaX6nmE9sUkbmaWZda6lWWP615plVlxVzL4C96YJWrsXfawoLjiOfpH9mDt+rnObFv/TLLOWVP8QQtCt2+mMGPENEyZkMGDACwQGJpGRsYC1a0eydu0YUlMfprDw90YbixoYGLQfRmq+jm3bgPA0BsYnd/RUWp33z3m/juUDKulj4983ehWAE/ucyPpr1zMsdpjz2LSiNKpt1aQWpgLubsbuod3d2s54iqcWJ9O/1mdBbsjcQP+o/s73+sacGu+c9Q4mYXKrlxgbHItJmNiZu5Mae02rVf8ICIinR48b6NHjBqqrc8jO/oisrHdJTb0PAJMpiLCwiUREnEBExAmEhY3DZPJv5KwGBgZtgSFmOjZtq4T4bAYnHF2WGdBg5XethJU39It2k8KTSC9OZ3/BfuzSTpAlyOlmzC7LJjk+2U3MJvac6Hau+iyzbtZuFFYWsj5zPecNc62n1Dfm1OgRVrfuqdlkJjY4ls3Zm4HWqcvoib9/DImJN5OYeDM1NXkUFv5GYeEyCguX6cTNSkzMeY5F2uOOKle1gcGRTpcWs4PFB9mWs835fnneYYiHXkdRJmNrkhSWxOqDq50uxuOSjuOnfT9Rbat2xqq02Jsmcnq0OFmof6jTMssuy6ZHaA96hPZgQ9YGAKpqq/gt7TfWZ653Ht8Y8SHxbD6sxKw1KuY3hJ9fNDExZxETcxaAU9zy878nO/tDDh9+h6CgAURHn0ZExIkEBw8nMLAXop4qHwYGBi3nqBCzmpoaMjIyqKysbNK4zJJM7DaX6+3ZW2OA74k3x7N9e8dnsbUHgYGBJCYm4ufn1+ixPcN7kluey6YsVdz3pD4n8eO+H9mZu5NqWzUxwTF1Ymt68ivysZgs9I7o7WaZxQTHkBiWyHe7vkNKyeyFs/lu93fOcb70E0sISWBj1kag/YsM68WtX78nOXz4Q/LyvuLgwZfJyHgGALM5lLCw8YSHTyY2dg5Wa/+GT2pgYNAkjgoxy8jIIDQ0lN69e/vs2qmqraIsu4y44DgigyKprYU9eyA+1kSPuKAu4SKSUpKXl0dGRgZ9+vRp9HjNhbg0dSkRgREkO2KL6zLXAS4RSQpPciaG6MmryCMqKIpu1m5u2Yx9IvowOn40b298m9fXv853u7/jruPu4vSBpxMeEN6gG1RD3w26LdyMvmKxhNGjx3X06HEdNls5paUbKCv7i9LSjRQV/UZq6v2kpt5HVNQM4uIuIjR0HEFB/bvEvzcDg7bkqBCzysrKJgkZqCrvoG7AgX6BFFcC1RBmha5yXxFCEB0dTU5OTuMHAz3DlAvxj/Q/GBE7wtnra90hh5g5RERLFPFEE7OooCinezenXK0L02JzN31/EwOjBzL/hPn4m31PptDXNzxS2r+YzVbCwycRHj7Jua2qKpPMzFc5dOgV8vNVX0OLJYKQkDGEhR1DaKh6BAYeHeXUDAzai6NCzIAm/7ItqiwiwBzgzIqrcJQKDDpyatC2C0353jTLrLK2kgHRA5zipllmWqwqKSyJPzP+rDM+vyKf6KBoooOiVY3G2iqKq4qJscYwKm4UAkGVrYqnT326SUIGLldkiH8IQX5H7h8xICCB3r0fICnpHsrLt1FcvIaSkrWUlKwhPf0ppFSVR4KDR5GQcCUxMecTENC4m9XAoKtz1IhZU7BLOyXVJXSzdnPezCsqwGJRDwPv9AjrgUAgkQyMGkiwfzBRQVF1YlWDug0iryKPNQfXcEyPY5zj88rzSApPIiooivyKfOcas5jgGEIDQhnTfQzdQ7szc8DMJs9NczMeKVZZY5hMFkJCRhESMgqtCLnNVklZ2SaKilaQnf0he/bcwp49txAQ0IuwsHGEho4jLGwcVusQ/Py6Ga5JAwMdXTK9qqSqBLu0O+sUghKzwMDmuRgLCwt56aWXmjWXmTNnUlhY2Kyx7Y2/2d9pAWlxrKTwJGcFfM3NeGXKlcQFx3Hz4puR0tU5Pb8in2hrNNHWaGrttc4ixZoALb98OZ+e92mz5qa5GTsyXtZSzOZAwsKOpWfPWxkzZg1jx26iX7+nCAs7lpKSNezbdzsbN05hxYpY/vgjii1bziAr6z1qa4s6euoGBh1Ol7RDiqqKVBVyR8q3lFBZCVFRzTufJmbXX399nX02mw2z2Vzv2EWL6rT/OaJJCk8iszTTWTGkZ1hPNmZtxOpndbYoCQsI49GTHuXKr6/kwy0fctFIVaQ4ryKPqMAoZ+X+nXk7AZcAtcQ9qIlsZ7HMfCEkZCQhISOd76ursykpWUd5+U7Ky7eTn7+IvLxvEcKfqKjpdOt2NsHBQwkM7GNYbgZdjqNOzObOhY0bGz6mrDoKk+hGkJ8yTKWE0lJlmXnLUE9Ohmeeqf98d955J3v37iU5OZlp06Zx2mmn8eCDD5KQkMDGjRv566+/OOuss0hPT6eyspJbbrmFa6+9FoDevXuzdu1aSktLmTFjBscddxwrVqygR48efPXVVwR5BPG++eYbHn74Yaqrq4mOjuaDDz4gLi6O0tJSbrrpJtauXYsQggceeIDZs2ezePFi7r77bmw2G926dePnn71Xp/eVpPAk/jz4p5tlBnVF5LLky3hp7Uv866d/MWvwLCwmC+U15coyc9SI3JG7w+vY5uB0M3Ziy6wx/P1jiY6eQXT0DACktFNc/Cc5OQvJyfmMvDxXh3shLFgs0YSFjScx8WYiIqYa4mZwVHPUiVljSGnHjsTP5ProNkdNXFMzna6PPfYYW7duZaNDRZctW8bq1avZunWrM+X9zTffJCoqioqKCo455hhmz55NdLR74d/du3fz0Ucf8dprr3H++efz+eefc/HFF7sdc9xxx7Fq1SqEELz++us88cQTLFiwgIceeojw8HC2bFHFcAsKCsjJyeGaa65h+fLl9OnTh/z8fFrK+MTx7Mzb6ewqoImZ50JlkzDxxMlPcOK7J/Ldru+cVd+jg6KdDUI1y6w1FjkH+QUxInYEo+NHN37wUYIQJsLDJxAePoF+/RZQXr6dioq9VFbup7o6m+rqLPLyvmbTpq8ICupPePhxhIWNJybmfPz8Ijt6+gYGrUqbiZkQ4k3gdCBbSjncy/7bgYt08xgCxEgpW3THbciCAiirrmB77k76R/UnIlBlzGVlQUYGjBrl3TJrDuPGjXNbu/Xcc8/x5ZdfApCens7u3bvriFmfPn1ITk4GYMyYMaSmptY5b0ZGBhdccAGZmZlUV1c7r/HTTz/x8ccfO4+LjIzkm2++YfLkyc5joprrR9Uxb8I85k2Y53zvtMy8WESTkibhb/ZnfaarvqOWmg/KMrOYLK3WbmfzPza3ynk6I0KYCA4eRnDwMLftNlsl2dkfkpPzBXl535GV9TZ79swjPv5SLJYIyst3IEQAERFTiIg4Aat1sGHBGXRK2tIyext4AXjX204p5ZPAkwBCiDOAW1sqZL5QbVOVzvWp38XFEBDQekIGEBwc7Hy9bNkyfvrpJ1auXInVauWEE07wWq0kIMBVPNdsNlOhrRfQcdNNNzFv3jzOPPNMli1bxvz58wG1ANrzJuRtW2ujped7cxX6m/0ZHjuc9VnrnRmKejdjamEqscGxxs2zDTGbA0lIuJKEhCuRUlJaupGDB58nM/NNQBIU1I/a2hJycj4BwM8vjoiIyQQHj8BqHURExBT8/eM69kMYGPhAm2UzSimXA76K04XAR201Fz1OMXNUN6+pUWLWEqMlNDSUkpKSevcXFRURGRmJ1Wplx44drFq1qtnXKioqokcPVWz3nXfecW4/5ZRTeOGFF5zvCwoKmDBhAr/++iv79+8HaBU3oyf1xcw0UuJT2JC5wVmLMSooisgg5eKyS/tRlbBxpCOEIDQ0hcGD3+S44wo4/vhyxo3bzoQJ6Rx77B4GDnyNyMiTKS5eTWrq/fz11wWsXJnE9u2XkJf3HaWlW6ipKWj8QgadFiHEdCHETiHEHiHEnV72DxZCrBRCVAkh/qnbPkgIsVH3KBZCzHXsmy+EOKjb1/S1Nz7Q4TEzIYQVmA7c2MAx1wLXAvj7t6zFRrWtGpMwYTapDMMCx//NyBaEEKKjo5k0aRLDhw9nxowZnHbaaW77p0+fziuvvMLIkSMZNGgQ48ePb/a15s+fz3nnnUePHj0YP368U6juvfdebrjhBoYPH47ZbOaBBx7gnHPO4dVXX+Wcc87BbrcTGxvLjz/+2PwP6oXuod0Z231snQr5GqMTRvPGhjeca9Gig6LxN/sT6h9KSXXJUZ2wcSRjNludr4UQBAX1IyioH927a2veyikr+4vDh98lK+ttDh9+33m8xRKN1TqYbt3OIC7uMgIC4p1LMAwru/MihDADLwLTgAxgjRDiaynlX7rD8oGbgbP0Y6WUO4Fk3XkOAl/qDnlaSvlUm00eEPp1QK1+ciF6A996i5npjrkAuFhKeYYv5wwODpZlZWVu27Zv386QIUN8mtPe/L1U1FYwPFZNaedOZZ0NG9Z1ylh50pTvr6msTF/JxDcnMrHnRFakr6D0rlKC/YPp/UxvDhQdYM7wOXw0u12McoNmUltbQmnpRqqrM6mqSqe8fBelpRspKVkNmPH3j6GmJh+TyZ/w8OOJiJhCUNAgAgN7Exw81OjxdoQghCiXUgY3sH8CMF9Kearj/V0AUspHvRw7Hyj1JlBCiFOAB6SUkxo7tjXpcMsMmEM7uRhBWWZavKy6GkpKoHv3ritkbc3IuJGYhIk/M/4kwBzgXIsWbY3mQNEBw83YCbBYQomIOL7O9vLynWRlvUtNTQ4WSxQ2WzGFhUvZt+975zFmcyiRkdOIiDiB4OBhWK1D8fePMyy4jsEihFire/+qlPJV3fsegL53UwZwbDOu4+2efqMQ4lJgLXCblLLV/dUdKmZCiHBgCnBxY8e2FtW2asL9VOUPrfBGS1yMBg0T7B/MoOhBbM/dTmyQK9lDy2g0xKzzYrUOom/fR+psr6nJp7JyP+Xluyks/IX8/O/Jzf3Cud9iicJqHYzZHIwQFiIiTqB7939gsTTet86gRdRKKcc2sN/bL4wmue6EEP7AmcBdus0vAw85zvUQsAC4sinn9YW2TM3/CDgB6CaEyAAeAPwApJSvOA47G/hBSlnm9SStjF3aqbHXOC2zggJVWLirFRdub1ISUtieu925vgxwZjQaMbOjDz+/KPz8oggNHUNc3ByklFRXZ1FWto3y8r8oK9tGRcUubLYSbLYy9u27g7S0x+jWbRZCBGA2hxAVdSoREVMMF2X7kgHo2zUkAoeaeI4ZwHop5WFtg/61EOI14NuWTLI+2kzMpJQX+nDM26gU/nahxlYDqJRxm01V/Ygzso7bnNHxo/lwy4dOawwMy6wrIYQgICCBgIAEoqJOrrO/uHgNaWn/R37+EqS0U1tbSEbGAszmMKzWQQQEJBEY2JOAgJ5YrYOJiDjBLYHFoNVYAwwQQvRBJXDMAf7WxHPUyUwXQiRIKTMdb88GtrZ0ot44EmJm7YZ+jVlJiSpjFRbWwZPqAmi9yjRrTP/asMwMwsKOYfhwV+KbzVZBQcFP5OcvoqJiL+Xl28jPX4zdrhw4JlMQ4eHHY7FEYjL54+cXjb9/dyyWMEDg5xdNdPTpmEwB9VzRwBtSylohxI3AEsAMvCml3CaEuM6x/xUhRDwq7hUG2B3p90OllMWOzPRpwN89Tv2EECIZ5WZM9bK/VeiyYpZdrMpXhYR08KS6ACnxXsTM4XJsjVJWBkcXZnMQ3bqdQbdurgRnKSW1tYWUlKwlL+8biop+o7LyAFJWU12d7RQ6DT+/OLp3v5bQ0DEEBCQSFDTQiMn5gJRyEbDIY9srutdZKPejt7HlQLSX7Ze08jS90jXFzORPcbESsubWY2wpISEhlJaWdszF25nIoEj+MfYfzOg/w7nt5L4nc86Qc+gb2bcDZ2bQWRBC4OcXSVTUNKKiptXZX1tbjM2m/j+VlW0lI+NZDhx4yO2YoKD+hIQkExKSTHDwCAID+xAY2Mth0Rl0drqcmFlMFmprTVRWQrduHT2jrsNLp7n3exseO5zPz/+8g2ZjcLRhsYQ5RSkgoDtRUadQXZ1LVdUBKivTKCvb5lgbt4GcnM88xkYQEJCE1TqQ4OCRBAePICRkJIGBvRGiS7Z87JQcdWI2d/FcZ7UJTypqKpBI/LBSWQnBwb5ZZsnxyTwz/Zl6999xxx306tXL2c9s/vz5hIaG8ve//51Zs2ZRUFBATU0NDz/8MLNmzWrwWvW1ivHWyqW+ti8GBgbg798Nf/9uhIaOISbmbOf22tpiysr+cgpdZeUBKitT6widyWQlKKgvgYF9CA4eSWjoWEJCRhIQkITJdNTdOjs9XeovYseOSZiw1apF0q3lYpwzZw5z5851itnChQtZvHgxgYGBfPnll4SFhZGbm8v48eM588wzG1ww6q1VjN1u99rKxVvbFwMDg4axWMIIDx8P1C0rV1tbSnn5NkpLt1Bevo2Kin1UVOwlL28RoHpFCeFHYGBfrNYBBAUNIChooPN1QECiYc11EEedmDVkQa3PXE90YDcKDiQRHg66Di0tIiUlhezsbA4dOkROTg6RkZEkJSVRU1PD3XffzfLlyzGZTBw8eJDDhw8THx9f77m8tYrJycnx2srFW9sXAwOD5mOxhBAWdixhYe6FL2y2CkpLN1Je/hfl5bupqFCPgoKfsdtd3S1MpkCs1sGEhIwmJCTFadlZrQNRJQsN2oqjTszqo9Zei13ayc/1x26D6Do5Ny3j3HPP5bPPPiMrK4s5c+YA8MEHH5CTk8O6devw8/Ojd+/eXlu/aNTXKqa+Vi7t0eLFwMBAZVhqjVD1SGmnquqQQ9x2UV6+m7KyreTlfU1W1pvO4yyWSCIipuLnF0NtbQFmcwjR0TOJjDzFyLJsJbqMmOUWqExGYfdn8GAVL2tN5syZwzXXXENubi6//voroNq1xMbG4ufnx9KlSzlw4ECD56ivVcyECRO44YYb2L9/v9PNGBUV5Wz78oyjI2lBQYFhnRkYtCNCmAgMTCQwMJHIyKnO7VrVk8rKVCoqdlNY+CuFhUux2cqwWCKpqcl2ip0QFoQIwGQK4P/bu9cYqc46juPfH7ddLspF7rsItBChNHZBYlqrphGNUAv0BUYUKlHjqya2psaW4CX61vuLamuqFlvSGitV0kRDRYNB09IWocVSLIWm3RaEoC4X6XLZvy/OQzrdnVkKu8s5Z+b3SSY75zlnTn47OWf+cy7zPIMGNTN8+CzGjVvC2LGLGDFiLkOG+PdDb0fDFLOhzaehE2a+exgjB6D7qnnz5nH8+HFaWlqYMmUKAKtWrWLp0qUsXLiQtrY25syZ0+s6ag0VM2HChKpDudQa9sXM8lXZ68no0dcxefJn3zK/q+ssx479lY6ObZw7d5Kurs70eIMTJ3Zw4MBa0uhODBs2mUGDsn4sp079ItOm3ZHDf1R8AzoEzEC41CFgTnSe4NDJQ0wfPZ2hg/txSOk6MJBDwJjZxevsfJ2Ojr9x6tReTp3aT1dXJxFnGD9+GZMmrbqkdV5oCJiya5gjs1FNo5jVNCvvGGZmF9TUNJWJE1fkHaNUfA+pmZmVXt0Us7KdLi0Kv29mVg/qopg1Nzdz9OhRfzBfpIjg6NGjNDc35x3FzKxP6uKaWWtrK+3t7Rw5ciTvKKXT3NxMa2vVTrDNzEqjLu5mNDOz3tX73Yx1cZrRzMwam4uZmZmVnouZmZmVXumumUnqAk5dcMHqhgBn+zHO5VLG3GXMDOXMXcbMUM7cZc48PCLq9gCmdMWsLyQ9HREL885xscqYu4yZoZy5y5gZypnbmYurbqu0mZk1DhczMzMrvUYrZj/NO8AlKmPuMmaGcuYuY2YoZ25nLqiGumZmZmb1qdGOzMzMrA65mJmZWek1TDGTtFjSXkn7JN2Vd55qJE2T9GdJeyT9Q9JtqX2cpMclvZj+js07a3eSBkv6u6TH0nQZMo+R9IikF9J7fl3Rc0v6cto2dkt6SFJzETNL+rmkw5J2V7TVzClpbdo390r6eD6pa+b+TtpGnpX0qKQxFfNyz10tc8W8r0gKSeMr2nLPPBAaophJGgzcDSwBrgI+LemqfFNVdRa4IyLmAtcCt6acdwFbImI2sCVNF81twJ6K6TJk/hHwh4iYA1xDlr+wuSW1AF8CFkbE1cBgYCXFzHw/sLhbW9WcaRtfCcxLr/lx2mfzcD89cz8OXB0R7wX+CayFQuW+n56ZkTQN+BjwSkVbUTL3u4YoZsD7gX0RsT8iTgMPA8tzztRDRByMiB3p+XGyD9cWsqzr02LrgZtzCViDpFbgE8B9Fc1Fz/xO4MPAzwAi4nRE/JeC5ybrzWG4pCHACOB1Cpg5Iv4C/Ltbc62cy4GHI6IzIg4A+8j22cuuWu6I2BwR53v9eAI4P2ZSIXLXeK8BfgB8Fai8y68QmQdCoxSzFuDViun21FZYkmYA84EngUkRcRCyggdMzDFaNT8k22m6KtqKnvkK4Ajwi3R69D5JIylw7oh4Dfgu2Tftg0BHRGymwJm7qZWzTPvn54Hfp+eFzS1pGfBaROzqNquwmfuqUYqZqrQV9jcJkkYBvwFuj4hjeefpjaSbgMMR8UzeWS7SEGAB8JOImA+cpBin52pK15iWAzOBqcBISavzTdUvSrF/SlpHdilgw/mmKovlnlvSCGAd8I1qs6u05Z65PzRKMWsHplVMt5KdnikcSUPJCtmGiNiYmv8laUqaPwU4nFe+Kq4Hlkl6mez07UckPUixM0O2TbRHxJNp+hGy4lbk3B8FDkTEkYg4A2wEPkCxM1eqlbPw+6ekNcBNwKp488e5Rc19JdkXnl1pv2wFdkiaTHEz91mjFLOngNmSZkoaRnYBdFPOmXqQJLJrOHsi4vsVszYBa9LzNcDvLne2WiJibUS0RsQMsvf1TxGxmgJnBoiIQ8Crkt6TmhYBz1Ps3K8A10oakbaVRWTXVYucuVKtnJuAlZKaJM0EZgPbc8hXlaTFwJ3Asoj4X8WsQuaOiOciYmJEzEj7ZTuwIG3zhczcLyKiIR7AjWR3Ir0ErMs7T42MHyQ75H8W2JkeNwLvIrv768X0d1zeWWvkvwF4LD0vfGagDXg6vd+/BcYWPTfwLeAFYDfwANBUxMzAQ2TX9c6QfZh+obecZKfFXgL2AksKlnsf2XWm8/vkPUXKXS1zt/kvA+OLlHkgHu7OyszMSq9RTjOamVkdczEzM7PSczEzM7PSczEzM7PSczEzM7PSczEzu4wk3XB+ZAEz6z8uZmZmVnouZmZVSFotabuknZLuTeO1nZD0PUk7JG2RNCEt2ybpiYrxrsam9lmS/ihpV3rNlWn1o/TmOGobUm8eZtYHLmZm3UiaC3wKuD4i2oBzwCpgJLAjIhYAW4Fvppf8ErgzsvGunqto3wDcHRHXkPWheDC1zwduJxtb7wqy/i3NrA+G5B3ArIAWAe8DnkoHTcPJOsXtAn6VlnkQ2ChpNDAmIram9vXAryW9A2iJiEcBIuINgLS+7RHRnqZ3AjOAbQP+X5nVMRczs54ErI+ItW9plL7ebbne+oLr7dRhZ8Xzc3g/NOszn2Y062kLsELSRABJ4yRNJ9tfVqRlPgNsi4gO4D+SPpTabwG2RjYOXbukm9M6mtI4U2Y2APyN0KybiHhe0teAzZIGkfVGfivZAJ7zJD0DdJBdV4NsOJN7UrHaD3wutd8C3Cvp22kdn7yM/4ZZQ3Gv+WZvk6QTETEq7xxm1pNPM5qZWen5yMzMzErPR2ZmZlZ6LmZmZlZ6LmZmZlZ6LmZmZlZ6LmZmZlZ6/wexYrK9IhJCZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax=plt.subplots()\n",
    "acc_ax=loss_ax.twinx()\n",
    " \n",
    "loss_ax.plot(es_hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(es_hist.history['val_loss'], 'r', label='val loss')\n",
    " \n",
    "acc_ax.plot(es_hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(es_hist.history['val_acc'], 'g', label='val acc')\n",
    " \n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    " \n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1_env]",
   "language": "python",
   "name": "conda-env-tf1_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
