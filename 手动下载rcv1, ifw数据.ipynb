{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import get_data_home\n",
    "from os import remove, makedirs\n",
    "from os.path import dirname, exists, join\n",
    "from gzip import GzipFile\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets._base import _pkl_filepath\n",
    "from sklearn.datasets._base import _fetch_remote\n",
    "from sklearn.datasets._base import RemoteFileMetadata\n",
    "from sklearn.datasets._svmlight_format_io import load_svmlight_files\n",
    "from sklearn.utils import shuffle as shuffle_\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.utils.validation import _deprecate_positional_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 804414\n",
    "N_FEATURES = 47236\n",
    "N_CATEGORIES = 103\n",
    "N_TRAIN = 23149\n",
    "data_home = get_data_home()\n",
    "rcv1_dir = join(data_home, \"RCV1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_path = _pkl_filepath(rcv1_dir, \"samples.pkl\")\n",
    "sample_id_path = _pkl_filepath(rcv1_dir, \"sample_id.pkl\")\n",
    "sample_topics_path = _pkl_filepath(rcv1_dir, \"sample_topics.pkl\")\n",
    "topics_path = _pkl_filepath(rcv1_dir, \"topics_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.append(GzipFile(filename=r\"C:\\Users\\Articuly\\scikit_learn_data\\RCV1\\lyrl2004_vectors_train.dat.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<gzip _io.BufferedReader name='C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\lyrl2004_vectors_test_pt0.dat.gz' 0x1d66ea3ccc8>,\n",
       " <gzip _io.BufferedReader name='C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\lyrl2004_vectors_test_pt1.dat.gz' 0x1d66e384808>,\n",
       " <gzip _io.BufferedReader name='C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\lyrl2004_vectors_test_pt2.dat.gz' 0x1d66f0890c8>,\n",
       " <gzip _io.BufferedReader name='C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\lyrl2004_vectors_test_pt3.dat.gz' 0x1d66f075d88>,\n",
       " <gzip _io.BufferedReader name='C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\lyrl2004_vectors_train.dat.gz' 0x1d66efaf408>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = load_svmlight_files(files, n_features=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sp.vstack([Xy[8], Xy[0], Xy[2], Xy[4], Xy[6]]).tocsr()\n",
    "sample_id = np.hstack((Xy[9], Xy[1], Xy[3], Xy[5], Xy[7]))\n",
    "sample_id = sample_id.astype(np.uint32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\sample_id_py3.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(X, samples_path, compress=9)\n",
    "joblib.dump(sample_id, sample_id_path, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = -1\n",
    "n_doc = -1\n",
    "doc_previous = -1\n",
    "y = np.zeros((N_SAMPLES, N_CATEGORIES), dtype=np.uint8)\n",
    "sample_id_bis = np.zeros(N_SAMPLES, dtype=np.int32)\n",
    "category_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joblib.load(samples_path)\n",
    "sample_id = joblib.load(sample_id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_archive_path=r\"C:\\Users\\Articuly\\scikit_learn_data\\RCV1\\rcv1v2.topics.qrels.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cat = -1\n",
    "n_doc = -1\n",
    "doc_previous = -1\n",
    "y = np.zeros((N_SAMPLES, N_CATEGORIES), dtype=np.uint8)\n",
    "sample_id_bis = np.zeros(N_SAMPLES, dtype=np.int32)\n",
    "category_names = {}\n",
    "with GzipFile(filename=topics_archive_path, mode='rb') as f:\n",
    "    for line in f:\n",
    "        line_components = line.decode(\"ascii\").split(\" \")\n",
    "        if len(line_components) == 3:\n",
    "            cat, doc, _ = line_components\n",
    "            if cat not in category_names:\n",
    "                n_cat += 1\n",
    "                category_names[cat] = n_cat\n",
    "\n",
    "            doc = int(doc)\n",
    "            if doc != doc_previous:\n",
    "                doc_previous = doc\n",
    "                n_doc += 1\n",
    "                sample_id_bis[n_doc] = doc\n",
    "            y[n_doc, category_names[cat]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_permutation(a, b):\n",
    "    \"\"\"find the permutation from a to b\"\"\"\n",
    "    t = np.argsort(a)\n",
    "    u = np.argsort(b)\n",
    "    u_ = _inverse_permutation(u)\n",
    "    return t[u_]\n",
    "\n",
    "def _inverse_permutation(p):\n",
    "    \"\"\"inverse permutation p\"\"\"\n",
    "    n = p.size\n",
    "    s = np.zeros(n, dtype=np.int32)\n",
    "    i = np.arange(n, dtype=np.int32)\n",
    "    np.put(s, p, i)  # s[p] = i\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples in X are ordered with sample_id,\n",
    "# whereas in y, they are ordered with sample_id_bis.\n",
    "permutation = _find_permutation(sample_id_bis, sample_id)\n",
    "y = y[permutation, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save category names in a list, with same order than y\n",
    "categories = np.empty(N_CATEGORIES, dtype=object)\n",
    "for k in category_names.keys():\n",
    "    categories[category_names[k]] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder categories in lexicographic order\n",
    "order = np.argsort(categories)\n",
    "categories = categories[order]\n",
    "y = sp.csr_matrix(y[:, order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Articuly\\\\scikit_learn_data\\\\RCV1\\\\topics_names_py3.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(y, sample_topics_path, compress=9)\n",
    "joblib.dump(categories, topics_path, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "news=fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _rcv1_dataset:\n",
      "\n",
      "RCV1 dataset\n",
      "------------\n",
      "\n",
      "Reuters Corpus Volume I (RCV1) is an archive of over 800,000 manually \n",
      "categorized newswire stories made available by Reuters, Ltd. for research \n",
      "purposes. The dataset is extensively described in [1]_.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    ==============     =====================\n",
      "    Classes                              103\n",
      "    Samples total                     804414\n",
      "    Dimensionality                     47236\n",
      "    Features           real, between 0 and 1\n",
      "    ==============     =====================\n",
      "\n",
      ":func:`sklearn.datasets.fetch_rcv1` will load the following \n",
      "version: RCV1-v2, vectors, full sets, topics multilabels::\n",
      "\n",
      "    >>> from sklearn.datasets import fetch_rcv1\n",
      "    >>> rcv1 = fetch_rcv1()\n",
      "\n",
      "It returns a dictionary-like object, with the following attributes:\n",
      "\n",
      "``data``:\n",
      "The feature matrix is a scipy CSR sparse matrix, with 804414 samples and\n",
      "47236 features. Non-zero values contains cosine-normalized, log TF-IDF vectors.\n",
      "A nearly chronological split is proposed in [1]_: The first 23149 samples are\n",
      "the training set. The last 781265 samples are the testing set. This follows \n",
      "the official LYRL2004 chronological split. The array has 0.16% of non zero \n",
      "values::\n",
      "\n",
      "    >>> rcv1.data.shape\n",
      "    (804414, 47236)\n",
      "\n",
      "``target``:\n",
      "The target values are stored in a scipy CSR sparse matrix, with 804414 samples \n",
      "and 103 categories. Each sample has a value of 1 in its categories, and 0 in \n",
      "others. The array has 3.15% of non zero values::\n",
      "\n",
      "    >>> rcv1.target.shape\n",
      "    (804414, 103)\n",
      "\n",
      "``sample_id``:\n",
      "Each sample can be identified by its ID, ranging (with gaps) from 2286 \n",
      "to 810596::\n",
      "\n",
      "    >>> rcv1.sample_id[:3]\n",
      "    array([2286, 2287, 2288], dtype=uint32)\n",
      "\n",
      "``target_names``:\n",
      "The target values are the topics of each sample. Each sample belongs to at \n",
      "least one topic, and to up to 17 topics. There are 103 topics, each \n",
      "represented by a string. Their corpus frequencies span five orders of \n",
      "magnitude, from 5 occurrences for 'GMIL', to 381327 for 'CCAT'::\n",
      "\n",
      "    >>> rcv1.target_names[:3].tolist()  # doctest: +SKIP\n",
      "    ['E11', 'ECAT', 'M11']\n",
      "\n",
      "The dataset will be downloaded from the `rcv1 homepage`_ if necessary.\n",
      "The compressed size is about 656 MB.\n",
      "\n",
      ".. _rcv1 homepage: http://jmlr.csail.mit.edu/papers/volume5/lewis04a/\n",
      "\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    .. [1] Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). \n",
      "           RCV1: A new benchmark collection for text categorization research. \n",
      "           The Journal of Machine Learning Research, 5, 361-397.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.datasets import fetch_lfw_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = get_data_home()\n",
    "lfw_home = join(data_home, \"lfw_home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = join(lfw_home, \"lfw_funneled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_path = r\"C:\\Users\\Articuly\\scikit_learn_data\\lfw_home\\lfw-funneled.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tarfile.open(archive_path, \"r:gz\").extractall(path=lfw_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=fetch_lfw_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _labeled_faces_in_the_wild_dataset:\n",
      "\n",
      "The Labeled Faces in the Wild face recognition dataset\n",
      "------------------------------------------------------\n",
      "\n",
      "This dataset is a collection of JPEG pictures of famous people collected\n",
      "over the internet, all details are available on the official website:\n",
      "\n",
      "    http://vis-www.cs.umass.edu/lfw/\n",
      "\n",
      "Each picture is centered on a single face. The typical task is called\n",
      "Face Verification: given a pair of two pictures, a binary classifier\n",
      "must predict whether the two images are from the same person.\n",
      "\n",
      "An alternative task, Face Recognition or Face Identification is:\n",
      "given the picture of the face of an unknown person, identify the name\n",
      "of the person by referring to a gallery of previously seen pictures of\n",
      "identified persons.\n",
      "\n",
      "Both Face Verification and Face Recognition are tasks that are typically\n",
      "performed on the output of a model trained to perform Face Detection. The\n",
      "most popular model for Face Detection is called Viola-Jones and is\n",
      "implemented in the OpenCV library. The LFW faces were extracted by this\n",
      "face detector from various online websites.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =======================\n",
      "    Classes                                5749\n",
      "    Samples total                         13233\n",
      "    Dimensionality                         5828\n",
      "    Features            real, between 0 and 255\n",
      "    =================   =======================\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "``scikit-learn`` provides two loaders that will automatically download,\n",
      "cache, parse the metadata files, decode the jpeg and convert the\n",
      "interesting slices into memmapped numpy arrays. This dataset size is more\n",
      "than 200 MB. The first load typically takes more than a couple of minutes\n",
      "to fully decode the relevant part of the JPEG files into numpy arrays. If\n",
      "the dataset has  been loaded once, the following times the loading times\n",
      "less than 200ms by using a memmapped version memoized on the disk in the\n",
      "``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\n",
      "\n",
      "The first loader is used for the Face Identification task: a multi-class\n",
      "classification task (hence supervised learning)::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_lfw_people\n",
      "  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
      "\n",
      "  >>> for name in lfw_people.target_names:\n",
      "  ...     print(name)\n",
      "  ...\n",
      "  Ariel Sharon\n",
      "  Colin Powell\n",
      "  Donald Rumsfeld\n",
      "  George W Bush\n",
      "  Gerhard Schroeder\n",
      "  Hugo Chavez\n",
      "  Tony Blair\n",
      "\n",
      "The default slice is a rectangular shape around the face, removing\n",
      "most of the background::\n",
      "\n",
      "  >>> lfw_people.data.dtype\n",
      "  dtype('float32')\n",
      "\n",
      "  >>> lfw_people.data.shape\n",
      "  (1288, 1850)\n",
      "\n",
      "  >>> lfw_people.images.shape\n",
      "  (1288, 50, 37)\n",
      "\n",
      "Each of the ``1140`` faces is assigned to a single person id in the ``target``\n",
      "array::\n",
      "\n",
      "  >>> lfw_people.target.shape\n",
      "  (1288,)\n",
      "\n",
      "  >>> list(lfw_people.target[:10])\n",
      "  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\n",
      "\n",
      "The second loader is typically used for the face verification task: each sample\n",
      "is a pair of two picture belonging or not to the same person::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_lfw_pairs\n",
      "  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\n",
      "\n",
      "  >>> list(lfw_pairs_train.target_names)\n",
      "  ['Different persons', 'Same person']\n",
      "\n",
      "  >>> lfw_pairs_train.pairs.shape\n",
      "  (2200, 2, 62, 47)\n",
      "\n",
      "  >>> lfw_pairs_train.data.shape\n",
      "  (2200, 5828)\n",
      "\n",
      "  >>> lfw_pairs_train.target.shape\n",
      "  (2200,)\n",
      "\n",
      "Both for the :func:`sklearn.datasets.fetch_lfw_people` and\n",
      ":func:`sklearn.datasets.fetch_lfw_pairs` function it is\n",
      "possible to get an additional dimension with the RGB color channels by\n",
      "passing ``color=True``, in that case the shape will be\n",
      "``(2200, 2, 62, 47, 3)``.\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\n",
      "3 subsets: the development ``train`` set, the development ``test`` set and\n",
      "an evaluation ``10_folds`` set meant to compute performance metrics using a\n",
      "10-folds cross validation scheme.\n",
      "\n",
      ".. topic:: References:\n",
      "\n",
      " * `Labeled Faces in the Wild: A Database for Studying Face Recognition\n",
      "   in Unconstrained Environments.\n",
      "   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\n",
      "   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\n",
      "   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\n",
      "\n",
      "\n",
      "Examples\n",
      "~~~~~~~~\n",
      "\n",
      ":ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pairs.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "people=fetch_lfw_people()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(people.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
